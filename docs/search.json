[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"sessions intended enable perform additional data analysis techniques appropriately confidently using R Python.Ongoing formative assessment exercisesOngoing formative assessment exercisesNo formal assessmentNo formal assessmentNo mathematical derivationsNo mathematical derivationsNo pen paper calculationsNo pen paper calculationsThey “mindlessly use stats program” course!","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.1 Core aims","text":"know presented non-standard dataset e.g.Know deal non-normal dataKnow analyse count dataBe able deal random effects","code":""},{"path":"index.html","id":"core-topics","chapter":"1 Overview","heading":"1.2 Core topics","text":"Generalised linear models","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.3 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder right-clicking link Save …. Next unzip file copy working directory. data accessible via <working-directory-name>/data..panelset{--panel-tab-font-family: inherit;}","code":""},{},{"path":"hierarchical-clustering.html","id":"hierarchical-clustering","chapter":"2 Hierarchical clustering","heading":"2 Hierarchical clustering","text":"","code":""},{"path":"hierarchical-clustering.html","id":"objectives","chapter":"2 Hierarchical clustering","heading":"2.1 Objectives","text":"Understand hierarchical clustering can used forBe able calculate distance matricesKnow different methods calculate distance matricesPerform hierarchical clusteringDraw dendrogramsCut dendrograms clusters use clustering information visualise data","code":""},{"path":"hierarchical-clustering.html","id":"purpose-and-aim","chapter":"2 Hierarchical clustering","heading":"2.2 Purpose and aim","text":"Hierarchical clustering form cluster analysis, aim create hierarchy clusters. results commonly displayed dendrogram, displays clusters found analysis.","code":""},{"path":"hierarchical-clustering.html","id":"libraries-and-functions","chapter":"2 Hierarchical clustering","heading":"2.3 Libraries and functions","text":"tidyverse","code":""},{"path":"hierarchical-clustering.html","id":"data","chapter":"2 Hierarchical clustering","heading":"2.4 Data","text":"example session ’ll using yeast RNAseq data set.Yeast RNAseqThese data experiment included fission R/Bioconductor package. briefly, transcriptome data :Two yeast strains: wild type (wt) atf21del mutant (mut)6 time points osmotic stress time (0, 15, 30, 60, 120 180 mins)Three replicates strain time pointLet’s say experiment , bioinformatician analysed provided four files data:sample_info.csv - information sample.counts_raw.csv - raw unprocessed read counts genes, gives measure genes’ expression. (simply scaled size library account fact different samples less total number reads).counts_transformed.csv - normalised read counts genes, log scale transformed correct dependency mean variance. typical count data.test_result.csv - results statistical test assessed probability observed expression differences first time points WT cells, assuming null hypothesis difference.","code":""},{"path":"hierarchical-clustering.html","id":"get-to-know-your-data","chapter":"2 Hierarchical clustering","heading":"2.5 Get to know your data","text":"Let’s load data need session (don’t need raw data):","code":"\ntrans_cts <- read_csv(\"data/transcriptome/counts_transformed.csv\")\nsample_info <- read_csv(\"data/transcriptome/sample_info.csv\")\ntest_result <- read_csv(\"data/transcriptome/test_result.csv\")"},{"path":"hierarchical-clustering.html","id":"transformed-counts","chapter":"2 Hierarchical clustering","heading":"2.5.1 Transformed counts","text":"Let’s look transformed count data:list genes, 37 columns. columns encode information strain (wt/mut), time point (0, 15, etc) repeat (r1, r2, r3). something need aware , ’s often helpful kind information encoded column name.quick check also tells us 6,011 genes data set, gene occurring :","code":"\ntrans_cts## # A tibble: 6,011 × 37\n##    gene     wt_0_r1 wt_0_r2 wt_0_r3 wt_15_r1 wt_15_r2 wt_15_r3 wt_30_r1 wt_30_r2\n##    <chr>      <dbl>   <dbl>   <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n##  1 SPAC212…    4.95    4.97    5.66     5.45     5.44     6.50     5.08     5.25\n##  2 SPAC212…    5.44    6.21    6.17     5.94     6.33     6.41     6.71     7.15\n##  3 SPAC212…    5.75    5.06    5.54     5.68     5.18     5.10     5.82     6.31\n##  4 SPNCRNA…    5.73    4.87    4.94     5.57     5.32     4.20     5.17     4.77\n##  5 SPAC977…    7.05    6.84    6.79     6.87     6.09     6.19     6.91     6.66\n##  6 SPAC977…    5.34    5.34    5.31     5.32     5.99     5.30     7.61     7.48\n##  7 SPAC977…    6.50    6.23    6.70     7.03     6.92     7.53     6.44     6.68\n##  8 SPAC977…    7.24    7.46    7.48     7.09     7.46     7.65     6.88     7.13\n##  9 SPNCRNA…    5.96    5.69    5.94     5.92     5.87     4.84     7.38     7.30\n## 10 SPAC1F8…    6.64    6.65    6.78     4.62     5.61     6.15     5.66     6.50\n## # … with 6,001 more rows, and 28 more variables: wt_30_r3 <dbl>,\n## #   wt_60_r1 <dbl>, wt_60_r2 <dbl>, wt_60_r3 <dbl>, wt_120_r1 <dbl>,\n## #   wt_120_r2 <dbl>, wt_120_r3 <dbl>, wt_180_r1 <dbl>, wt_180_r2 <dbl>,\n## #   wt_180_r3 <dbl>, mut_0_r1 <dbl>, mut_0_r2 <dbl>, mut_0_r3 <dbl>,\n## #   mut_15_r1 <dbl>, mut_15_r2 <dbl>, mut_15_r3 <dbl>, mut_30_r1 <dbl>,\n## #   mut_30_r2 <dbl>, mut_30_r3 <dbl>, mut_60_r1 <dbl>, mut_60_r2 <dbl>,\n## #   mut_60_r3 <dbl>, mut_120_r1 <dbl>, mut_120_r2 <dbl>, mut_120_r3 <dbl>, …\ntrans_cts %>% \n  count(gene) %>%  # count the number of genes\n  arrange(desc(n)) # arrange in descending order## # A tibble: 6,011 × 2\n##    gene             n\n##    <chr>        <int>\n##  1 SPAC1002.01      1\n##  2 SPAC1002.02      1\n##  3 SPAC1002.03c     1\n##  4 SPAC1002.04c     1\n##  5 SPAC1002.05c     1\n##  6 SPAC1002.07c     1\n##  7 SPAC1002.08c     1\n##  8 SPAC1002.09c     1\n##  9 SPAC1002.10c     1\n## 10 SPAC1002.11      1\n## # … with 6,001 more rows"},{"path":"hierarchical-clustering.html","id":"sample-info","chapter":"2 Hierarchical clustering","heading":"2.5.2 Sample info","text":"Let’s look see sample info:data set contains information various samples, data also split column. ’ll come handy later .","code":"\nsample_info## # A tibble: 36 × 4\n##    sample   strain minute replicate\n##    <chr>    <chr>   <dbl> <chr>    \n##  1 wt_0_r1  wt          0 r1       \n##  2 wt_0_r2  wt          0 r2       \n##  3 wt_0_r3  wt          0 r3       \n##  4 wt_15_r1 wt         15 r1       \n##  5 wt_15_r2 wt         15 r2       \n##  6 wt_15_r3 wt         15 r3       \n##  7 wt_30_r1 wt         30 r1       \n##  8 wt_30_r2 wt         30 r2       \n##  9 wt_30_r3 wt         30 r3       \n## 10 wt_60_r1 wt         60 r1       \n## # … with 26 more rows"},{"path":"hierarchical-clustering.html","id":"test-results","chapter":"2 Hierarchical clustering","heading":"2.5.3 Test results","text":"test results give us results statistical test first time point WT cells, comparing time points. null hypothesis difference. column ’re mostly interested padj, gives us adjusted p-values.","code":"\ntest_result## # A tibble: 30,055 × 8\n##    gene        baseMean log2FoldChange lfcSE   stat pvalue  padj comparison\n##    <chr>          <dbl>          <dbl> <dbl>  <dbl>  <dbl> <dbl>      <dbl>\n##  1 SPAC212.11      8.55         1.54   0.497  1.09  0.276      1         15\n##  2 SPAC212.09c    50.8          0.399  0.273  0     1          1         15\n##  3 SPAC212.04c    38.3         -0.0230 0.269  0     1          1         15\n##  4 SPNCRNA.601     9.47        -0.0841 0.483  0     1          1         15\n##  5 SPAC977.11     70.4         -0.819  0.201  0     1          1         15\n##  6 SPAC977.13c    36.7          1.19   0.344  0.552 0.581      1         15\n##  7 SPAC977.15     49.1          0.600  0.208  0     1          1         15\n##  8 SPAC977.16c    83.2          0.148  0.239  0     1          1         15\n##  9 SPNCRNA.607    60.4          0.0638 0.268  0     1          1         15\n## 10 SPAC1F8.06     74.2         -1.58   0.298 -1.94  0.0520     1         15\n## # … with 30,045 more rows\ntest_result %>% \n  select(gene, padj)## # A tibble: 30,055 × 2\n##    gene         padj\n##    <chr>       <dbl>\n##  1 SPAC212.11      1\n##  2 SPAC212.09c     1\n##  3 SPAC212.04c     1\n##  4 SPNCRNA.601     1\n##  5 SPAC977.11      1\n##  6 SPAC977.13c     1\n##  7 SPAC977.15      1\n##  8 SPAC977.16c     1\n##  9 SPNCRNA.607     1\n## 10 SPAC1F8.06      1\n## # … with 30,045 more rows"},{"path":"hierarchical-clustering.html","id":"clustering","chapter":"2 Hierarchical clustering","heading":"2.6 Clustering","text":"lot data (6,000 data points!). might interested data group/cluster together. using k-means clustering ’re going use hierarchical clustering.’re looking specifically whether groups genes similar one another. approach creating hierarchy: genes similar cluster together, followed next groups genes similar , forth.make things bit manageable example, ’ll look subset 6,011 genes. ’ll select 50 highly differentially expressed genes work store gene names data frame:tidyverseNow ’ve got list genes ’re interested , can use cluster data.way works first gene compared genes. two genes form cluster. second gene compared cluster remaining genes. forms cluster similar gene cluster.process continues comparisons left.way quantified calculating matrix dissimilarities. happens using distance measures - something already learned k-means clustering. Two useful distance measures Euclidian Manhattan distance.different ways methods calculating distances, commonly types used:tidyverse\nfunction use calculate clusters hclust(). can , need calculate dissimilarities clusters. using dist() function. default method used \"euclidian\", options. Run ?dist look.default method used hclust() \"complete\", just different ’ll using \"average\" linkage . ’s always useful see method helps look data best.Scaling technically necessary , differential expression analysis already done us. However, ’ve included step anyway make aware . Trying calculate distances values different scales result non-sensical results!can look hclust() produced us:answer list contains whole bunch data. can see distance clustering methods specified (hoorah!). Also, appear 44 objects.help us much, let’s go ahead plot . make bit manageable ’re using library ggdendro, allows us plot dendrograms using ggplot-style syntax.haven’t installed/loaded , now good time. can follows:Next, can plot dendrogram using ggdendrogram() function. give gene_clust object, tell rotate dendrogram (try setting TRUE see happens!), give title.dendrogram can see quite bit structure data. question , start delve bit deeper ? One way cutting dendrogram different groups.Visually, see slicing across various clusters. represented horizontal line, slice dendrogram four groups:tidyverseWe can kind slicing programmatically well. happens comparable k-means clustering, divide data groups (clusters) gene gets assigned specific cluster.tidyverse\ncreate clusters cutting dendrogram using cutree() function. little bit data wrangling (creating tibble resulting vector, renaming column names) get following output:can see gene list now assigned certain cluster number. can use information look data bit detail.example, see gene expression trends visible across different clusters. useful visually follow gene expression candidate genes time, cluster strain.requires bit logical thinking, let’s go step--step.three biological repeats per time point per strain, need average thosewe need make sure data scaledwe need create scaled averages gene, strain time pointTo , take transformed counts (trans_cts) data first rejig long format can grouping . merge sample_info data, get relevant information regarding strain, time point repeat. filter candidate genes, scale counts, group data calculate average counts.Sounds doable, right? Hoorah pipes, can go step--step:’s done, can merge information gene_cluster, contains cluster classification gene:can see now data need: gene information type strain, time point, scaled mean counts cluster gene assigned . also bonus column containing number repeats make mean values.Exercise 2.1  Bonus exercise\nmean values made three biological repeats?many ways can skin proverbial cat, one :yes, mean counts values made three biological repeats. good know, realise averages comparable.Now data, can finally plot gene expression trends, separating genes interest cluster.facetting:can see overall trend comparable clusters. Something different seems going cluster 4, actually based seems like single observation. reason (well, ) choice look top 50 differentially expressed genes.get generalised view can also add median line facet, showing median expression cluster:","code":"\n# set of candidate genes for clustering\n# we select the 50 genes with the lowest padj value\ncandidate_genes <- test_result %>% \n  slice_min(padj, n = 50) %>%  \n  select(gene) %>% \n  distinct()\ngene_hclust <- trans_cts %>%\n  # filter our data for the candidate genes\n  semi_join(candidate_genes, by = \"gene\") %>%\n  # convert the gene column to row names\n  # because dist() takes a matrix\n  column_to_rownames(var = \"gene\") %>% \n  # scale the data\n  scale() %>% \n  # calculate the Euclidian distance\n  dist(method = \"euclidian\") %>% \n  # perform the clustering\n  hclust(method = \"average\")\ngene_hclust## \n## Call:\n## hclust(d = ., method = \"average\")\n## \n## Cluster method   : average \n## Distance         : euclidean \n## Number of objects: 44\n# install if needed\ninstall.packages(\"ggdendro\")\n\n# and load the library\nlibrary(ggdendro)\nggdendrogram(gene_hclust, rotate = FALSE) +\n  labs(title = \"Top 50 DEG dendrogram\")\nggdendrogram(gene_hclust, rotate = FALSE) +\n  geom_hline(yintercept = 8.2, colour = \"red\") +\n  labs(title = \"Top 50 DEG dendrogram\",\n       subtitle = \"cutting into 4 cluster\")\ngene_cluster <- cutree(gene_hclust, k = 4) %>% \n  # turn the named vector into a tibble\n  enframe() %>% \n  # rename some of the columns\n  rename(gene = name, cluster = value)\n\nhead(gene_cluster)## # A tibble: 6 × 2\n##   gene          cluster\n##   <chr>           <int>\n## 1 SPAC22A12.17c       1\n## 2 SPACUNK4.17         1\n## 3 SPAC4H3.03c         2\n## 4 SPAC2F3.05c         1\n## 5 SPAC637.03          2\n## 6 SPAC26F1.07         3\n# summarise counts \ntrans_cts_mean <- trans_cts %>% \n  # convert to long format\n  pivot_longer(cols = wt_0_r1:mut_180_r3, names_to = \"sample\", values_to = \"cts\")  %>% \n  # join with sample info table\n  full_join(sample_info, by = \"sample\") %>% \n  # filter to retain only genes of interest\n  semi_join(candidate_genes, by = \"gene\") %>%\n  # for each gene\n  group_by(gene) %>% \n  # scale the cts column\n  mutate(cts_scaled = scale(cts)) %>% \n  # for each gene, strain and minute\n  group_by(gene, strain, minute) %>%\n  # calculate the mean (scaled) cts\n  summarise(mean_cts_scaled = mean(cts_scaled),\n            n_rep = n()) %>% \n  ungroup()\ntrans_cts_cluster <- trans_cts_mean %>% \n  inner_join(gene_cluster, by = \"gene\")\n\nhead(trans_cts_cluster)## # A tibble: 6 × 6\n##   gene        strain minute mean_cts_scaled n_rep cluster\n##   <chr>       <chr>   <dbl>           <dbl> <int>   <int>\n## 1 SPAC11E3.14 mut         0          -1.06      3       1\n## 2 SPAC11E3.14 mut        15           0.615     3       1\n## 3 SPAC11E3.14 mut        30           1.83      3       1\n## 4 SPAC11E3.14 mut        60          -0.553     3       1\n## 5 SPAC11E3.14 mut       120          -0.353     3       1\n## 6 SPAC11E3.14 mut       180          -0.635     3       1\ntrans_cts_cluster %>% \n  count(n_rep)## # A tibble: 1 × 2\n##   n_rep     n\n##   <int> <int>\n## 1     3   528\ntrans_cts_cluster %>% \n  ggplot(aes(minute, mean_cts_scaled)) +\n  geom_line(aes(group = gene)) +\n  facet_grid(rows = vars(strain), cols = vars(cluster))\ntrans_cts_cluster %>% \n  ggplot(aes(minute, mean_cts_scaled)) +\n  geom_line(aes(group = gene),\n            alpha = 0.3) +\n  geom_line(stat = \"summary\",      # create a summary stat\n            fun = \"median\",        # and use the median\n            colour = \"red\",\n            size = 0.5, \n            aes(group = 1)) +      # idiosyncratic necessity to group the line\n  facet_grid(rows = vars(strain),  # plot strains in rows\n             cols = vars(cluster)) # and clusters in columns"},{"path":"hierarchical-clustering.html","id":"exercise-penguins","chapter":"2 Hierarchical clustering","heading":"2.7 Exercise: Penguins","text":"Exercise 2.2  ’re still us point, well done! exercise ’re going practice creating dendrogram using penguins data set.like following:load penguins data set, neededremove missing values add ID column (factor)scale data (needed)calculate distance matrix using Euclidian distanceperform hierarchical clustering complete linkageplot dendrogramrepeat process now using Manhattan distancesee hierarchical structure similar (eye-balling )tidyverseFirst update penguins data set, removing missing values creating ID column. simply creating row number, gives unique ID observation. number real numerical meaning, set factor.clustering, first remove non-numerical data data set. still want retain information data, use id column row names.need scale() data, original variables different scales (e.g. flipper length milimeters, whereas body mass grams).show calculate distance matrix using Euclidian distance, Manhattan method, simply change method = \"manhattan\". everything life easy…, dear viewers, allows us create wonderful dendrogram. many observations, can omit labels using labels = FALSE.Lastly, comparing effect Euclidian Manhattan distance matrices final dendrogram shows slight differences two methods:","code":"\npenguins <- penguins %>% \n  # remove missing values\n  drop_na() %>% \n  # create ID column\n  mutate(id = 1:n(),\n         id = as_factor(id))\npenguins_hclust <- penguins %>% \n  select(-species, -island, -sex, -year) %>% \n  column_to_rownames(var = \"id\") %>% \n  scale() %>% \n  dist(method = \"euclidian\") %>% \n  hclust(method = \"complete\")\nggdendrogram(penguins_hclust, rotate = FALSE, labels = FALSE) +\n  labs(title = \"Penguins dendrogram\")"},{"path":"hierarchical-clustering.html","id":"optional-colouring-clusters","chapter":"2 Hierarchical clustering","heading":"2.8 Optional: Colouring clusters","text":"Adding colour dendrograms can bit tricky. different ways , simplest method ’ve found (far) require installation various, extensive packages bunch functions written Atrebas. See blogpost.Basically, need load script provided go!can also plot circular dendrogram:","code":"\nsource(file = \"scripts/ggdendro_extended.R\")\n# cut the dendrogram, specify the number of clusters\nhcdata <- dendro_data_k(gene_hclust, 4)\n\n\nplot_ggdendro(hcdata,\n              direction   = \"lr\",\n              expand.y    = 0.2,\n              branch.size = 0.5)\nplot_ggdendro(hcdata,\n              fan         = TRUE,\n              label.size  = 3,\n              nudge.label = 0.02,\n              expand.y    = 0.4) +\n  theme_void()"},{"path":"hierarchical-clustering.html","id":"key-points","chapter":"2 Hierarchical clustering","heading":"2.9 Key points","text":"Hierarchical clustering can used determine visualise hierarchy dataDistance matrices can calculated , example, Euclidian distance Manhattan distanceCalculating dissimilarity clusters can done different ways, example using complete linkage (largest distance), single linkage (minimum distance) average linkageDrawing dendrograms can visualise hierarchy cutting dendrograms can help investigate potential clusters data","code":""}]
