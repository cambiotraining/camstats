[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"sessions intended enable perform additional data analysis techniques appropriately confidently using R Python.Ongoing formative assessment exercisesOngoing formative assessment exercisesNo formal assessmentNo formal assessmentNo mathematical derivationsNo mathematical derivationsNo pen paper calculationsNo pen paper calculationsThey “mindlessly use stats program” course!","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.1 Core aims","text":"know presented non-standard dataset e.g.Know deal non-normal dataKnow analyse count dataBe able deal random effects","code":""},{"path":"index.html","id":"core-topics","chapter":"1 Overview","heading":"1.2 Core topics","text":"Generalised linear models","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.3 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder right-clicking link Save …. Next unzip file copy working directory. data accessible via <working-directory-name>/data.","code":"## Registered S3 method overwritten by 'tune':\n##   method                   from   \n##   required_pkgs.model_spec parsnip## ── Attaching packages ────────────────────────────────────── tidymodels 0.1.4 ──## ✓ dials        0.1.0     ✓ rsample      0.1.1\n## ✓ infer        1.0.0     ✓ tune         0.1.6\n## ✓ modeldata    0.1.1     ✓ workflows    0.2.4\n## ✓ parsnip      0.2.0     ✓ workflowsets 0.1.0\n## ✓ recipes      0.2.0     ✓ yardstick    0.0.9## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n## x scales::discard() masks purrr::discard()\n## x dplyr::filter()   masks stats::filter()\n## x recipes::fixed()  masks stringr::fixed()\n## x dplyr::lag()      masks stats::lag()\n## x yardstick::spec() masks readr::spec()\n## x recipes::step()   masks stats::step()\n## x tune::tune()      masks parsnip::tune()\n## • Search for functions across packages at https://www.tidymodels.org/find/"},{},{"path":"glm-intro.html","id":"glm-intro","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"glm-intro.html","id":"objectives","chapter":"2 Introduction","heading":"2.1 Objectives","text":"Aim: introduce R commands analysing data non-continuous response variables.end practical participants able achieve following:Construct\nlogistic model binary response variables\nlogistic model proportion response variables\nPoisson model count response variables\nNegative Binomial model count response variables\nlogistic model binary response variablesa logistic model proportion response variablesa Poisson model count response variablesa Negative Binomial model count response variablesPlot data fitted curve case continuous categorical predictorsAssess significance fitAssess assumption model","code":""},{"path":"glm-intro.html","id":"background","chapter":"2 Introduction","heading":"2.2 Background","text":"practical divided sections considers sort response variable generalised linear model turn. Within section least one example modelling process followed example..panelset{--panel-tab-font-family: inherit;}","code":"## Registered S3 method overwritten by 'tune':\n##   method                   from   \n##   required_pkgs.model_spec parsnip## ── Attaching packages ────────────────────────────────────── tidymodels 0.1.4 ──## ✓ dials        0.1.0     ✓ rsample      0.1.1\n## ✓ infer        1.0.0     ✓ tune         0.1.6\n## ✓ modeldata    0.1.1     ✓ workflows    0.2.4\n## ✓ parsnip      0.2.0     ✓ workflowsets 0.1.0\n## ✓ recipes      0.2.0     ✓ yardstick    0.0.9## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n## x scales::discard() masks purrr::discard()\n## x dplyr::filter()   masks stats::filter()\n## x recipes::fixed()  masks stringr::fixed()\n## x dplyr::lag()      masks stats::lag()\n## x yardstick::spec() masks readr::spec()\n## x recipes::step()   masks stats::step()\n## x tune::tune()      masks parsnip::tune()\n## • Use suppressPackageStartupMessages() to eliminate package startup messages## Warning: 'xaringanExtra::style_panelset' is deprecated.\n## Use 'style_panelset_tabs' instead.\n## See help(\"Deprecated\")"},{},{"path":"logistic-models-binary-response.html","id":"logistic-models-binary-response","chapter":"3 Logistic Models – Binary Response","heading":"3 Logistic Models – Binary Response","text":"","code":""},{"path":"logistic-models-binary-response.html","id":"objectives-1","chapter":"3 Logistic Models – Binary Response","heading":"3.1 Objectives","text":"QuestionsHow analyse data binary outcome?Can test model good?ObjectivesBe able perform logistic regression binary outcomePredict outcomes new data, based defined modelEvaluate model reliability using training test data sets","code":""},{"path":"logistic-models-binary-response.html","id":"libraries-and-functions","chapter":"3 Logistic Models – Binary Response","heading":"3.2 Libraries and functions","text":"tidyverse","code":""},{"path":"logistic-models-binary-response.html","id":"datasets","chapter":"3 Logistic Models – Binary Response","heading":"3.3 Datasets","text":"DiabetesThe example section uses following data set:data/diabetes.csvThis data set comprising 768 observations three variables (one dependent two predictor variables). records results diabetes test result binary variable (1 positive result, 0 negative result), along result glucose test diastolic blood pressure 767 women. variables called test_result, glucose diastolic.","code":""},{"path":"logistic-models-binary-response.html","id":"visualise-the-data","chapter":"3 Logistic Models – Binary Response","heading":"3.4 Visualise the data","text":"First load data, visualise . needed, load tidyverse package using:tidyverse\nFirst, load inspect data:Looking data, can see test_result column contains zeros ones. test result outcomes actually numeric representations.cause problems later, need tell R see values factors. good measure ’ll also improve information test_result classifying ‘negative’ (0) ‘positive’ (1).can plot data:looks though patients positive diabetes test slightly higher glucose levels negative diabetes test.can visualise differently plotting data points classic binary response plot:","code":"\ndiabetes <- read_csv(\"data/diabetes.csv\")\ndiabetes <- \ndiabetes %>% \n  # replace 0 with 'negative' and 1 with 'positive'\n  mutate(test_result = case_when(test_result == 0 ~ \"negative\",\n                                 TRUE ~ \"positive\")) %>% \n  # convert character columns to factor\n  mutate_if(is.character, factor)\ndiabetes %>% \n  ggplot(aes(x = test_result, y = glucose)) +\n  geom_boxplot()\ndiabetes %>% \n  ggplot(aes(x = glucose, y = test_result)) +\n  geom_point()"},{"path":"logistic-models-binary-response.html","id":"model-building","chapter":"3 Logistic Models – Binary Response","heading":"3.5 Model building","text":"different ways construct logistic model.tidyverseIn tidymodels access useful package: parsnip, provides common syntax whole range modelling libraries. means syntax stay different kind model comparisons. , learning curve might bit steeper start , pay dividend long-term (just like started using R!).First, need load tidymodels (install first, needed):workflow parsnip bit different ’re used far. now, ’ve directly used relevant model functions analyse data, example using lm() function create linear models.Using parsnip approach things systematic manner. first might seem unnecessarily verbose, clear advantages approaching analysis systematic way. example, straightforward implement types models using workflow, ’ll definitely find useful moving difficult modelling tasks.Using tidymodels specify model three steps:Specify type model based mathematical structure (e.g., linear regression, random forest, K-nearest neighbors, etc).required, declare mode model. mode reflects type prediction outcome. numeric outcomes, mode regression; qualitative outcomes, classification. model can create one type model, logistic regression, mode already set.Specify engine fitting model. usually software package library used., can create model follows:Note actually specifying variables just yet! ’ve done tell R kind model ’re planning use. want see parsnip converts code package syntax, can check translate():shows logistic regression model, outcome going classification (case, ’s positive negative test result). model fit template tells us ’ll using glm() function stats package, can take formula, data, weights family argument. family argument already set binomial.Now ’ve specified kind model ’re planning use, can fit data , using fit() function:can look output directly, prefer tidy data using tidy() function broom package:estimate column gives coefficients logistic model equation. use calculate probability positive diabetes test, given glucose level, using following equation:\\[\\begin{equation}\nP(positive \\ test \\ result) = \\frac{1}{1 + {e}^{-(-5.61 +  0.040 \\cdot glucose)}}\n\\end{equation}\\]course ’re going way. ’ll let R deal next section.std.error column gives error associated coefficients statistic column tells statistic value.values p.value merely show whether particular coefficient significantly different zero. similar p-values obtained summary output linear model, , continuous predictors p-values can used rough guide whether predictor important (case glucose appears significant). However, p-values aren’t great multiple predictor variables, categorical predictors multiple levels (since output give us p-value level rather predictor whole).","code":"\n# install.packages(\"tidymodels\")\nlibrary(tidymodels)\ndia_mod <- logistic_reg() %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"glm\")\ndia_mod %>% translate()## Logistic Regression Model Specification (classification)\n## \n## Computational engine: glm \n## \n## Model fit template:\n## stats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n##     family = stats::binomial)\ndia_fit <- dia_mod %>% \n  fit(test_result ~ glucose,\n      data = diabetes)\ndia_fit %>% tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -5.61     0.442       -12.7 6.90e-37\n## 2 glucose       0.0395   0.00340      11.6 2.96e-31"},{"path":"logistic-models-binary-response.html","id":"model-predictions","chapter":"3 Logistic Models – Binary Response","heading":"3.6 Model predictions","text":"got new glucose level data wanted predict people might diabetes ?use existing model feed data:tidyverseAlthough able get predicted outcomes (.pred_class), like stress point running model. important realise model (statistical models) creates predicted outcome based certain probabilities. therefore much informative look probable predicted outcomes . encoded .pred_negative .pred_positive.first value means 14% chance diabetes test return negative result around 86% chance return positive result.","code":"\n# create a dummy data set using some hypothetical glucose measurements\ndiabetes_newdata <- tibble(glucose = c(188, 122, 83, 76, 144))\n\n# predict if the patients have diabetes or not\naugment(dia_fit,\n        new_data = diabetes_newdata)## # A tibble: 5 × 4\n##   glucose .pred_class .pred_negative .pred_positive\n##     <dbl> <fct>                <dbl>          <dbl>\n## 1     188 positive             0.140         0.860 \n## 2     122 negative             0.688         0.312 \n## 3      83 negative             0.912         0.0885\n## 4      76 negative             0.931         0.0686\n## 5     144 positive             0.481         0.519"},{"path":"logistic-models-binary-response.html","id":"exercise-penguins","chapter":"3 Logistic Models – Binary Response","heading":"3.7 Exercise: Penguins","text":"Exercise 3.1  practice bit , ’ll using data set penguins. data palmerpenguins package, included tidymodels. data set contains information penguins Palmer Station Antarctica. Chilly.look plot , comparing bill length (bill_length_mm) three species penguins (species) flipper length (flipper_length_mm).also colouring data based sex (sex) good measure ’re also including information body size (body_mass_g).looks like female penguins smaller different sized bills interesting (yes, !) investigate .like following:load data object called penguins using data(\"penguins\")create logistic model fit data , using sex classifieris bill length important indicator sex?First, load data:already reasonably good idea ’re looking , can never hurt understand data better, :shows columns data set, namely island, indicating island penguins residing bill_depth_mm records bill depth.also notice missing values. good get rid , least rows sex isn’t scored:Next, specify type model. Notice can useful use prefix naming objects indicate data set model belongs . ’re using pgn denote penguins.Remember, setting model specification yet define model . follows:’ve fitted data model, can look model parameters:model parameters tell us intercept coefficient bill_length_mm significantly different zero. seems bill length important predictor sex penguins. knew?!","code":"\ndata(\"penguins\")\nhead(penguins)## # A tibble: 6 × 7\n##   species island bill_length_mm bill_depth_mm flipper_length_… body_mass_g sex  \n##   <fct>   <fct>           <dbl>         <dbl>            <int>       <int> <fct>\n## 1 Adelie  Torge…           39.1          18.7              181        3750 male \n## 2 Adelie  Torge…           39.5          17.4              186        3800 fema…\n## 3 Adelie  Torge…           40.3          18                195        3250 fema…\n## 4 Adelie  Torge…           NA            NA                 NA          NA <NA> \n## 5 Adelie  Torge…           36.7          19.3              193        3450 fema…\n## 6 Adelie  Torge…           39.3          20.6              190        3650 male\npenguins <- penguins %>% \n  filter(!is.na(sex))\npgn_mod <- logistic_reg() %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"glm\")\npgn_fit <- pgn_mod %>% \n  fit(sex ~ bill_length_mm,\n      data = penguins)\npgn_fit %>% tidy()## # A tibble: 2 × 5\n##   term           estimate std.error statistic       p.value\n##   <chr>             <dbl>     <dbl>     <dbl>         <dbl>\n## 1 (Intercept)      -6.04     1.01       -5.96 0.00000000247\n## 2 bill_length_mm    0.138    0.0229      6.02 0.00000000176"},{"path":"logistic-models-binary-response.html","id":"model-evaluation","chapter":"3 Logistic Models – Binary Response","heading":"3.8 Model evaluation","text":"far ’ve constructed logistic model fed new data make predictions possible outcome diabetes test, depending glucose level given patient. gave us diabetes test predictions , importantly, probabilities whether test come back negative positive.question ’d like ask point: reliable model?explore , need take step back.","code":""},{"path":"logistic-models-binary-response.html","id":"split-the-data","chapter":"3 Logistic Models – Binary Response","heading":"3.8.1 Split the data","text":"created model, used data. However, good way assessing model fit actually split data two:training data set use fit modela test data set validate model measure model performanceBefore split data, let’s closer look data set. count many diabetes test results negative positive, see counts evenly split.tidyverseThis can consequences start splitting data training test set. splitting data two parts - data goes training set - data left afterwards can use test good predictions model . However, need make sure proportion negative positive diabetes test outcomes remains roughly .rsample package couple useful functions allow us just can use strata argument keep proportions less constant.can check initial_split() function done:output can see around 75% data set used create training data set, remaining 25% kept test set.Furthermore, proportions negative:positive kept less constant.Although seems bit overkill, now single function can can use prepare recipe train model resulting predictors:creates object called dia_fit, contains final recipe fitted model objects. can extract model recipe objects several helper functions:far, done following:Built model (dia_mod),Created pre-processing recipe (dia_rec),Combined model recipe workflow (dia_wflow)Trained workflow using fit() function (dia_fit)results generated differ much values obtained entire data set. However, based 3/4 data (training data set). , still test data set available apply workflow data model yet seen.can now evaluate model. One way using area ROC curve metric.ROC curve (receiver operating characteristic curve - name strange relic WWII developed operators military radar receivers) plots true-positive rate (TPR) false-positive rate (FPR) varying thresholds.true-positive rate also known sensitivity, whereas false-positive rate 1 - sensitivity (, recall session Power Analysis also known power.)area ROC curve, known AUC provides aggregate measure performance across possible classification thresholds.ranges value 0 1. model whose predictions 100% wrong AUC 0. model whose predictions 100% correct AUC 1.0.addition ROC curve AUC also whole range model parameters associated fitted model. ’re going point, one particular familiar.extract parameters follows:see Akaike Information Criterion (AIC) output. Remember, value AIC meaningless, ’s useful compare relative AICs models. covered Power analysis session Core statistics course.see AIC model uses glucose level single predictor diabetes test result 558.","code":"\ndiabetes %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      478 0.657\n## 2 positive      250 0.343\n# ensures random data split is reproducible\nset.seed(123)\n\n# split the data, basing the proportions on the diabetes test results\ndata_split <- initial_split(diabetes, strata = test_result)\n\n# create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n# proportion of data allocated to the training set\nnrow(train_data) / nrow(diabetes)## [1] 0.7486264\n# proportion of diabetes test results for the training data set\ntrain_data %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      358 0.657\n## 2 positive      187 0.343\n# proportion of diabetes test results for the test data set\ntest_data %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      120 0.656\n## 2 positive       63 0.344\n# Create a recipe\ndia_rec <- \n  recipe(test_result ~ glucose, data = train_data)\n\n# Look at the recipe summary\nsummary(dia_rec)## # A tibble: 2 × 4\n##   variable    type    role      source  \n##   <chr>       <chr>   <chr>     <chr>   \n## 1 glucose     numeric predictor original\n## 2 test_result nominal outcome   original\ndia_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")\ndia_wflow <- \n  workflow() %>% \n  add_model(dia_mod) %>% \n  add_recipe(dia_rec)\n\ndia_wflow## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## 0 Recipe Steps\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## Logistic Regression Model Specification (classification)\n## \n## Computational engine: glm\ndia_fit <- \n  dia_wflow %>% \n  fit(data = train_data)\ndia_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -5.72     0.513       -11.2 6.84e-29\n## 2 glucose       0.0406   0.00397      10.2 1.46e-24\ndia_aug <- \naugment(dia_fit, test_data)\n\ndia_aug## # A tibble: 183 × 6\n##    glucose diastolic test_result .pred_class .pred_negative .pred_positive\n##      <dbl>     <dbl> <fct>       <fct>                <dbl>          <dbl>\n##  1      85        66 negative    negative            0.906          0.0938\n##  2     183        64 positive    positive            0.152          0.848 \n##  3     168        74 positive    positive            0.249          0.751 \n##  4     166        72 positive    positive            0.264          0.736 \n##  5     115        70 positive    negative            0.740          0.260 \n##  6      99        84 negative    negative            0.845          0.155 \n##  7     196        90 positive    positive            0.0959         0.904 \n##  8     119        80 positive    negative            0.708          0.292 \n##  9     143        94 positive    positive            0.478          0.522 \n## 10      97        66 negative    negative            0.856          0.144 \n## # … with 173 more rows\ndia_aug %>% \n  roc_curve(truth = test_result, .pred_negative) %>% \n  autoplot()\ndia_aug %>% \n  roc_auc(truth = test_result, .pred_negative)## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 roc_auc binary         0.766\ndia_fit %>% glance()## # A tibble: 1 × 8\n##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n## 1          701.     544  -277.  558.  567.     554.         543   545"},{"path":"logistic-models-binary-response.html","id":"create-a-recipe","chapter":"3 Logistic Models – Binary Response","heading":"3.8.2 Create a recipe","text":"","code":"\n# Create a recipe\ndia_rec <- \n  recipe(test_result ~ glucose, data = train_data)\n\n# Look at the recipe summary\nsummary(dia_rec)## # A tibble: 2 × 4\n##   variable    type    role      source  \n##   <chr>       <chr>   <chr>     <chr>   \n## 1 glucose     numeric predictor original\n## 2 test_result nominal outcome   original"},{"path":"logistic-models-binary-response.html","id":"build-a-model-specification","chapter":"3 Logistic Models – Binary Response","heading":"3.8.3 Build a model specification","text":"","code":"\ndia_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")"},{"path":"logistic-models-binary-response.html","id":"use-recipe-as-we-train-and-test-our-model","chapter":"3 Logistic Models – Binary Response","heading":"3.8.4 Use recipe as we train and test our model","text":"Although seems bit overkill, now single function can can use prepare recipe train model resulting predictors:creates object called dia_fit, contains final recipe fitted model objects. can extract model recipe objects several helper functions:","code":"\ndia_wflow <- \n  workflow() %>% \n  add_model(dia_mod) %>% \n  add_recipe(dia_rec)\n\ndia_wflow## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## 0 Recipe Steps\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## Logistic Regression Model Specification (classification)\n## \n## Computational engine: glm\ndia_fit <- \n  dia_wflow %>% \n  fit(data = train_data)\ndia_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -5.72     0.513       -11.2 6.84e-29\n## 2 glucose       0.0406   0.00397      10.2 1.46e-24"},{"path":"logistic-models-binary-response.html","id":"use-trained-workflow-for-predictions","chapter":"3 Logistic Models – Binary Response","heading":"3.8.5 Use trained workflow for predictions","text":"far, done following:Built model (dia_mod),Created pre-processing recipe (dia_rec),Combined model recipe workflow (dia_wflow)Trained workflow using fit() function (dia_fit)results generated differ much values obtained entire data set. However, based 3/4 data (training data set). , still test data set available apply workflow data model yet seen.","code":"\ndia_aug <- \naugment(dia_fit, test_data)\n\ndia_aug## # A tibble: 183 × 6\n##    glucose diastolic test_result .pred_class .pred_negative .pred_positive\n##      <dbl>     <dbl> <fct>       <fct>                <dbl>          <dbl>\n##  1      85        66 negative    negative            0.906          0.0938\n##  2     183        64 positive    positive            0.152          0.848 \n##  3     168        74 positive    positive            0.249          0.751 \n##  4     166        72 positive    positive            0.264          0.736 \n##  5     115        70 positive    negative            0.740          0.260 \n##  6      99        84 negative    negative            0.845          0.155 \n##  7     196        90 positive    positive            0.0959         0.904 \n##  8     119        80 positive    negative            0.708          0.292 \n##  9     143        94 positive    positive            0.478          0.522 \n## 10      97        66 negative    negative            0.856          0.144 \n## # … with 173 more rows"},{"path":"logistic-models-binary-response.html","id":"evaluate-the-model","chapter":"3 Logistic Models – Binary Response","heading":"3.8.6 Evaluate the model","text":"can now evaluate model. One way using area ROC curve metric.ROC curve (receiver operating characteristic curve - name strange relic WWII developed operators military radar receivers) plots true-positive rate (TPR) false-positive rate (FPR) varying thresholds.true-positive rate also known sensitivity, whereas false-positive rate 1 - sensitivity (, recall session Power Analysis also known power.)area ROC curve, known AUC provides aggregate measure performance across possible classification thresholds.ranges value 0 1. model whose predictions 100% wrong AUC 0. model whose predictions 100% correct AUC 1.0.addition ROC curve AUC also whole range model parameters associated fitted model. ’re going point, one particular familiar.extract parameters follows:see Akaike Information Criterion (AIC) output. Remember, value AIC meaningless, ’s useful compare relative AICs models. covered Power analysis session Core statistics course.see AIC model uses glucose level single predictor diabetes test result 558.","code":"\ndia_aug %>% \n  roc_curve(truth = test_result, .pred_negative) %>% \n  autoplot()\ndia_aug %>% \n  roc_auc(truth = test_result, .pred_negative)## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 roc_auc binary         0.766\ndia_fit %>% glance()## # A tibble: 1 × 8\n##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n## 1          701.     544  -277.  558.  567.     554.         543   545"},{"path":"logistic-models-binary-response.html","id":"exercise-diabetes-predictors","chapter":"3 Logistic Models – Binary Response","heading":"3.9 Exercise: Diabetes predictors","text":"Exercise 3.2  Using training test diabetes data sets, investigate relationship test_result glucose diastolic. Try answer following:adding diastolic model markedly improve reliability predictions?AICs two models tell ?Build model, needed (done already stays ):Create workflow…… fit data:Extract model parameters look:Apply fitted model test data set:Plot ROC curve:get area ROC curve:Another way assess model fit look Akaike Information Criterion (AIC).get AIC 555, lower AIC 558 got just glucose predictor variable.Adding diastolic variable predictor model seem much effect model reliability, since AUC 0.761 extra parameter, versus 0.766 without.AIC hand suggests additive model ’ve analysed better fit original model (AIC 555 vs 558).Perhaps interaction glucose diastolic, interesting investigate.","code":"\n# Update the recipe\ndia_rec <- \n  recipe(test_result ~ glucose + diastolic,\n         data = train_data)\n\n# Look at the recipe summary\nsummary(dia_rec)## # A tibble: 3 × 4\n##   variable    type    role      source  \n##   <chr>       <chr>   <chr>     <chr>   \n## 1 glucose     numeric predictor original\n## 2 diastolic   numeric predictor original\n## 3 test_result nominal outcome   original\ndia_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")\ndia_wflow <- \n  workflow() %>% \n  add_model(dia_mod) %>% \n  add_recipe(dia_rec)\ndia_fit <- \n  dia_wflow %>% \n  fit(data = train_data)\ndia_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()## # A tibble: 3 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -6.99     0.790       -8.85 8.60e-19\n## 2 glucose       0.0394   0.00398      9.88 5.19e-23\n## 3 diastolic     0.0195   0.00877      2.22 2.61e- 2\ndia_aug <- \naugment(dia_fit, test_data)\n\ndia_aug## # A tibble: 183 × 6\n##    glucose diastolic test_result .pred_class .pred_negative .pred_positive\n##      <dbl>     <dbl> <fct>       <fct>                <dbl>          <dbl>\n##  1      85        66 negative    negative            0.914          0.0862\n##  2     183        64 positive    positive            0.189          0.811 \n##  3     168        74 positive    positive            0.257          0.743 \n##  4     166        72 positive    positive            0.280          0.720 \n##  5     115        70 positive    negative            0.751          0.249 \n##  6      99        84 negative    negative            0.811          0.189 \n##  7     196        90 positive    positive            0.0776         0.922 \n##  8     119        80 positive    negative            0.679          0.321 \n##  9     143        94 positive    positive            0.385          0.615 \n## 10      97        66 negative    negative            0.869          0.131 \n## # … with 173 more rows\ndia_aug %>% \n  roc_curve(truth = test_result, .pred_negative) %>% \n  autoplot()\ndia_aug %>% \n  roc_auc(truth = test_result, .pred_negative)## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 roc_auc binary         0.761\ndia_fit %>% glance()## # A tibble: 1 × 8\n##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n## 1          701.     544  -275.  555.  568.     549.         542   545"},{"path":"logistic-models-binary-response.html","id":"conclusions","chapter":"3 Logistic Models – Binary Response","heading":"3.9.0.1 Conclusions","text":"Adding diastolic variable predictor model seem much effect model reliability, since AUC 0.761 extra parameter, versus 0.766 without.AIC hand suggests additive model ’ve analysed better fit original model (AIC 555 vs 558).","code":""},{"path":"logistic-models-binary-response.html","id":"food-for-thought","chapter":"3 Logistic Models – Binary Response","heading":"3.9.0.2 Food for thought","text":"Perhaps interaction glucose diastolic, interesting investigate.","code":""},{"path":"logistic-models-binary-response.html","id":"key-points","chapter":"3 Logistic Models – Binary Response","heading":"3.10 Key points","text":"use logistic regression model binary responseModel suitability can checked splitting data training test data set. logistic model created based training data, reliability can checked (known) values test data setThe ROC curve shows performance classification model thresholds, whereas area ROC curve provides aggregate measure performance possible classifications thresholds.panelset{--panel-tab-font-family: inherit;}","code":"## Registered S3 method overwritten by 'tune':\n##   method                   from   \n##   required_pkgs.model_spec parsnip## ── Attaching packages ────────────────────────────────────── tidymodels 0.1.4 ──## ✓ dials        0.1.0     ✓ rsample      0.1.1\n## ✓ infer        1.0.0     ✓ tune         0.1.6\n## ✓ modeldata    0.1.1     ✓ workflows    0.2.4\n## ✓ parsnip      0.2.0     ✓ workflowsets 0.1.0\n## ✓ recipes      0.2.0     ✓ yardstick    0.0.9## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n## x scales::discard() masks purrr::discard()\n## x dplyr::filter()   masks stats::filter()\n## x recipes::fixed()  masks stringr::fixed()\n## x dplyr::lag()      masks stats::lag()\n## x yardstick::spec() masks readr::spec()\n## x recipes::step()   masks stats::step()\n## x tune::tune()      masks parsnip::tune()\n## • Dig deeper into tidy modeling with R at https://www.tmwr.org## Warning: 'xaringanExtra::style_panelset' is deprecated.\n## Use 'style_panelset_tabs' instead.\n## See help(\"Deprecated\")"},{},{"path":"logistic-regression---proportion-response.html","id":"logistic-regression---proportion-response","chapter":"4 Logistic regression - proportion response","heading":"4 Logistic regression - proportion response","text":"","code":""},{"path":"logistic-regression---proportion-response.html","id":"objectives-2","chapter":"4 Logistic regression - proportion response","heading":"4.1 Objectives","text":"QuestionsHow analyse proportion responses?ObjectivesBe able create logistic model test proportion response variablesBe able plot data fitted curveAssess significance fit","code":""},{"path":"logistic-regression---proportion-response.html","id":"libraries-and-functions-1","chapter":"4 Logistic regression - proportion response","heading":"4.2 Libraries and functions","text":"tidyverse","code":""},{"path":"logistic-regression---proportion-response.html","id":"datasets-1","chapter":"4 Logistic regression - proportion response","heading":"4.3 Datasets","text":"DiabetesThe example section uses following data set:data/challenger.csvThese data, obtained faraway package, contain information related explosion USA Space Shuttle Challenger 28 January, 1986. investigation disaster traced back certain joints one two solid booster rockets, containing two O-rings (primary secondary) ensured exhaust gases escape booster.night launch unusually cold, temperatures freezing. final report suggested cold snap night made o-rings stiff, unable adjust changes pressure. result, exhaust gases leaked away solid booster rockets, causing one break loose rupture main fuel tank, leading final explosion.question ’re trying answer session : based data previous flights, possible predict failure o-rings Challenger flight?","code":""},{"path":"logistic-regression---proportion-response.html","id":"visualise-the-data-1","chapter":"4 Logistic regression - proportion response","heading":"4.4 Visualise the data","text":"First, read data:tidyverseThe data set contains several columns:temp, launch temperature degrees Fahrenheitdamage, number o-rings showed erosionBefore look data, let’s calculate proportion damaged o-rings (prop_damaged) total number o-rings (total) update data set.tidyversePlotting proportion damaged o-rings launch temperature shows following picture:tidyverseThe point left data point corresponding coldest flight experienced disaster, five damaged o-rings found. Fortunately, result disaster.’ll explore predicted failure o-rings Challenger flight, launch temperature 31 degrees Fahrenheit.","code":"\nchallenger <- read_csv(\"data/challenger.csv\")## Rows: 23 Columns: 2\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## dbl (2): temp, damage\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nchallenger## # A tibble: 23 × 2\n##     temp damage\n##    <dbl>  <dbl>\n##  1    53      5\n##  2    57      1\n##  3    58      1\n##  4    63      1\n##  5    66      0\n##  6    67      0\n##  7    67      0\n##  8    67      0\n##  9    68      0\n## 10    69      0\n## # … with 13 more rows\nchallenger <-\nchallenger %>%\n  mutate(total = 6,                     # total number of o-rings\n         intact = 6 - damage,           # number of undamaged o-rings\n         prop_damaged = damage / total) # proportion damaged o-rings\n\nchallenger## # A tibble: 23 × 5\n##     temp damage total intact prop_damaged\n##    <dbl>  <dbl> <dbl>  <dbl>        <dbl>\n##  1    53      5     6      1        0.833\n##  2    57      1     6      5        0.167\n##  3    58      1     6      5        0.167\n##  4    63      1     6      5        0.167\n##  5    66      0     6      6        0    \n##  6    67      0     6      6        0    \n##  7    67      0     6      6        0    \n##  8    67      0     6      6        0    \n##  9    68      0     6      6        0    \n## 10    69      0     6      6        0    \n## # … with 13 more rows\nggplot(challenger, aes(x = temp, y = prop_damaged)) +\n  geom_point()"},{"path":"logistic-regression---proportion-response.html","id":"model-building-1","chapter":"4 Logistic regression - proportion response","heading":"4.5 Model building","text":"little point evaluating model using training/test data set, since 23 data points total. ’re building model testing available data.tidyverse\nusing logistic regression proportion response case, since ’re interested proportion o-rings damaged.logistic_reg() function used binary response section work , expects binary (yes/; positive/negative; 0/1 etc) response.deal , using standard linear_reg() function, still using glm generalised linear model engine, family error distribution set binomial ().First set model specification:fit data. Fitting data proportion responses bit annoying, give glm model two-column matrix specify response variable., first column corresponds number damaged o-rings, whereas second column refers number intact o-rings. use cbind() function bind two together matrix.Next, can closer look results:can see p-values intercept temp significant. can also use intercept temp coefficients construct logistic equation, can use sketch logistic curve.\\[\\begin{equation}\nP(o-ring \\ failure) = \\frac{1}{1 + {e}^{-(11.66 -  0.22 \\cdot temp)}}\n\\end{equation}\\]Let’s see well model performed fed data ill-fated Challenger launch.First generate table data range temperatures, 25 85 degrees Fahrenheit, steps 1. can use data generate logistic curve, based fitted model.seems high probability o-rings failing launch temperature. One thing graph shows lot uncertainty involved model.","code":"\nchl_mod <- linear_reg(mode = \"regression\") %>%\n  set_engine(\"glm\", family = \"binomial\")\nchl_fit <- chl_mod %>% \n  fit(cbind(damage, intact) ~ temp,\n      data = challenger)\nchl_fit %>% tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic   p.value\n##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n## 1 (Intercept)   11.7      3.30        3.54 0.000403 \n## 2 temp          -0.216    0.0532     -4.07 0.0000478\nmodel <- tibble(temp = seq(25, 85, 1))\n# get the predicted proportions for the curve\ncurve <- chl_fit %>% augment(new_data = model)\n\n# plot the curve and the original data\nggplot(curve, aes(temp, .pred)) +\n  geom_line(colour = \"red\") +\n  geom_point(data = challenger, aes(temp, prop_damaged)) +\n  # add a vertical line at the disaster launch temperature\n  geom_vline(xintercept = 31, linetype = \"dashed\")"},{"path":"logistic-regression---proportion-response.html","id":"exercise","chapter":"4 Logistic regression - proportion response","heading":"4.6 Exercise","text":"Exercise 4.1  data point 53 degrees Fahrenheit quite influential analysis. Remove data point repeat analysis. still predicted link launch temperature o-ring failure?tidyverseFirst, need remove influential data point:can reuse model specification, update fit:prediction proportion damaged o-rings markedly less scenario, failure rate around 80%. original fitted curve already quite uncertainty associated , uncertainty model much greater.","code":"\nchallenger_new <- challenger %>% filter(temp != 53)\nchl_new_fit <- chl_mod %>% \n  fit(cbind(damage, intact) ~ temp,\n      data = challenger_new)\n# get the predicted proportions for the curve\ncurve_new <- chl_new_fit %>% augment(new_data = model)\n\n# plot the curve and the original data\nggplot(curve_new, aes(temp, .pred)) +\n  geom_line(colour = \"red\") +\n  geom_point(data = challenger_new, aes(temp, prop_damaged)) +\n  # add a vertical line at the disaster launch temperature\n  geom_vline(xintercept = 31, linetype = \"dashed\")"},{"path":"logistic-regression---proportion-response.html","id":"key-points-1","chapter":"4 Logistic regression - proportion response","heading":"4.7 Key points","text":"can use logistic model proportion response variables","code":""}]
