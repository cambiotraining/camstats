[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"sessions intended enable perform additional data analysis techniques appropriately confidently using R Python.Ongoing formative assessment exercisesOngoing formative assessment exercisesNo formal assessmentNo formal assessmentNo mathematical derivationsNo mathematical derivationsNo pen paper calculationsNo pen paper calculationsThey “mindlessly use stats program” course!","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.1 Core aims","text":"know presented non-standard dataset e.g.Know deal non-normal dataKnow analyse count dataBe able deal random effects","code":""},{"path":"index.html","id":"core-topics","chapter":"1 Overview","heading":"1.2 Core topics","text":"Generalised linear models","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.3 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder right-clicking link Save …. Next unzip file copy working directory. data accessible via <working-directory-name>/data..panelset{--panel-tab-font-family: inherit;}","code":"## Registered S3 method overwritten by 'tune':\n##   method                   from   \n##   required_pkgs.model_spec parsnip## ── Attaching packages ────────────────────────────────────── tidymodels 0.1.4 ──## ✓ dials        0.1.0     ✓ rsample      0.1.1\n## ✓ infer        1.0.0     ✓ tune         0.1.6\n## ✓ modeldata    0.1.1     ✓ workflows    0.2.4\n## ✓ parsnip      0.2.0     ✓ workflowsets 0.1.0\n## ✓ recipes      0.2.0     ✓ yardstick    0.0.9## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n## x scales::discard() masks purrr::discard()\n## x dplyr::filter()   masks stats::filter()\n## x recipes::fixed()  masks stringr::fixed()\n## x dplyr::lag()      masks stats::lag()\n## x yardstick::spec() masks readr::spec()\n## x recipes::step()   masks stats::step()\n## x tune::tune()      masks parsnip::tune()\n## • Dig deeper into tidy modeling with R at https://www.tmwr.org## Warning: 'xaringanExtra::style_panelset' is deprecated.\n## Use 'style_panelset_tabs' instead.\n## See help(\"Deprecated\")"},{},{"path":"logistic-models-binary-response.html","id":"logistic-models-binary-response","chapter":"2 Logistic Models – Binary Response","heading":"2 Logistic Models – Binary Response","text":"","code":""},{"path":"logistic-models-binary-response.html","id":"objectives","chapter":"2 Logistic Models – Binary Response","heading":"2.1 Objectives","text":"QuestionsObjectives","code":""},{"path":"logistic-models-binary-response.html","id":"libraries-and-functions","chapter":"2 Logistic Models – Binary Response","heading":"2.2 Libraries and functions","text":"tidyverse","code":""},{"path":"logistic-models-binary-response.html","id":"datasets","chapter":"2 Logistic Models – Binary Response","heading":"2.3 Datasets","text":"DiabetesThe example section uses following data set:data/diabetes.csvThis data set comprising 768 observations three variables (one dependent two predictor variables). records results diabetes test result binary variable (1 positive result, 0 negative result), along result glucose test diastolic blood pressure 767 women. variables called test_result, glucose diastolic.","code":""},{"path":"logistic-models-binary-response.html","id":"visualise-the-data","chapter":"2 Logistic Models – Binary Response","heading":"2.4 Visualise the data","text":"First load data, visualise . needed, load tidyverse package using:tidyverse\nFirst, load inspect data:Looking data, can see test_result column contains zeros ones. test result outcomes actually numeric representations.cause problems later, need tell R see values factors. good measure ’ll also improve information test_result classifying ‘negative’ (0) ‘positive’ (1).can plot data:looks though patients positive diabetes test slightly higher glucose levels negative diabetes test.can visualise differently plotting data points classic binary response plot:","code":"\ndiabetes <- read_csv(\"data/diabetes.csv\")\ndiabetes <- \ndiabetes %>% \n  # replace 0 with 'negative' and 1 with 'positive'\n  mutate(test_result = case_when(test_result == 0 ~ \"negative\",\n                                 TRUE ~ \"positive\")) %>% \n  # convert character columns to factor\n  mutate_if(is.character, factor)\ndiabetes %>% \n  ggplot(aes(x = test_result, y = glucose)) +\n  geom_boxplot()\ndiabetes %>% \n  ggplot(aes(x = glucose, y = test_result)) +\n  geom_point()"},{"path":"logistic-models-binary-response.html","id":"construct-the-model","chapter":"2 Logistic Models – Binary Response","heading":"2.5 Construct the model","text":"different ways construct logistic model.tidyverseIn tidymodels access useful package: parsnip, provides common syntax whole range modelling libraries. means syntax stay different kind model comparisons. , learning curve might bit steeper start , pay dividend long-term (just like started using R!).First, need load tidymodels (install first, needed):workflow parsnip bit different ’re used far. now, ’ve directly used relevant model functions analyse data, example using lm() function create linear models.Using parsnip approach things systematic manner. first might seem unnecessarily verbose, clear advantages approaching analysis systematic way. example, straightforward implement types models using workflow, ’ll definitely find useful moving difficult modelling tasks.Using tidymodels specify model three steps:Specify type model based mathematical structure (e.g., linear regression, random forest, K-nearest neighbors, etc).required, declare mode model. mode reflects type prediction outcome. numeric outcomes, mode regression; qualitative outcomes, classification. model can create one type model, logistic regression, mode already set.Specify engine fitting model. usually software package library used., can create model follows:Note actually specifying variables just yet! ’ve done tell R kind model ’re planning use. want see parsnip converts code package syntax, can check translate():shows logistic regression model, outcome going classification (case, ’s positive negative test result). model fit template tells us ’ll using glm() function stats package, can take formula, data, weights family argument. family argument already set binomial.Now ’ve specified kind model ’re planning use, can fit data , using fit() function:can look output directly, prefer tidy data using tidy() function broom package:estimate column gives coefficients logistic model equation. use calculate probability positive diabetes test, given glucose level, using following equation:\\[\\begin{equation}\nP(positive \\ test_result) = \\frac{1}{1 + {e}^{-(-5.61 +  0.040 \\cdot glucose)}}\n\\end{equation}\\]course ’re going way. ’ll let R deal next section.std.error column gives error associated coefficients statistic column tells statistic value.values p.value merely show whether particular coefficient significantly different zero. similar p-values obtained summary output linear model, , continuous predictors p-values can used rough guide whether predictor important (case glucose appears significant). However, p-values aren’t great multiple predictor variables, categorical predictors multiple levels (since output give us p-value level rather predictor whole).","code":"\n# install.packages(\"tidymodels\")\nlibrary(tidymodels)\ndia_mod <- logistic_reg() %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"glm\")\ndia_mod %>% translate()## Logistic Regression Model Specification (classification)\n## \n## Computational engine: glm \n## \n## Model fit template:\n## stats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n##     family = stats::binomial)\ndia_fit <- dia_mod %>% \n  fit(test_result ~ glucose,\n      data = diabetes)\ndia_fit %>% tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -5.61     0.442       -12.7 6.90e-37\n## 2 glucose       0.0395   0.00340      11.6 2.96e-31"},{"path":"logistic-models-binary-response.html","id":"using-the-model-to-make-predictions","chapter":"2 Logistic Models – Binary Response","heading":"2.6 Using the model to make predictions","text":"got new glucose level data wanted predict people might diabetes ?use existing model feed data:tidyverseAlthough able get predicted outcomes (.pred_class), like stress point running model. important realise model (statistical models) creates predicted outcome based certain probabilities. therefore much informative look probable predicted outcomes . encoded .pred_negative .pred_positive.first value means 14% chance diabetes test return negative result around 86% chance return positive result.","code":"\n# create a dummy data set using some hypothetical glucose measurements\ndiabetes_newdata <- tibble(glucose = c(188, 122, 83, 76, 144))\n\n# predict if the patients have diabetes or not\naugment(dia_fit,\n        new_data = diabetes_newdata)## # A tibble: 5 × 4\n##   glucose .pred_class .pred_negative .pred_positive\n##     <dbl> <fct>                <dbl>          <dbl>\n## 1     188 positive             0.140         0.860 \n## 2     122 negative             0.688         0.312 \n## 3      83 negative             0.912         0.0885\n## 4      76 negative             0.931         0.0686\n## 5     144 positive             0.481         0.519"},{"path":"logistic-models-binary-response.html","id":"model-evaluation","chapter":"2 Logistic Models – Binary Response","heading":"2.7 Model evaluation","text":"far ’ve constructed logistic model fed new data make predictions possible outcome diabetes test, depending glucose level given patient. gave us diabetes test predictions , importantly, probabilities whether test come back negative positive.question ’d like ask point: reliable model?explore , need take step back.tidyverseWhen created model, used data. However, good way assessing model fit actually split data two:training data set use fit modela test data set validate model measure model performanceBefore split data, let’s closer look data set. count many diabetes test results negative (0) positive (1), see counts evenly split.can consequences start splitting data training test set. splitting data two parts - data goes training set - data left afterwards can use test good predictions model . However, need make sure proportion negative positive diabetes test outcomes remains roughly .rsample package couple useful functions allow us just can use strata argument keep proportions less .can check initial_split() function done:output can see around 75% data set used create training data set, remaining 25% kept test set.Furthermore, proportions negative:positive kept less constant.Although seems bit overkill, now single function can can use prepare recipe train model resulting predictors:creates object called dia_fit, contains final recipe fitted model objects. can extract model recipe objects several helper functions:far, done following:Built model (dia_mod),Created pre-processing recipe (dia_rec),Combined model recipe workflow (dia_wflow)Trained workflow using fit() function (dia_fit)results generated differ much values obtained entire data set. However, based 3/4 data (training data set). , still test data set available apply workflow data model yet seen.can now evaluate model. One way using area ROC curve metric.","code":"\ndiabetes %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      478 0.657\n## 2 positive      250 0.343\n# Use 75% of the data to create the training data set\ndata_split <- initial_split(diabetes, strata = test_result)\n\n# Create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n# proportion of data allocated to the training set\nnrow(train_data) / nrow(diabetes)## [1] 0.7486264\n# proportion of diabetes test results for the training and test data sets\ntrain_data %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      358 0.657\n## 2 positive      187 0.343\ntest_data %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      120 0.656\n## 2 positive       63 0.344\n# Create a recipe\ndia_rec <- \n  recipe(test_result ~ ., data = train_data)\n\n# Look at the recipe summary\nsummary(dia_rec)## # A tibble: 3 × 4\n##   variable    type    role      source  \n##   <chr>       <chr>   <chr>     <chr>   \n## 1 glucose     numeric predictor original\n## 2 diastolic   numeric predictor original\n## 3 test_result nominal outcome   original\ndia_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")\ndia_wflow <- \n  workflow() %>% \n  add_model(dia_mod) %>% \n  add_recipe(dia_rec)\n\ndia_wflow## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## 0 Recipe Steps\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## Logistic Regression Model Specification (classification)\n## \n## Computational engine: glm\ndia_fit <- \n  dia_wflow %>% \n  fit(data = train_data)\ndia_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()## # A tibble: 3 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -7.13     0.782       -9.12 7.61e-20\n## 2 glucose       0.0378   0.00388      9.72 2.41e-22\n## 3 diastolic     0.0240   0.00872      2.75 6.03e- 3\ndia_aug <- \naugment(dia_fit, test_data)\n\ndia_aug## # A tibble: 183 × 6\n##    glucose diastolic test_result .pred_class .pred_negative .pred_positive\n##      <dbl>     <dbl> <fct>       <fct>                <dbl>          <dbl>\n##  1     137        40 positive    negative            0.731           0.269\n##  2     197        70 positive    positive            0.121           0.879\n##  3     110        92 negative    negative            0.685           0.315\n##  4     115        70 positive    negative            0.753           0.247\n##  5     196        90 positive    positive            0.0813          0.919\n##  6      97        66 negative    negative            0.869           0.131\n##  7     138        76 negative    negative            0.525           0.475\n##  8     111        72 positive    negative            0.771           0.229\n##  9     103        66 positive    negative            0.841           0.159\n## 10     187        68 positive    positive            0.174           0.826\n## # … with 173 more rows\ndia_aug %>% \n  roc_curve(truth = test_result, .pred_negative) %>% \n  autoplot()\ndia_aug %>% \n  filter(test_result == .pred_class) %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      102 0.761\n## 2 positive       32 0.239\ndia_aug %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      120 0.656\n## 2 positive       63 0.344\ndia_aug %>% \n  roc_auc(truth = test_result, .pred_negative)## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 roc_auc binary         0.761"},{"path":"logistic-models-binary-response.html","id":"split-the-data","chapter":"2 Logistic Models – Binary Response","heading":"2.7.1 Split the data","text":"created model, used data. However, good way assessing model fit actually split data two:training data set use fit modela test data set validate model measure model performanceBefore split data, let’s closer look data set. count many diabetes test results negative (0) positive (1), see counts evenly split.can consequences start splitting data training test set. splitting data two parts - data goes training set - data left afterwards can use test good predictions model . However, need make sure proportion negative positive diabetes test outcomes remains roughly .rsample package couple useful functions allow us just can use strata argument keep proportions less .can check initial_split() function done:output can see around 75% data set used create training data set, remaining 25% kept test set.Furthermore, proportions negative:positive kept less constant.","code":"\ndiabetes %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      478 0.657\n## 2 positive      250 0.343\n# Use 75% of the data to create the training data set\ndata_split <- initial_split(diabetes, strata = test_result)\n\n# Create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n# proportion of data allocated to the training set\nnrow(train_data) / nrow(diabetes)## [1] 0.7486264\n# proportion of diabetes test results for the training and test data sets\ntrain_data %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      358 0.657\n## 2 positive      187 0.343\ntest_data %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      120 0.656\n## 2 positive       63 0.344"},{"path":"logistic-models-binary-response.html","id":"create-a-recipe","chapter":"2 Logistic Models – Binary Response","heading":"2.7.2 Create a recipe","text":"","code":"\n# Create a recipe\ndia_rec <- \n  recipe(test_result ~ ., data = train_data)\n\n# Look at the recipe summary\nsummary(dia_rec)## # A tibble: 3 × 4\n##   variable    type    role      source  \n##   <chr>       <chr>   <chr>     <chr>   \n## 1 glucose     numeric predictor original\n## 2 diastolic   numeric predictor original\n## 3 test_result nominal outcome   original"},{"path":"logistic-models-binary-response.html","id":"build-a-model-specification","chapter":"2 Logistic Models – Binary Response","heading":"2.7.3 Build a model specification","text":"","code":"\ndia_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")"},{"path":"logistic-models-binary-response.html","id":"use-recipe-as-we-train-and-test-our-model","chapter":"2 Logistic Models – Binary Response","heading":"2.7.4 Use recipe as we train and test our model","text":"Although seems bit overkill, now single function can can use prepare recipe train model resulting predictors:creates object called dia_fit, contains final recipe fitted model objects. can extract model recipe objects several helper functions:","code":"\ndia_wflow <- \n  workflow() %>% \n  add_model(dia_mod) %>% \n  add_recipe(dia_rec)\n\ndia_wflow## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## 0 Recipe Steps\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## Logistic Regression Model Specification (classification)\n## \n## Computational engine: glm\ndia_fit <- \n  dia_wflow %>% \n  fit(data = train_data)\ndia_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()## # A tibble: 3 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -7.13     0.782       -9.12 7.61e-20\n## 2 glucose       0.0378   0.00388      9.72 2.41e-22\n## 3 diastolic     0.0240   0.00872      2.75 6.03e- 3"},{"path":"logistic-models-binary-response.html","id":"use-trained-workflow-for-predictions","chapter":"2 Logistic Models – Binary Response","heading":"2.7.5 Use trained workflow for predictions","text":"far, done following:Built model (dia_mod),Created pre-processing recipe (dia_rec),Combined model recipe workflow (dia_wflow)Trained workflow using fit() function (dia_fit)results generated differ much values obtained entire data set. However, based 3/4 data (training data set). , still test data set available apply workflow data model yet seen.","code":"\ndia_aug <- \naugment(dia_fit, test_data)\n\ndia_aug## # A tibble: 183 × 6\n##    glucose diastolic test_result .pred_class .pred_negative .pred_positive\n##      <dbl>     <dbl> <fct>       <fct>                <dbl>          <dbl>\n##  1     137        40 positive    negative            0.731           0.269\n##  2     197        70 positive    positive            0.121           0.879\n##  3     110        92 negative    negative            0.685           0.315\n##  4     115        70 positive    negative            0.753           0.247\n##  5     196        90 positive    positive            0.0813          0.919\n##  6      97        66 negative    negative            0.869           0.131\n##  7     138        76 negative    negative            0.525           0.475\n##  8     111        72 positive    negative            0.771           0.229\n##  9     103        66 positive    negative            0.841           0.159\n## 10     187        68 positive    positive            0.174           0.826\n## # … with 173 more rows"},{"path":"logistic-models-binary-response.html","id":"evaluate-the-model","chapter":"2 Logistic Models – Binary Response","heading":"2.7.6 Evaluate the model","text":"can now evaluate model. One way using area ROC curve metric.","code":"\ndia_aug %>% \n  roc_curve(truth = test_result, .pred_negative) %>% \n  autoplot()\ndia_aug %>% \n  filter(test_result == .pred_class) %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      102 0.761\n## 2 positive       32 0.239\ndia_aug %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      120 0.656\n## 2 positive       63 0.344\ndia_aug %>% \n  roc_auc(truth = test_result, .pred_negative)## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 roc_auc binary         0.761"},{"path":"logistic-models-binary-response.html","id":"exercise","chapter":"2 Logistic Models – Binary Response","heading":"2.8 Exercise","text":"Exercise 2.1  can add exercises","code":""},{"path":"logistic-models-binary-response.html","id":"key-points","chapter":"2 Logistic Models – Binary Response","heading":"2.9 Key points","text":"Adding key points","code":""}]
