[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"sessions intended enable perform additional data analysis techniques appropriately confidently using R Python.Ongoing formative assessment exercisesOngoing formative assessment exercisesNo formal assessmentNo formal assessmentNo mathematical derivationsNo mathematical derivationsNo pen paper calculationsNo pen paper calculationsThey “mindlessly use stats program” course!","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.1 Core aims","text":"know presented non-standard dataset e.g.Know deal non-normal dataKnow analyse count dataBe able deal random effects","code":""},{"path":"index.html","id":"core-topics","chapter":"1 Overview","heading":"1.2 Core topics","text":"Generalised linear models","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.3 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder right-clicking link Save …. Next unzip file copy working directory. data accessible via <working-directory-name>/data.","code":""},{},{"path":"glm-intro.html","id":"glm-intro","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"glm-intro.html","id":"objectives","chapter":"2 Introduction","heading":"2.1 Objectives","text":"Aim: introduce R commands analysing data non-continuous response variables.end practical participants able achieve following:Construct\nlogistic model binary response variables\nlogistic model proportion response variables\nPoisson model count response variables\nNegative Binomial model count response variables\nlogistic model binary response variablesa logistic model proportion response variablesa Poisson model count response variablesa Negative Binomial model count response variablesPlot data fitted curve case continuous categorical predictorsAssess significance fitAssess assumption model","code":""},{"path":"glm-intro.html","id":"background","chapter":"2 Introduction","heading":"2.2 Background","text":"practical divided sections considers sort response variable generalised linear model turn. Within section least one example modelling process followed example..panelset{--panel-tab-font-family: inherit;}","code":""},{},{"path":"logistic-models-binary-response.html","id":"logistic-models-binary-response","chapter":"3 Logistic Models – Binary Response","heading":"3 Logistic Models – Binary Response","text":"","code":""},{"path":"logistic-models-binary-response.html","id":"objectives-1","chapter":"3 Logistic Models – Binary Response","heading":"3.1 Objectives","text":"QuestionsHow analyse data binary outcome?Can test model good?ObjectivesBe able perform logistic regression binary outcomePredict outcomes new data, based defined modelEvaluate model reliability using training test data sets","code":""},{"path":"logistic-models-binary-response.html","id":"libraries-and-functions","chapter":"3 Logistic Models – Binary Response","heading":"3.2 Libraries and functions","text":"tidyverse","code":""},{"path":"logistic-models-binary-response.html","id":"datasets","chapter":"3 Logistic Models – Binary Response","heading":"3.3 Datasets","text":"DiabetesThe example section uses following data set:data/diabetes.csvThis data set comprising 768 observations three variables (one dependent two predictor variables). records results diabetes test result binary variable (1 positive result, 0 negative result), along result glucose test diastolic blood pressure 767 women. variables called test_result, glucose diastolic.","code":""},{"path":"logistic-models-binary-response.html","id":"visualise-the-data","chapter":"3 Logistic Models – Binary Response","heading":"3.4 Visualise the data","text":"First load data, visualise .tidyverse\nFirst, load inspect data:Looking data, can see test_result column contains zeros ones. test result outcomes actually numeric representations.cause problems later, need tell R see values factors. good measure ’ll also improve information test_result classifying ‘negative’ (0) ‘positive’ (1).can plot data:looks though patients positive diabetes test slightly higher glucose levels negative diabetes test.can visualise differently plotting data points classic binary response plot:","code":"\ndiabetes <- read_csv(\"data/diabetes.csv\")\ndiabetes <- \ndiabetes %>% \n  # replace 0 with 'negative' and 1 with 'positive'\n  mutate(test_result = case_when(test_result == 0 ~ \"negative\",\n                                 TRUE ~ \"positive\")) %>% \n  # convert character columns to factor\n  mutate_if(is.character, factor)\ndiabetes %>% \n  ggplot(aes(x = test_result, y = glucose)) +\n  geom_boxplot()\ndiabetes %>% \n  ggplot(aes(x = glucose, y = test_result)) +\n  geom_point()"},{"path":"logistic-models-binary-response.html","id":"model-building","chapter":"3 Logistic Models – Binary Response","heading":"3.5 Model building","text":"different ways construct logistic model.tidyverseIn tidymodels access useful package: parsnip, provides common syntax whole range modelling libraries. means syntax stay different kind model comparisons. , learning curve might bit steeper start , pay dividend long-term (just like started using R!).First, need load tidymodels (install first, needed):workflow parsnip bit different ’re used far. now, ’ve directly used relevant model functions analyse data, example using lm() function create linear models.Using parsnip approach things systematic manner. first might seem unnecessarily verbose, clear advantages approaching analysis systematic way. example, straightforward implement types models using workflow, ’ll definitely find useful moving difficult modelling tasks.Using tidymodels specify model three steps:Specify type model based mathematical structure (e.g., linear regression, random forest, K-nearest neighbors, etc).required, declare mode model. mode reflects type prediction outcome. numeric outcomes, mode regression; qualitative outcomes, classification. model can create one type model, logistic regression, mode already set.Specify engine fitting model. usually software package library used., can create model follows:Note actually specifying variables just yet! ’ve done tell R kind model ’re planning use. want see parsnip converts code package syntax, can check translate():shows logistic regression model, outcome going classification (case, ’s positive negative test result). model fit template tells us ’ll using glm() function stats package, can take formula, data, weights family argument. family argument already set binomial.Now ’ve specified kind model ’re planning use, can fit data , using fit() function:can look output directly, prefer tidy data using tidy() function broom package:estimate column gives coefficients logistic model equation. use calculate probability positive diabetes test, given glucose level, using following equation:\\[\\begin{equation}\nP(positive \\ test \\ result) = \\frac{1}{1 + {e}^{-(-5.61 +  0.040 \\cdot glucose)}}\n\\end{equation}\\]course ’re going way. ’ll let R deal next section.std.error column gives error associated coefficients statistic column tells statistic value.values p.value merely show whether particular coefficient significantly different zero. similar p-values obtained summary output linear model, , continuous predictors p-values can used rough guide whether predictor important (case glucose appears significant). However, p-values aren’t great multiple predictor variables, categorical predictors multiple levels (since output give us p-value level rather predictor whole).","code":"\n# install.packages(\"tidymodels\")\nlibrary(tidymodels)\ndia_mod <- logistic_reg() %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"glm\")\ndia_mod %>% translate()## Logistic Regression Model Specification (classification)\n## \n## Computational engine: glm \n## \n## Model fit template:\n## stats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n##     family = stats::binomial)\ndia_fit <- dia_mod %>% \n  fit(test_result ~ glucose,\n      data = diabetes)\ndia_fit %>% tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -5.61     0.442       -12.7 6.90e-37\n## 2 glucose       0.0395   0.00340      11.6 2.96e-31"},{"path":"logistic-models-binary-response.html","id":"model-predictions","chapter":"3 Logistic Models – Binary Response","heading":"3.6 Model predictions","text":"got new glucose level data wanted predict people might diabetes ?use existing model feed data:tidyverseAlthough able get predicted outcomes (.pred_class), like stress point running model. important realise model (statistical models) creates predicted outcome based certain probabilities. therefore much informative look probable predicted outcomes . encoded .pred_negative .pred_positive.first value means 14% chance diabetes test return negative result around 86% chance return positive result.","code":"\n# create a dummy data set using some hypothetical glucose measurements\ndiabetes_newdata <- tibble(glucose = c(188, 122, 83, 76, 144))\n\n# predict if the patients have diabetes or not\naugment(dia_fit,\n        new_data = diabetes_newdata)## # A tibble: 5 × 4\n##   glucose .pred_class .pred_negative .pred_positive\n##     <dbl> <fct>                <dbl>          <dbl>\n## 1     188 positive             0.140         0.860 \n## 2     122 negative             0.688         0.312 \n## 3      83 negative             0.912         0.0885\n## 4      76 negative             0.931         0.0686\n## 5     144 positive             0.481         0.519"},{"path":"logistic-models-binary-response.html","id":"exercise-penguins","chapter":"3 Logistic Models – Binary Response","heading":"3.7 Exercise: Penguins","text":"Exercise 3.1  practice bit , ’ll using data set penguins. data palmerpenguins package, included tidymodels. data set contains information penguins Palmer Station Antarctica. Chilly.look plot , comparing bill length (bill_length_mm) three species penguins (species) flipper length (flipper_length_mm).also colouring data based sex (sex) good measure ’re also including information body size (body_mass_g).looks like female penguins smaller different sized bills interesting (yes, !) investigate .like following:load data object called penguins using data(\"penguins\")create logistic model fit data , using sex classifieris bill length important indicator sex?First, load data:already reasonably good idea ’re looking , can never hurt understand data better, :shows columns data set, namely island, indicating island penguins residing bill_depth_mm records bill depth.also notice missing values. good get rid , least rows sex isn’t scored:Next, specify type model. Notice can useful use prefix naming objects indicate data set model belongs . ’re using pgn denote penguins.Remember, setting model specification yet define model . follows:’ve fitted data model, can look model parameters:model parameters tell us intercept coefficient bill_length_mm significantly different zero. seems bill length important predictor sex penguins. knew?!","code":"\ndata(\"penguins\")\nhead(penguins)## # A tibble: 6 × 8\n##   species island bill_length_mm bill_depth_mm flipper_length_… body_mass_g sex  \n##   <fct>   <fct>           <dbl>         <dbl>            <int>       <int> <fct>\n## 1 Adelie  Torge…           39.1          18.7              181        3750 male \n## 2 Adelie  Torge…           39.5          17.4              186        3800 fema…\n## 3 Adelie  Torge…           40.3          18                195        3250 fema…\n## 4 Adelie  Torge…           NA            NA                 NA          NA <NA> \n## 5 Adelie  Torge…           36.7          19.3              193        3450 fema…\n## 6 Adelie  Torge…           39.3          20.6              190        3650 male \n## # … with 1 more variable: year <int>\npenguins <- penguins %>% \n  filter(!is.na(sex))\npgn_mod <- logistic_reg() %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"glm\")\npgn_fit <- pgn_mod %>% \n  fit(sex ~ bill_length_mm,\n      data = penguins)\npgn_fit %>% tidy()## # A tibble: 2 × 5\n##   term           estimate std.error statistic       p.value\n##   <chr>             <dbl>     <dbl>     <dbl>         <dbl>\n## 1 (Intercept)      -6.04     1.01       -5.96 0.00000000247\n## 2 bill_length_mm    0.138    0.0229      6.02 0.00000000176"},{"path":"logistic-models-binary-response.html","id":"model-evaluation","chapter":"3 Logistic Models – Binary Response","heading":"3.8 Model evaluation","text":"far ’ve constructed logistic model fed new data make predictions possible outcome diabetes test, depending glucose level given patient. gave us diabetes test predictions , importantly, probabilities whether test come back negative positive.question ’d like ask point: reliable model?explore , need take step back.","code":""},{"path":"logistic-models-binary-response.html","id":"split-the-data","chapter":"3 Logistic Models – Binary Response","heading":"3.8.1 Split the data","text":"created model, used data. However, good way assessing model fit actually split data two:training data set use fit modela test data set validate model measure model performanceBefore split data, let’s closer look data set. count many diabetes test results negative positive, see counts evenly split.tidyverseThis can consequences start splitting data training test set. splitting data two parts - data goes training set - data left afterwards can use test good predictions model . However, need make sure proportion negative positive diabetes test outcomes remains roughly .rsample package couple useful functions allow us just can use strata argument keep proportions less constant.can check initial_split() function done:output can see around 75% data set used create training data set, remaining 25% kept test set.Furthermore, proportions negative:positive kept less constant.Although seems bit overkill, now single function can can use prepare recipe train model resulting predictors:creates object called dia_fit, contains final recipe fitted model objects. can extract model recipe objects several helper functions:far, done following:Built model (dia_mod),Created pre-processing recipe (dia_rec),Combined model recipe workflow (dia_wflow)Trained workflow using fit() function (dia_fit)results generated differ much values obtained entire data set. However, based 3/4 data (training data set). , still test data set available apply workflow data model yet seen.can now evaluate model. One way using area ROC curve metric.ROC curve (receiver operating characteristic curve - name strange relic WWII developed operators military radar receivers) plots true-positive rate (TPR) false-positive rate (FPR) varying thresholds.true-positive rate also known sensitivity, whereas false-positive rate 1 - sensitivity (, recall session Power Analysis also known power.)area ROC curve, known AUC provides aggregate measure performance across possible classification thresholds.ranges value 0 1. model whose predictions 100% wrong AUC 0. model whose predictions 100% correct AUC 1.0.addition ROC curve AUC also whole range model parameters associated fitted model. ’re going point, one particular familiar.extract parameters follows:see Akaike Information Criterion (AIC) output. Remember, value AIC meaningless, ’s useful compare relative AICs models. covered Power analysis session Core statistics course.see AIC model uses glucose level single predictor diabetes test result 558.","code":"\ndiabetes %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      478 0.657\n## 2 positive      250 0.343\n# ensures random data split is reproducible\nset.seed(123)\n\n# split the data, basing the proportions on the diabetes test results\ndata_split <- initial_split(diabetes, strata = test_result)\n\n# create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n# proportion of data allocated to the training set\nnrow(train_data) / nrow(diabetes)## [1] 0.7486264\n# proportion of diabetes test results for the training data set\ntrain_data %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      358 0.657\n## 2 positive      187 0.343\n# proportion of diabetes test results for the test data set\ntest_data %>% \n  count(test_result) %>% \n  mutate(prop = n/sum(n))## # A tibble: 2 × 3\n##   test_result     n  prop\n##   <fct>       <int> <dbl>\n## 1 negative      120 0.656\n## 2 positive       63 0.344\n# Create a recipe\ndia_rec <- \n  recipe(test_result ~ glucose, data = train_data)\n\n# Look at the recipe summary\nsummary(dia_rec)## # A tibble: 2 × 4\n##   variable    type    role      source  \n##   <chr>       <chr>   <chr>     <chr>   \n## 1 glucose     numeric predictor original\n## 2 test_result nominal outcome   original\ndia_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")\ndia_wflow <- \n  workflow() %>% \n  add_model(dia_mod) %>% \n  add_recipe(dia_rec)\n\ndia_wflow## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## 0 Recipe Steps\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## Logistic Regression Model Specification (classification)\n## \n## Computational engine: glm\ndia_fit <- \n  dia_wflow %>% \n  fit(data = train_data)\ndia_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -5.72     0.513       -11.2 6.84e-29\n## 2 glucose       0.0406   0.00397      10.2 1.46e-24\ndia_aug <- \naugment(dia_fit, test_data)\n\ndia_aug## # A tibble: 183 × 6\n##    glucose diastolic test_result .pred_class .pred_negative .pred_positive\n##      <dbl>     <dbl> <fct>       <fct>                <dbl>          <dbl>\n##  1      85        66 negative    negative            0.906          0.0938\n##  2     183        64 positive    positive            0.152          0.848 \n##  3     168        74 positive    positive            0.249          0.751 \n##  4     166        72 positive    positive            0.264          0.736 \n##  5     115        70 positive    negative            0.740          0.260 \n##  6      99        84 negative    negative            0.845          0.155 \n##  7     196        90 positive    positive            0.0959         0.904 \n##  8     119        80 positive    negative            0.708          0.292 \n##  9     143        94 positive    positive            0.478          0.522 \n## 10      97        66 negative    negative            0.856          0.144 \n## # … with 173 more rows\ndia_aug %>% \n  roc_curve(truth = test_result, .pred_negative) %>% \n  autoplot()\ndia_aug %>% \n  roc_auc(truth = test_result, .pred_negative)## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 roc_auc binary         0.766\ndia_fit %>% glance()## # A tibble: 1 × 8\n##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n## 1          701.     544  -277.  558.  567.     554.         543   545"},{"path":"logistic-models-binary-response.html","id":"create-a-recipe","chapter":"3 Logistic Models – Binary Response","heading":"3.8.2 Create a recipe","text":"","code":"\n# Create a recipe\ndia_rec <- \n  recipe(test_result ~ glucose, data = train_data)\n\n# Look at the recipe summary\nsummary(dia_rec)## # A tibble: 2 × 4\n##   variable    type    role      source  \n##   <chr>       <chr>   <chr>     <chr>   \n## 1 glucose     numeric predictor original\n## 2 test_result nominal outcome   original"},{"path":"logistic-models-binary-response.html","id":"build-a-model-specification","chapter":"3 Logistic Models – Binary Response","heading":"3.8.3 Build a model specification","text":"","code":"\ndia_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")"},{"path":"logistic-models-binary-response.html","id":"use-recipe-as-we-train-and-test-our-model","chapter":"3 Logistic Models – Binary Response","heading":"3.8.4 Use recipe as we train and test our model","text":"Although seems bit overkill, now single function can can use prepare recipe train model resulting predictors:creates object called dia_fit, contains final recipe fitted model objects. can extract model recipe objects several helper functions:","code":"\ndia_wflow <- \n  workflow() %>% \n  add_model(dia_mod) %>% \n  add_recipe(dia_rec)\n\ndia_wflow## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## 0 Recipe Steps\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## Logistic Regression Model Specification (classification)\n## \n## Computational engine: glm\ndia_fit <- \n  dia_wflow %>% \n  fit(data = train_data)\ndia_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -5.72     0.513       -11.2 6.84e-29\n## 2 glucose       0.0406   0.00397      10.2 1.46e-24"},{"path":"logistic-models-binary-response.html","id":"use-trained-workflow-for-predictions","chapter":"3 Logistic Models – Binary Response","heading":"3.8.5 Use trained workflow for predictions","text":"far, done following:Built model (dia_mod),Created pre-processing recipe (dia_rec),Combined model recipe workflow (dia_wflow)Trained workflow using fit() function (dia_fit)results generated differ much values obtained entire data set. However, based 3/4 data (training data set). , still test data set available apply workflow data model yet seen.","code":"\ndia_aug <- \naugment(dia_fit, test_data)\n\ndia_aug## # A tibble: 183 × 6\n##    glucose diastolic test_result .pred_class .pred_negative .pred_positive\n##      <dbl>     <dbl> <fct>       <fct>                <dbl>          <dbl>\n##  1      85        66 negative    negative            0.906          0.0938\n##  2     183        64 positive    positive            0.152          0.848 \n##  3     168        74 positive    positive            0.249          0.751 \n##  4     166        72 positive    positive            0.264          0.736 \n##  5     115        70 positive    negative            0.740          0.260 \n##  6      99        84 negative    negative            0.845          0.155 \n##  7     196        90 positive    positive            0.0959         0.904 \n##  8     119        80 positive    negative            0.708          0.292 \n##  9     143        94 positive    positive            0.478          0.522 \n## 10      97        66 negative    negative            0.856          0.144 \n## # … with 173 more rows"},{"path":"logistic-models-binary-response.html","id":"evaluate-the-model","chapter":"3 Logistic Models – Binary Response","heading":"3.8.6 Evaluate the model","text":"can now evaluate model. One way using area ROC curve metric.ROC curve (receiver operating characteristic curve - name strange relic WWII developed operators military radar receivers) plots true-positive rate (TPR) false-positive rate (FPR) varying thresholds.true-positive rate also known sensitivity, whereas false-positive rate 1 - sensitivity (, recall session Power Analysis also known power.)area ROC curve, known AUC provides aggregate measure performance across possible classification thresholds.ranges value 0 1. model whose predictions 100% wrong AUC 0. model whose predictions 100% correct AUC 1.0.addition ROC curve AUC also whole range model parameters associated fitted model. ’re going point, one particular familiar.extract parameters follows:see Akaike Information Criterion (AIC) output. Remember, value AIC meaningless, ’s useful compare relative AICs models. covered Power analysis session Core statistics course.see AIC model uses glucose level single predictor diabetes test result 558.","code":"\ndia_aug %>% \n  roc_curve(truth = test_result, .pred_negative) %>% \n  autoplot()\ndia_aug %>% \n  roc_auc(truth = test_result, .pred_negative)## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 roc_auc binary         0.766\ndia_fit %>% glance()## # A tibble: 1 × 8\n##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n## 1          701.     544  -277.  558.  567.     554.         543   545"},{"path":"logistic-models-binary-response.html","id":"exercise-diabetes-predictors","chapter":"3 Logistic Models – Binary Response","heading":"3.9 Exercise: Diabetes predictors","text":"Exercise 3.2  Using training test diabetes data sets, investigate relationship test_result glucose diastolic. Try answer following:adding diastolic model markedly improve reliability predictions?AICs two models tell ?Build model, needed (done already stays ):Create workflow…… fit data:Extract model parameters look:Apply fitted model test data set:Plot ROC curve:get area ROC curve:Another way assess model fit look Akaike Information Criterion (AIC).get AIC 555, lower AIC 558 got just glucose predictor variable.Adding diastolic variable predictor model seem much effect model reliability, since AUC 0.761 extra parameter, versus 0.766 without.AIC hand suggests additive model ’ve analysed better fit original model (AIC 555 vs 558).Perhaps interaction glucose diastolic, interesting investigate.","code":"\n# Update the recipe\ndia_rec <- \n  recipe(test_result ~ glucose + diastolic,\n         data = train_data)\n\n# Look at the recipe summary\nsummary(dia_rec)## # A tibble: 3 × 4\n##   variable    type    role      source  \n##   <chr>       <chr>   <chr>     <chr>   \n## 1 glucose     numeric predictor original\n## 2 diastolic   numeric predictor original\n## 3 test_result nominal outcome   original\ndia_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")\ndia_wflow <- \n  workflow() %>% \n  add_model(dia_mod) %>% \n  add_recipe(dia_rec)\ndia_fit <- \n  dia_wflow %>% \n  fit(data = train_data)\ndia_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()## # A tibble: 3 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -6.99     0.790       -8.85 8.60e-19\n## 2 glucose       0.0394   0.00398      9.88 5.19e-23\n## 3 diastolic     0.0195   0.00877      2.22 2.61e- 2\ndia_aug <- \naugment(dia_fit, test_data)\n\ndia_aug## # A tibble: 183 × 6\n##    glucose diastolic test_result .pred_class .pred_negative .pred_positive\n##      <dbl>     <dbl> <fct>       <fct>                <dbl>          <dbl>\n##  1      85        66 negative    negative            0.914          0.0862\n##  2     183        64 positive    positive            0.189          0.811 \n##  3     168        74 positive    positive            0.257          0.743 \n##  4     166        72 positive    positive            0.280          0.720 \n##  5     115        70 positive    negative            0.751          0.249 \n##  6      99        84 negative    negative            0.811          0.189 \n##  7     196        90 positive    positive            0.0776         0.922 \n##  8     119        80 positive    negative            0.679          0.321 \n##  9     143        94 positive    positive            0.385          0.615 \n## 10      97        66 negative    negative            0.869          0.131 \n## # … with 173 more rows\ndia_aug %>% \n  roc_curve(truth = test_result, .pred_negative) %>% \n  autoplot()\ndia_aug %>% \n  roc_auc(truth = test_result, .pred_negative)## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 roc_auc binary         0.761\ndia_fit %>% glance()## # A tibble: 1 × 8\n##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n## 1          701.     544  -275.  555.  568.     549.         542   545"},{"path":"logistic-models-binary-response.html","id":"conclusions","chapter":"3 Logistic Models – Binary Response","heading":"3.9.0.1 Conclusions","text":"Adding diastolic variable predictor model seem much effect model reliability, since AUC 0.761 extra parameter, versus 0.766 without.AIC hand suggests additive model ’ve analysed better fit original model (AIC 555 vs 558).","code":""},{"path":"logistic-models-binary-response.html","id":"food-for-thought","chapter":"3 Logistic Models – Binary Response","heading":"3.9.0.2 Food for thought","text":"Perhaps interaction glucose diastolic, interesting investigate.","code":""},{"path":"logistic-models-binary-response.html","id":"key-points","chapter":"3 Logistic Models – Binary Response","heading":"3.10 Key points","text":"use logistic regression model binary responseModel suitability can checked splitting data training test data set. logistic model created based training data, reliability can checked (known) values test data setThe ROC curve shows performance classification model thresholds, whereas area ROC curve provides aggregate measure performance possible classifications thresholds.panelset{--panel-tab-font-family: inherit;}","code":""},{},{"path":"logistic-regression---proportion-response.html","id":"logistic-regression---proportion-response","chapter":"4 Logistic regression - proportion response","heading":"4 Logistic regression - proportion response","text":"","code":""},{"path":"logistic-regression---proportion-response.html","id":"objectives-2","chapter":"4 Logistic regression - proportion response","heading":"4.1 Objectives","text":"QuestionsHow analyse proportion responses?ObjectivesBe able create logistic model test proportion response variablesBe able plot data fitted curveAssess significance fit","code":""},{"path":"logistic-regression---proportion-response.html","id":"libraries-and-functions-1","chapter":"4 Logistic regression - proportion response","heading":"4.2 Libraries and functions","text":"tidyverse","code":""},{"path":"logistic-regression---proportion-response.html","id":"datasets-1","chapter":"4 Logistic regression - proportion response","heading":"4.3 Datasets","text":"DiabetesThe example section uses following data set:data/challenger.csvThese data, obtained faraway package, contain information related explosion USA Space Shuttle Challenger 28 January, 1986. investigation disaster traced back certain joints one two solid booster rockets, containing two O-rings (primary secondary) ensured exhaust gases escape booster.night launch unusually cold, temperatures freezing. final report suggested cold snap night made o-rings stiff, unable adjust changes pressure. result, exhaust gases leaked away solid booster rockets, causing one break loose rupture main fuel tank, leading final explosion.question ’re trying answer session : based data previous flights, possible predict failure o-rings Challenger flight?","code":""},{"path":"logistic-regression---proportion-response.html","id":"visualise-the-data-1","chapter":"4 Logistic regression - proportion response","heading":"4.4 Visualise the data","text":"First, read data:tidyverseThe data set contains several columns:temp, launch temperature degrees Fahrenheitdamage, number o-rings showed erosionBefore look data, let’s calculate proportion damaged o-rings (prop_damaged) total number o-rings (total) update data set.tidyversePlotting proportion damaged o-rings launch temperature shows following picture:tidyverseThe point left data point corresponding coldest flight experienced disaster, five damaged o-rings found. Fortunately, result disaster.’ll explore predicted failure o-rings Challenger flight, launch temperature 31 degrees Fahrenheit.","code":"\nchallenger <- read_csv(\"data/challenger.csv\")## Rows: 23 Columns: 2\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## dbl (2): temp, damage\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nchallenger## # A tibble: 23 × 2\n##     temp damage\n##    <dbl>  <dbl>\n##  1    53      5\n##  2    57      1\n##  3    58      1\n##  4    63      1\n##  5    66      0\n##  6    67      0\n##  7    67      0\n##  8    67      0\n##  9    68      0\n## 10    69      0\n## # … with 13 more rows\nchallenger <-\nchallenger %>%\n  mutate(total = 6,                     # total number of o-rings\n         intact = 6 - damage,           # number of undamaged o-rings\n         prop_damaged = damage / total) # proportion damaged o-rings\n\nchallenger## # A tibble: 23 × 5\n##     temp damage total intact prop_damaged\n##    <dbl>  <dbl> <dbl>  <dbl>        <dbl>\n##  1    53      5     6      1        0.833\n##  2    57      1     6      5        0.167\n##  3    58      1     6      5        0.167\n##  4    63      1     6      5        0.167\n##  5    66      0     6      6        0    \n##  6    67      0     6      6        0    \n##  7    67      0     6      6        0    \n##  8    67      0     6      6        0    \n##  9    68      0     6      6        0    \n## 10    69      0     6      6        0    \n## # … with 13 more rows\nggplot(challenger, aes(x = temp, y = prop_damaged)) +\n  geom_point()"},{"path":"logistic-regression---proportion-response.html","id":"model-building-1","chapter":"4 Logistic regression - proportion response","heading":"4.5 Model building","text":"little point evaluating model using training/test data set, since 23 data points total. ’re building model testing available data.tidyverse\nusing logistic regression proportion response case, since ’re interested proportion o-rings damaged.logistic_reg() function used binary response section work , expects binary (yes/; positive/negative; 0/1 etc) response.deal , using standard linear_reg() function, still using glm generalised linear model engine, family error distribution set binomial ().First set model specification:fit data. Fitting data proportion responses bit annoying, give glm model two-column matrix specify response variable., first column corresponds number damaged o-rings, whereas second column refers number intact o-rings. use cbind() function bind two together matrix.Next, can closer look results:can see p-values intercept temp significant. can also use intercept temp coefficients construct logistic equation, can use sketch logistic curve.\\[\\begin{equation}\nP(o-ring \\ failure) = \\frac{1}{1 + {e}^{-(11.66 -  0.22 \\cdot temp)}}\n\\end{equation}\\]Let’s see well model performed fed data ill-fated Challenger launch.First generate table data range temperatures, 25 85 degrees Fahrenheit, steps 1. can use data generate logistic curve, based fitted model.seems high probability o-rings failing launch temperature. One thing graph shows lot uncertainty involved model.","code":"\nchl_mod <- linear_reg(mode = \"regression\") %>%\n  set_engine(\"glm\", family = \"binomial\")\nchl_fit <- chl_mod %>% \n  fit(cbind(damage, intact) ~ temp,\n      data = challenger)\nchl_fit %>% tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic   p.value\n##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n## 1 (Intercept)   11.7      3.30        3.54 0.000403 \n## 2 temp          -0.216    0.0532     -4.07 0.0000478\nmodel <- tibble(temp = seq(25, 85, 1))\n# get the predicted proportions for the curve\ncurve <- chl_fit %>% augment(new_data = model)\n\n# plot the curve and the original data\nggplot(curve, aes(temp, .pred)) +\n  geom_line(colour = \"red\") +\n  geom_point(data = challenger, aes(temp, prop_damaged)) +\n  # add a vertical line at the disaster launch temperature\n  geom_vline(xintercept = 31, linetype = \"dashed\")"},{"path":"logistic-regression---proportion-response.html","id":"exercise","chapter":"4 Logistic regression - proportion response","heading":"4.6 Exercise","text":"Exercise 4.1  data point 53 degrees Fahrenheit quite influential analysis. Remove data point repeat analysis. still predicted link launch temperature o-ring failure?tidyverseFirst, need remove influential data point:can reuse model specification, update fit:prediction proportion damaged o-rings markedly less scenario, failure rate around 80%. original fitted curve already quite uncertainty associated , uncertainty model much greater.","code":"\nchallenger_new <- challenger %>% filter(temp != 53)\nchl_new_fit <- chl_mod %>% \n  fit(cbind(damage, intact) ~ temp,\n      data = challenger_new)\n# get the predicted proportions for the curve\ncurve_new <- chl_new_fit %>% augment(new_data = model)\n\n# plot the curve and the original data\nggplot(curve_new, aes(temp, .pred)) +\n  geom_line(colour = \"red\") +\n  geom_point(data = challenger_new, aes(temp, prop_damaged)) +\n  # add a vertical line at the disaster launch temperature\n  geom_vline(xintercept = 31, linetype = \"dashed\")"},{"path":"logistic-regression---proportion-response.html","id":"key-points-1","chapter":"4 Logistic regression - proportion response","heading":"4.7 Key points","text":"can use logistic model proportion response variables.panelset{--panel-tab-font-family: inherit;}","code":""},{},{"path":"poisson-regression-count-response.html","id":"poisson-regression-count-response","chapter":"5 Poisson Regression – Count Response","heading":"5 Poisson Regression – Count Response","text":"","code":""},{"path":"poisson-regression-count-response.html","id":"objectives-3","chapter":"5 Poisson Regression – Count Response","heading":"5.1 Objectives","text":"QuestionsHow analyse count data?ObjectivesBe able perform poisson regression count data","code":""},{"path":"poisson-regression-count-response.html","id":"libraries-and-functions-2","chapter":"5 Poisson Regression – Count Response","heading":"5.2 Libraries and functions","text":"tidyverse","code":""},{"path":"poisson-regression-count-response.html","id":"datasets-2","chapter":"5 Poisson Regression – Count Response","heading":"5.3 Datasets","text":"IslandsThe example section uses following data set:data/islands.csvThis data set comprising 35 observations two variables (one dependent one predictor). records number species recorded different small islands along area (km2)islands. variables species area.","code":""},{"path":"poisson-regression-count-response.html","id":"visualise-the-data-2","chapter":"5 Poisson Regression – Count Response","heading":"5.4 Visualise the data","text":"First load data, visualise .tidyverse\nFirst, load inspect data:Looking data, can see two columns: species, contains number species recorded island area, contains surface area island square kilometers.can plot data:looks though area may effect number species observe island. note response variable count data try construct Poisson regression.","code":"\nislands <- read_csv(\"data/island.csv\")\n\nislands## # A tibble: 35 × 2\n##    species  area\n##      <dbl> <dbl>\n##  1     114  12.1\n##  2     130  13.4\n##  3     113  13.7\n##  4     109  14.5\n##  5     118  16.8\n##  6     136  19.0\n##  7     149  19.6\n##  8     162  20.6\n##  9     145  20.9\n## 10     148  21.0\n## # … with 25 more rows\nislands %>% \n  ggplot(aes(x = area, y = species)) +\n  geom_point()"},{"path":"poisson-regression-count-response.html","id":"model-building-2","chapter":"5 Poisson Regression – Count Response","heading":"5.5 Model building","text":"create poisson regression following:tidyverseAgain, similar ’ve done logistic models, use parsnip package tidymodels library. Yes, workflow still seems bit faffy, provides common syntax whole range modelling libraries. means syntax stay different kind model comparisons.haven’t loaded tidymodels yet, now really good time. also need load poissonreg, adds extra functionality parsnip.Remember workflow parsnip bit different ’re used far. Using parsnip approach things systematic manner. specify model three steps:Specify type model based mathematical structure (e.g., linear regression, random forest, K-nearest neighbors, etc).required, declare mode model. mode reflects type prediction outcome. numeric outcomes, mode regression; qualitative outcomes, classification. model can create one type model, logistic regression, mode already set.Specify engine fitting model. usually software package library used., can create model follows:, note actually specifying variables yet. ’ve done tell R kind model ’re planning use. want see parsnip converts code package syntax, can check translate():shows poisson regression model, outcome going regression. model fit template tells us ’ll using glm() function stats package, can take formula, data, weights family argument. family argument already set poisson.Now ’ve specified kind model ’re planning use, can fit data , using fit() function:can look output directly, prefer tidy data using tidy() function broom package:output strikingly similar logistic regression models (’d guessed, eh?) main numbers extract output two numbers estimate column.coefficients Poisson model equation need placed following formula order estimate expected number species function island size:\\[\\begin{equation}\nE(species) = {e}^{(4.24 + 0.036 \\times area)}\n\\end{equation}\\]Interpreting requires bit thought (much, bit).intercept coefficient (\\(\\beta_0\\)), 4.24, related number species expect island zero area (statistics, real life. ’d well remember worry much even means). order turn number something meaningful exponentiate . Since \\({e}^{(4.24) \\approx 70}\\), can say baseline number species model expects island 70. isn’t actually interesting bit though.coefficient area (\\(\\beta_1\\)) fun bit. starters can see positive number mean increasing area leads increasing numbers species. Good far - since matches saw plotted data. value 0.036 actually mean?Well, exponentiate get \\({e}^{(0.036)} \\approx 1.04\\). means every increase area 1 km2 (original units area variable) number species island multiplied 1.04. , island area 1 km2 predicted \\(1.04 \\times 70 \\approx 72\\) species., order interpret Poisson coefficients, exponentiate .","code":"\n# install.packages(\"tidymodels\")\nlibrary(tidymodels)\n# install.packages(\"poissonreg\")\nlibrary(poissonreg)\nisl_mod <- poisson_reg() %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"glm\")\nisl_mod %>% translate()## Poisson Regression Model Specification (regression)\n## \n## Computational engine: glm \n## \n## Model fit template:\n## stats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n##     family = stats::poisson)\nisl_fit <- isl_mod %>% \n  fit(species ~ area,\n      data = islands)\nisl_fit %>% tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic   p.value\n##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n## 1 (Intercept)   4.24     0.0413      103.  0        \n## 2 area          0.0356   0.00125      28.6 2.73e-179"},{"path":"poisson-regression-count-response.html","id":"model-predictions-1","chapter":"5 Poisson Regression – Count Response","heading":"5.6 Model predictions","text":"Now can interpret Poisson coefficients, good see using poisson regression describe data actually good idea.Visualisation always useful, order get idea data fits Poisson regression, ’ll plot Poisson regression curve. Next, overlay original data.tidyverseFirst, create table contains data curve, starting area value 1 50, steps 1.Next, feed model data:gives predicted number species given value area. closer look data can see , example, area surface area 4 km2 predicted number species around 80. Nice.Using data, can now plot predicted number species overlay original measured data.looks like pretty decent fit, really. course want (slightly) less hand-wavy conclusion .","code":"\nmodel <- tibble(area = seq(1, 50, 1))\ncurve <- isl_fit %>% augment(new_data = model)\nhead(curve)## # A tibble: 6 × 2\n##    area .pred\n##   <dbl> <dbl>\n## 1     1  72.0\n## 2     2  74.6\n## 3     3  77.3\n## 4     4  80.1\n## 5     5  83.0\n## 6     6  86.0\nggplot(curve, aes(area, .pred)) +\n  geom_line(colour = \"red\") +\n  geom_point(data = islands, aes(area, species))"},{"path":"poisson-regression-count-response.html","id":"goodness-of-fit","chapter":"5 Poisson Regression – Count Response","heading":"5.6.1 Goodness-of-fit","text":"can use model’s residual deviance assess much predicted values differ observed. gives us idea well-specified model . model “true”, .e. model makes pretty accurate predictions, expect residual deviance distributed \\(\\chi^2\\)\nrandom variable degrees freedom equal model’s residual degrees freedom.can get parameters follows ’ll store new object, can extract bit.values interested deviance df.residual columns, respectively.Next, use pchisq() function calculate correct probability.gives us value around 0.60. suggests model actually pretty good one (wasn’t value close zero) data pretty well supported model.pchisq() function gives lower tail probability \\(\\chi^2 \\le x\\) default. ’re actually interested probability \\(\\chi^2 \\ge x\\). two probabilities must sum one, get upper tail probability setting argument lower.tail = FALSE. alternative way use default, 1 - pchisq().Poisson models extra interpretation. can used assess whether significant overdispersion data. Poisson model appropriate need variance data exactly mean data. overdispersion data spread higher predicted values species lower ones. visualisation shows isn’t really happening. spread unlikely perfectly homogeneous, don’t want data spread much.easy way check look ratio residual deviance residual degrees freedom (case 0.922). Poisson model valid, ratio 1. ratio significantly bigger 1 say -dispersion model wouldn’t able trust significance testing using Poisson regression.","code":"\nisl_fit %>% glance()## # A tibble: 1 × 8\n##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n## 1          857.      34  -139.  283.  286.     30.4          33    35\nisl_parameters <- isl_fit %>% glance()\npchisq(isl_parameters$deviance,\n       isl_parameters$df.residual,\n       lower.tail = FALSE)## [1] 0.595347"},{"path":"poisson-regression-count-response.html","id":"confidence-intervals","chapter":"5 Poisson Regression – Count Response","heading":"5.6.2 Confidence intervals","text":"can also assess reliable model looking confidence intervals estimated parameters.extracted parameters model usingAlthough focussed estimate column, can see associated standard errors estimate also given std.error column. can use values calculate 95% confidence intervals.can either hand multiplying standard errors 1.96. can subtract (giving lower confidence estimate) add (giving higher confidence estimate) estimated parameter. gives pretty decent approximation., life short, can just use additional argument available tidy() function. can look columns returned, ’m selecting relevant ones :’re interested confidence intervals area parameter. delve , ’m also going calculate exponent confidence intervals. can using exp() function.values bit familiar, since ’ve previously determined based area coefficient increase square kilometer, number species increases approximately 1.04.values tell us can 95% certain every increase square kilometer island area size, number species increases somewhere 1.034 1.039.association area species, \\(\\beta_1\\) coefficient zero. mean exponent \\({e}^{\\beta_1}=1\\). interval calculated \\({e}^{\\beta_1}\\) lies 1.034 1.039 therefore include 1, model area preferred model without area.Similarly, interval \\(\\beta_1\\) (0.033 - 0.038) include 0, showing significance area predictor species.","code":"\nisl_fit %>% tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic   p.value\n##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n## 1 (Intercept)   4.24     0.0413      103.  0        \n## 2 area          0.0356   0.00125      28.6 2.73e-179\nisl_fit %>% tidy(conf.int = TRUE,        # default is FALSE\n                 conf.level = 0.95) %>%  # is the default\n  select(term, estimate, conf.low, conf.high)## # A tibble: 2 × 4\n##   term        estimate conf.low conf.high\n##   <chr>          <dbl>    <dbl>     <dbl>\n## 1 (Intercept)   4.24     4.16      4.32  \n## 2 area          0.0356   0.0332    0.0381\nisl_fit %>% tidy(conf.int = TRUE,        # default is FALSE\n                 conf.level = 0.95) %>%  # is the default\n  select(term, estimate, conf.low, conf.high) %>% \n  mutate(conf.low_exp = exp(conf.low),\n         conf.high_exp = exp(conf.high))## # A tibble: 2 × 6\n##   term        estimate conf.low conf.high conf.low_exp conf.high_exp\n##   <chr>          <dbl>    <dbl>     <dbl>        <dbl>         <dbl>\n## 1 (Intercept)   4.24     4.16      4.32          64.1          75.3 \n## 2 area          0.0356   0.0332    0.0381         1.03          1.04"},{"path":"poisson-regression-count-response.html","id":"exercise-seatbelts","chapter":"5 Poisson Regression – Count Response","heading":"5.7 Exercise: Seatbelts","text":"Exercise 5.1  Seatbelts data set R multiple time-series data set commissioned Department Transport 1984 measure differences deaths front seatbelt legislation introduced 31st January 1983. provides monthly total numerical data number incidents including related death injury Road Traffic Accidents (RTA’s). data set starts January 1969 observations run December 1984.’d like following:Load data (see code )Visualise data create poisson regression modelPlot regression model top dataAssess model decent predictor number fatalitiestidyverse\ncan load data directly R, unfortunately data friendly format. need bit data wrangling tidying.\ncan make life (bit) easier janitor library - ’s addition tidyverse clean_names() function enables clean messy column names. Install needed, load .Don’t worry much code means tidies data. Just copy/paste , end tidy seatbelts object.tidyverseThe data tracks number drivers killed road traffic accidents, seatbelt law introduced. information whether law place encoded law column 0 (law place) 1 (law place).many observations law place, need keep mind ’re interpreting data.First look data comparing law vs law:data recorded month year, can also display number drivers killed year:data look bit weird. quite variation within years (keeping mind data aggregated monthly). data also seems wave around bit… vague peaks (e.g. 1972 - 1973) troughs (e.g. around 1976).initial thought data going bit tricky interpret. ’s OK.’re dealing count data, ’re going use poisson regression., first define model type.check everything order.Next, fit data model just specified:can extract estimated coefficients fitted data:see model actually decent prediction data, can plot ., create modelled values predictor variable year. monthly data, create sequence “years” 1/12th intervals - one month.Next, ask model predict number drivers killed based values.Lastly, can plot predicted values observed values data set.look like good fit, data look rather messy well.Let’s check goodness--fit.First store parameter estimates object. use pchisq() function calculate probability residual deviance actually distributed \\(\\chi^2\\) random variable degrees freedom equal model’s residual degrees freedom.Yes, can read sentence three times still wonder really means. Suffice say outcome gives us measure well-specified model .Well, ’s bit blow. probability value extremely low, suggesting model well-specified. kind matches already saw plot. might still better null model (“data can modelled average across observations”), seem missing parameters .Similar islands example, can also calculate confidence intervals associated estimated parameters.’re interested confidence interval year variable. Remember association year drivers_killed parameter \\(e^{\\beta_1} = 1\\).case interval calculated \\(e^{\\beta_1}\\) lies 0.981 0.986. include 1, seems model takes year account still preferred model doesn’t.","code":"\n# install.packages(\"janitor\")\nlibrary(janitor)## \n## Attaching package: 'janitor'## The following objects are masked from 'package:stats':\n## \n##     chisq.test, fisher.test\ndata(Seatbelts)\n\nseatbelts <- Seatbelts %>%\n  as_tibble() %>%\n  mutate(Year = floor(time(Seatbelts)),\n         Year = as.numeric(Year),\n         Month = factor(cycle(Seatbelts),\n                        labels = month.abb),\n         law = factor(law)) %>% \n  clean_names()\n\n# check if the data is now in a decent format\nseatbelts## # A tibble: 192 × 10\n##    drivers_killed drivers front  rear   kms petrol_price van_killed law    year\n##             <dbl>   <dbl> <dbl> <dbl> <dbl>        <dbl>      <dbl> <fct> <dbl>\n##  1            107    1687   867   269  9059        0.103         12 0      1969\n##  2             97    1508   825   265  7685        0.102          6 0      1969\n##  3            102    1507   806   319  9963        0.102         12 0      1969\n##  4             87    1385   814   407 10955        0.101          8 0      1969\n##  5            119    1632   991   454 11823        0.101         10 0      1969\n##  6            106    1511   945   427 12391        0.101         13 0      1969\n##  7            110    1559  1004   522 13460        0.104         11 0      1969\n##  8            106    1630  1091   536 14055        0.104          6 0      1969\n##  9            107    1579   958   405 12106        0.104         10 0      1969\n## 10            134    1653   850   437 11372        0.103         16 0      1969\n## # … with 182 more rows, and 1 more variable: month <fct>\nseatbelts %>% \n  ggplot(aes(law, drivers_killed)) +\n  geom_boxplot()\nseatbelts %>% \n  ggplot(aes(year, drivers_killed)) +\n  geom_point()\nstb_mod <- poisson_reg() %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"glm\")\nstb_mod %>% translate()## Poisson Regression Model Specification (regression)\n## \n## Computational engine: glm \n## \n## Model fit template:\n## stats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n##     family = stats::poisson)\nstb_fit <- stb_mod %>% \n  fit(drivers_killed ~ year,\n      data = seatbelts)\nstb_fit %>% tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  37.2      2.80         13.3 2.62e-40\n## 2 year         -0.0164   0.00142     -11.6 5.88e-31\n# create the sequence of values that are used\n# in predicting number of deaths\nmodel <- tibble(year = seq(1969, 1984, (1/12)))\n\n# fit these data to the model\nstb_curve <- stb_fit %>% augment(new_data = model)\n\n# plot the predicted values\n# and overlay the observed values\nggplot(seatbelts, aes(year, drivers_killed)) +\n  geom_point() +\n  geom_point(data = stb_curve, aes(x = year, y = .pred),\n             colour = \"red\")\nstb_parameter <- stb_fit %>% glance()\n\nstb_parameter## # A tibble: 1 × 8\n##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n## 1          984.     191 -1062. 2127. 2134.     850.         190   192\npchisq(stb_parameter$deviance,\n       stb_parameter$df.residual,\n       lower.tail = FALSE)## [1] 3.12987e-84\nstb_fit %>% tidy(conf.int = TRUE,        # default is FALSE\n                 conf.level = 0.95) %>%  # is the default\n  select(term, estimate, conf.low, conf.high) %>% \n  mutate(conf.low_exp = exp(conf.low),\n         conf.high_exp = exp(conf.high))## # A tibble: 2 × 6\n##   term        estimate conf.low conf.high conf.low_exp conf.high_exp\n##   <chr>          <dbl>    <dbl>     <dbl>        <dbl>         <dbl>\n## 1 (Intercept)  37.2     31.7      42.7        5.78e+13      3.34e+18\n## 2 year         -0.0164  -0.0191   -0.0136     9.81e- 1      9.86e- 1"},{"path":"poisson-regression-count-response.html","id":"visualise-the-data-3","chapter":"5 Poisson Regression – Count Response","heading":"5.7.1 Visualise the data","text":"data tracks number drivers killed road traffic accidents, seatbelt law introduced. information whether law place encoded law column 0 (law place) 1 (law place).many observations law place, need keep mind ’re interpreting data.First look data comparing law vs law:data recorded month year, can also display number drivers killed year:data look bit weird. quite variation within years (keeping mind data aggregated monthly). data also seems wave around bit… vague peaks (e.g. 1972 - 1973) troughs (e.g. around 1976).initial thought data going bit tricky interpret. ’s OK.","code":"\nseatbelts %>% \n  ggplot(aes(law, drivers_killed)) +\n  geom_boxplot()\nseatbelts %>% \n  ggplot(aes(year, drivers_killed)) +\n  geom_point()"},{"path":"poisson-regression-count-response.html","id":"model-building-3","chapter":"5 Poisson Regression – Count Response","heading":"5.7.2 Model building","text":"’re dealing count data, ’re going use poisson regression., first define model type.check everything order.Next, fit data model just specified:can extract estimated coefficients fitted data:","code":"\nstb_mod <- poisson_reg() %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"glm\")\nstb_mod %>% translate()## Poisson Regression Model Specification (regression)\n## \n## Computational engine: glm \n## \n## Model fit template:\n## stats::glm(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), \n##     family = stats::poisson)\nstb_fit <- stb_mod %>% \n  fit(drivers_killed ~ year,\n      data = seatbelts)\nstb_fit %>% tidy()## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  37.2      2.80         13.3 2.62e-40\n## 2 year         -0.0164   0.00142     -11.6 5.88e-31"},{"path":"poisson-regression-count-response.html","id":"visualise-the-model","chapter":"5 Poisson Regression – Count Response","heading":"5.7.3 Visualise the model","text":"see model actually decent prediction data, can plot ., create modelled values predictor variable year. monthly data, create sequence “years” 1/12th intervals - one month.Next, ask model predict number drivers killed based values.Lastly, can plot predicted values observed values data set.look like good fit, data look rather messy well.","code":"\n# create the sequence of values that are used\n# in predicting number of deaths\nmodel <- tibble(year = seq(1969, 1984, (1/12)))\n\n# fit these data to the model\nstb_curve <- stb_fit %>% augment(new_data = model)\n\n# plot the predicted values\n# and overlay the observed values\nggplot(seatbelts, aes(year, drivers_killed)) +\n  geom_point() +\n  geom_point(data = stb_curve, aes(x = year, y = .pred),\n             colour = \"red\")"},{"path":"poisson-regression-count-response.html","id":"goodness-of-fit-1","chapter":"5 Poisson Regression – Count Response","heading":"5.7.4 Goodness-of-fit","text":"Let’s check goodness--fit.First store parameter estimates object. use pchisq() function calculate probability residual deviance actually distributed \\(\\chi^2\\) random variable degrees freedom equal model’s residual degrees freedom.Yes, can read sentence three times still wonder really means. Suffice say outcome gives us measure well-specified model .Well, ’s bit blow. probability value extremely low, suggesting model well-specified. kind matches already saw plot. might still better null model (“data can modelled average across observations”), seem missing parameters .","code":"\nstb_parameter <- stb_fit %>% glance()\n\nstb_parameter## # A tibble: 1 × 8\n##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n## 1          984.     191 -1062. 2127. 2134.     850.         190   192\npchisq(stb_parameter$deviance,\n       stb_parameter$df.residual,\n       lower.tail = FALSE)## [1] 3.12987e-84"},{"path":"poisson-regression-count-response.html","id":"confidence-intervals-1","chapter":"5 Poisson Regression – Count Response","heading":"5.7.5 Confidence intervals","text":"Similar islands example, can also calculate confidence intervals associated estimated parameters.’re interested confidence interval year variable. Remember association year drivers_killed parameter \\(e^{\\beta_1} = 1\\).case interval calculated \\(e^{\\beta_1}\\) lies 0.981 0.986. include 1, seems model takes year account still preferred model doesn’t.","code":"\nstb_fit %>% tidy(conf.int = TRUE,        # default is FALSE\n                 conf.level = 0.95) %>%  # is the default\n  select(term, estimate, conf.low, conf.high) %>% \n  mutate(conf.low_exp = exp(conf.low),\n         conf.high_exp = exp(conf.high))## # A tibble: 2 × 6\n##   term        estimate conf.low conf.high conf.low_exp conf.high_exp\n##   <chr>          <dbl>    <dbl>     <dbl>        <dbl>         <dbl>\n## 1 (Intercept)  37.2     31.7      42.7        5.78e+13      3.34e+18\n## 2 year         -0.0164  -0.0191   -0.0136     9.81e- 1      9.86e- 1"},{"path":"poisson-regression-count-response.html","id":"key-points-2","chapter":"5 Poisson Regression – Count Response","heading":"5.8 Key points","text":"","code":""},{},{"path":"resampling-intro.html","id":"resampling-intro","chapter":"6 Introduction","heading":"6 Introduction","text":"","code":""},{"path":"resampling-intro.html","id":"objectives-4","chapter":"6 Introduction","heading":"6.1 Objectives","text":"Aim: introduce R/Python commands algorithms conducting simple permutation tests.end practical participants able performMonte Carlo permutation tests \nTwo-samples continuous data\nMultiple samples continuous data\nSimple Linear Regression\nTwo-way anova\nTwo-samples continuous dataMultiple samples continuous dataSimple Linear RegressionTwo-way anovaand understand apply techniques generally.","code":""},{"path":"resampling-intro.html","id":"background-1","chapter":"6 Introduction","heading":"6.2 Background","text":"traditional statistical test make use various named distributions (normally normal distribution, lol, parametric tests like t-test ANOVA) order work properly, require certain assumptions made parent distribution (shape distribution symmetric non-parametric tests like Wilcoxon). assumptions met traditional statistical tests fine, can can’t assume normality distribution data just weird?Resampling techniques tools work . can allow us test hypotheses data using data (without appeal assumptions shape form parent distribution). ways much simpler approach statistics, rely ability generate thousands tens thousands random numbers quickly, simply weren’t considered practical back day. Even now, aren’t widely used require user (, case ’d forgotten ’s going time day) click button stats package even know name test. techniques require mix statistical knowledge programming; combination skills isn’t common! three broad areas resampling methods (although quite closely related):Permutation MethodsBootstrappingCross-validationPermutation methods focus practical allow us carry hypothesis testing.Bootstrapping technique estimating confidence intervals parameter estimates. effectively treat dataset parent distribution, draw samples calculate statistic choice (mean usually) using sub-samples. repeat process many times, eventually able construct distribution sample statistic. can used give us confidence interval statistic.Cross-validation heart modern machine learning approaches existed long technique became sexy/fashionable. divide dataset two sets: training set use fit model testing set use evaluate model. allows model accuracy empirically measured. several variants technique (holdout, k-fold cross validation, leave-one--cross-validation (LOOCV), leave-p--cross-validation (LpOCV) etc.), essentially thing; main difference trade-amount time takes perform versus reliability method.won’t cover bootstrapping cross-validation practical feel free Google ..panelset{--panel-tab-font-family: inherit;}","code":"## Warning: 'xaringanExtra::style_panelset' is deprecated.\n## Use 'style_panelset_tabs' instead.\n## See help(\"Deprecated\")"},{},{"path":"single-predictor-permutation-tests.html","id":"single-predictor-permutation-tests","chapter":"7 Single predictor permutation tests","heading":"7 Single predictor permutation tests","text":"","code":""},{"path":"single-predictor-permutation-tests.html","id":"objectives-5","chapter":"7 Single predictor permutation tests","heading":"7.1 Objectives","text":"ObjectivesUnderstand resampling techniques work RBe able carry permutation techniques single predictorsBe able define statistic permuteUnderstand advantages limitations permutation techniques","code":""},{"path":"single-predictor-permutation-tests.html","id":"libraries-and-functions-3","chapter":"7 Single predictor permutation tests","heading":"7.2 Libraries and functions","text":"tidyverse","code":""},{"path":"single-predictor-permutation-tests.html","id":"purpose-and-aim","chapter":"7 Single predictor permutation tests","heading":"7.3 Purpose and aim","text":"wish test difference two groups case assumptions two-sample t-test just aren’t met, two-sample permutation test procedure appropriate. also appropriate even assumptions t-test met, case, easier just t-test.One additional benefits permutation test aren’t just restricted testing hypotheses means two groups. can test hypotheses absolutely anything want! , see ranges two groups differed significantly etc.","code":""},{"path":"single-predictor-permutation-tests.html","id":"data-and-hypotheses","chapter":"7 Single predictor permutation tests","heading":"7.4 Data and hypotheses","text":"Let’s consider experimental data set measured weights two groups 12 female mice (24 mice total). One group mice given perfectly normal diet (control) group mice given high fat diet several months. want test whether difference mean weight two groups. still need specify hypotheses:\\(H_0\\): difference means two groups\\(H_1\\): difference means two groups","code":""},{"path":"single-predictor-permutation-tests.html","id":"load-and-visualise-the-data","chapter":"7 Single predictor permutation tests","heading":"7.4.1 Load and visualise the data","text":"First load data, visualise .tidyverseIt looks mice fed high fat diet greater weight control (hardly surprising!). look bit closely calculate difference mean weight two groups:Let’s store value object called mice_diff.Right, difference two group means 3.02, hoorah! difference lot? unusual/big/statistically significant?Specifically, likely get difference big difference two groups? Let’s find !","code":"\n# load the data\nmice <- read_csv(\"data/mice.csv\")\n\n# view the data\nmice## # A tibble: 24 × 2\n##    diet    weight\n##    <chr>    <dbl>\n##  1 control   21.5\n##  2 control   28.1\n##  3 control   24.0\n##  4 control   23.4\n##  5 control   23.7\n##  6 control   19.8\n##  7 control   28.4\n##  8 control   21.0\n##  9 control   22.5\n## 10 control   20.1\n## # … with 14 more rows\nggplot(mice, aes(x = diet, y = weight)) +\n  geom_boxplot()\n# determine mean weight per group\nmice %>% \n  group_by(diet) %>%                         # split data by diet\n  summarise(mean_weight = mean(weight)) %>%  # calculate mean weight per group\n  ungroup() %>%                              # remove the grouping\n  pull(mean_weight) %>%                      # extract group values\n  diff()                                     # calculate the difference## [1] 3.020833"},{"path":"single-predictor-permutation-tests.html","id":"permutation-tests","chapter":"7 Single predictor permutation tests","heading":"7.5 Permutation Tests","text":"key idea behind permutation techniques null hypothesis true, difference two groups switch mice one group next wouldn’t change difference groups much. hand actually difference groups (one group much higher weights ), switch mice groups average two groups leading smaller difference group means., shuffle mice weights around lots lots times, calculating difference group means time. done shuffling hundreds thousands times, loads possible values difference two group means. stage can look actual difference (one calculated original data) see compares simulated differences.\ncan calculate many simulated differences bigger real difference proportion exactly p-value ’re looking !\nLet look carry practice.","code":""},{"path":"single-predictor-permutation-tests.html","id":"performing-permutation-tests","chapter":"7 Single predictor permutation tests","heading":"7.6 Performing permutation tests","text":"example ’ll using mice data set.Initialising random number generatorsBefore start resampling, ’s important initialise random number generator. Although ’s required analysis work, make analysis reproducible., results different every time ’d rerun analysis. problem, sake consistency materials ’re setting ‘seed’ random number generators.tidyverse\ndevelopment tidymodels package, reiterating analysis require looping data many times calculating statistic interest.Behind scenes, still ’s happening infer packages (part tidymodels) makes explicit verbose.workflow takes account several steps:specify() variables interest datahypothesise() define null hypothesisgenerate() replicatescalculate() summary statistic interestvisualise() resulting distribution confidence interval.case can fill steps:specify(weight ~ diet) state response variable ’re interested (weight) predictor variable (diet)hypothesise() two variables independent one another - order words, null hypothesis “world wonderful boring place, weight mice depend diet ’ve given.”generate() function generates (ha!) number resamples (reps = ...) uses permutation method (type = \"permute\"). can also bootstrapping draw theoretical distribution changing type. See ?generateNext, calculate() metric/statistic interest - see ?calculate options, statistic ’re interested difference means (\"diff means\") provide order want compare inWe store output object called mice_resampleLastly visualise() results, creates ggplot object. can add actual, calculated difference means (stored mice_diff) using shade_p_value() function - plots p-value region top outputGrab cup tea takes …base RSo, tell us? Well, can see difference means observed data - indicated vertical red line - quite far away right simulated null distribution.iteration, resample data 1,000 times, gives us single p-value. Remember created simulated distribution differences means, compare actual difference means. asked, likely ’re going see difference mean extreme one actually observed?get better sense reliable particularly p-value might , repeat whole process many times obtain resulting p-values visualise p-values distribution.tidyverseOne way getting p-value single iteration follows:p-value tells us , using threshold p < 0.05, possible observe difference means like , difference came distribution like one simulated.However, think can agree p-value awfully close arbitrary threshold ’ve imposed . useful find reliable p-value actually .order , want get distribution p-values, based simulated null distributions.want repeat iterations many times can wrap whole workflow used obtain p-value within replicate() function tell many times want repeat . repeat whole process 100 times.might get warning reporting p-value zero. depends number reps chosen generate() function. ’s low , due simulation-based nature package observed statistic extreme test statistic generated form null hypothesis. happens, approximate p-value zero. results warning, true p-value zero impossible (well, maybe experiment first place?).distribution shows us large chunk calculated p-values rather close p < 0.05 threshold. smaller, larger.? Well, personally report particular graph explain means quite uncertainty associated p-values. close threshold want draw firm conclusions whether deem difference weight means significant two diet groups.elaborate way saying “’m sure.” :-)","code":"\n# initialise the random number generator\nset.seed(123)\n\nmice_resample <- mice %>% \n  specify(weight ~ diet) %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(stat = \"diff in means\", order = c(\"control\", \"highfat\"))\n\nmice_resample %>% \n  visualise() +\n  shade_p_value(obs_stat = mice_diff, direction = \"two-sided\")\nset.seed(123)\nreps<-1000\nsim_diff<-numeric(reps)\nfor(i in 1:reps){\n  new_dat<-mice\n  new_dat$diet<-sample(new_dat$diet)\n  new_means <- aggregate(weight ~ diet , new_dat , mean)$weight\n  new_diff <- diff(new_means)\n  \n  sim_diff[i]<-new_diff  \n}\nhist(sim_diff , breaks = 30 , col=\"red\")\nabline(v = mice_diff , col=\"black\" , lwd=2)\n# get a two-tailed p-value\np_value <- mice_resample %>%\n  get_p_value(obs_stat = mice_diff, direction = \"two-sided\")\n\np_value## # A tibble: 1 × 1\n##   p_value\n##     <dbl>\n## 1   0.074\n# remove the set.seed()\n# otherwise we get the same result 100 times\nset.seed(NULL)\n\nresample_replicates <- replicate(100, mice %>% \n  specify(weight ~ diet) %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(\"diff in means\", order = c(\"control\", \"highfat\")) %>% \n  get_p_value(obs_stat = mice_diff, direction = \"two-sided\") %>% \n  # pull out the calculated p-value\n  pull()) %>% \n  # store the p-value in a tibble\n  as_tibble() %>% \n  # with a column for the repeat number\n  # and a column that contains the p-value\n  mutate(n_rep = 1:n(),\n         p_value = value) %>% \n  select(-value)\n\n# plot the data in a histogram\nggplot(resample_replicates, aes(x = p_value)) +\n  geom_histogram(bins = 10)"},{"path":"single-predictor-permutation-tests.html","id":"exercise-rats-on-a-wheel","chapter":"7 Single predictor permutation tests","heading":"7.7 Exercise: Rats on a wheel","text":"Exercise 7.1  data set data/rats.csv contains information length time 24 rats able stay balanced rotating wheel. 12 rats assigned control group 12 given dose centrally acting muscle relaxant. animals placed rotating cylinder length time rat remained cylinder measured, maximum 300 seconds. data set contains two variables time group.\nWhilst explore differences means two groups, case alternative statistic presents . look data notice control group 12 rats manage stay roller maximum 300 seconds, whereas treated group 5 12 fall earlier.exercise, instead calculating mean length time group, calculate proportion rats make 300s group find difference. statistic.Use permutation test decide whether proportion rats survive group.tidyverse\nlook stat options calculate() functiontidyverseAs always, let’s first load visualise data:lot overlap values (many rats manage stay wheel entire 300s), need jitter data bit.’re interested proportion rats make full 300s. , let’s calculate :, means proportion rats make full-time follows:Now, question , difference proportion likely ? check , resample data see likely proportional difference observe .answer : likely. One thing keep mind ’ve resampled thousand times . ’s really fair, since thousand different options possible due low sample size. However, just means responses occur often. able calculate exactly, without using resampling, bit headache. Importantly, really use technique much samples, ’s good illustration can use technique analyse different statistics.put number , can get p-value like :base R","code":"\nrats <- read_csv(\"data/rats.csv\")\n\nrats## # A tibble: 24 × 2\n##     time group  \n##    <dbl> <chr>  \n##  1   300 control\n##  2   300 control\n##  3   300 control\n##  4   300 control\n##  5   300 control\n##  6   300 control\n##  7   300 control\n##  8   300 control\n##  9   300 control\n## 10   300 control\n## # … with 14 more rows\nrats %>% \n  ggplot(aes(x = group, y = time)) +\n  geom_jitter(width = 0.1)\nrats <- rats %>% \n  group_by(group) %>% \n  mutate(full_time = time == 300,\n         full_time = as.character(full_time))\nfull_time_control = 12/12\nfull_time_treatment = 7/12\n\nrats_diff <- full_time_control - full_time_treatment\nset.seed(123)\nrats_resample <- rats %>% \n  specify(full_time ~ group, success = \"TRUE\") %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(\"diff in props\", order = c(\"control\", \"treatment\"))\n\nrats_resample %>% \n  visualise() +\n  shade_p_value(obs_stat = rats_diff, direction = \"two-sided\")\n# get a two-tailed p-value\np_value <- rats_resample %>%\n  get_p_value(obs_stat = rats_diff, direction = \"two-sided\")\n\np_value## # A tibble: 1 × 1\n##   p_value\n##     <dbl>\n## 1   0.038\nset.seed(123)\nrats_r <- read.csv(\"data/rats.csv\")\n\nunstRats<-unstack(rats_r)\n\npropControl <- length(\n  which(unstRats$control==300)) / length(unstRats$control)\n\npropTreatment <- length(\n  which(unstRats$treatment==300)) / length(unstRats$treatment)\n\nratDiff <- propControl - propTreatment\n\nnReps <- 1000\nsimRat<-numeric(nReps)\n\nfor(i in 1:nReps){\n  \n  newdat <- rats_r\n  newdat$group <- sample(newdat$group)\n  \n  newUnstRats <- unstack(newdat)\n  \n  newPropControl <- length(\n    which(newUnstRats$control==300))/length(newUnstRats$control)\n  \n  newPropTreatment <- length(\n    which(newUnstRats$treatment==300))/length(newUnstRats$treatment)\n  \n  newDiff <- newPropControl - newPropTreatment\n  \n  simRat[i] <- newDiff\n}\n\nhist(simRat, breaks = 30, col='red' , main=\"\" , xlab=\"Simulated Differences\")\nabline(v = ratDiff, col = \"black\", lwd = 2)\nabline(v = -ratDiff, col = \"black\", lwd = 2)"},{"path":"single-predictor-permutation-tests.html","id":"resampling-based-on-a-linear-regression","chapter":"7 Single predictor permutation tests","heading":"7.8 Resampling based on a linear regression","text":"far ’ve seen two examples can use permutation techniques look data: looking difference means (mice---diet example) comparing difference proportion (rats---wheel exercise).might noticed code little difference approach, good! ’re going adjust code slightly, can similar resampling exercise using linear model. look , ’re using data set penguins.tidyverseThe penguins data set part library called palmerpenguins, ’ll install load:Let’s attach data remove missing values. ’re also filter data one type penguin, just make analysis bit easier follow.can see 8 variables. ’ll come back later sessions, now ’re focussing 3:species type penguinflipper_length_mm length flipper mmbill_length_mm length bill mmTo practise, ’ll look relationship flipper length bill length, comparing two species selected.tidyverseLooking data, seems overall positive relationship flipper length bill length. relationship species-dependent, doesn’t seem much interaction going , since lines best fit pretty much parallel.Let’s look models resampling perspective.tidyverseFirst, specify model. ’re creating additive model, bill_length_mm depends flipper_length_mm species:aside, Power analysis session Core statistics looked model evaluation. something similar see interaction flipper_length_mm species:can see AIC value gets tiny bit worse drop interaction term. means species contributing model, although tiny bit.Next, fit models resamples data set:Lastly, can get p-value, comparing likely observed_fit based resampled fits simulated:, ’re likely get warning stating result approximation based number reps chosen. ’s unlikely true p-value zero.based , seems unlikely ’d get coefficients linear model data described best horizontal line (pretty obvious looking data!).Alternatively, can view plotting simulated null distributions placing coefficient values observed linear model top:can also compare looking confidence intervals simulated coefficients. ’re showing 95% confidence intervals, comparing observed values coefficients (.e. ones get fitting model actual data)., interpret results? Well, coefficients linear model fitted actual data miles away coefficients obtained simulated data. Remember, simulated data permuted (randomly shuffled) bill_length_mm values, refitted linear model calculated corresponding coefficients.fine relationship bill length, flipper length species. reshuffling data effect. clearly relationship variables, can see plotted data line best fit.Just satisfy curiosity (’re still point surely must curious!), can check normal approach, fit linear model perform ANOVA:Note ’ve included interaction flipper length species (flipper_length_mm:species) , consistent AIC result, ’s much data suggest interaction two variables.Finally, ANOVA confirms ’re seeing permutation test: data described best horizontal line, linear model able account good proportion variance data (adjusted R-squared value 0.37).","code":"\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\ndata(\"penguins\")\n\npenguins <- penguins %>%\n  filter(species != \"Adelie\") %>% \n  drop_na()\n\npenguins## # A tibble: 187 × 8\n##    species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n##    <fct>   <fct>           <dbl>         <dbl>             <int>       <int>\n##  1 Gentoo  Biscoe           46.1          13.2               211        4500\n##  2 Gentoo  Biscoe           50            16.3               230        5700\n##  3 Gentoo  Biscoe           48.7          14.1               210        4450\n##  4 Gentoo  Biscoe           50            15.2               218        5700\n##  5 Gentoo  Biscoe           47.6          14.5               215        5400\n##  6 Gentoo  Biscoe           46.5          13.5               210        4550\n##  7 Gentoo  Biscoe           45.4          14.6               211        4800\n##  8 Gentoo  Biscoe           46.7          15.3               219        5200\n##  9 Gentoo  Biscoe           43.3          13.4               209        4400\n## 10 Gentoo  Biscoe           46.8          15.4               215        5150\n## # … with 177 more rows, and 2 more variables: sex <fct>, year <int>\nggplot(penguins, aes(x = flipper_length_mm,\n                     y = bill_length_mm,\n                     colour = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\nobserved_fit <- penguins %>% \n  specify(bill_length_mm ~ flipper_length_mm + species) %>% \n  fit()\n# define the model\nlm_penguins <- lm(bill_length_mm ~ flipper_length_mm * species,\n                  data = penguins)\n\n# have a look at the coefficients\nsummary(lm_penguins)## \n## Call:\n## lm(formula = bill_length_mm ~ flipper_length_mm * species, data = penguins)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6.6977 -1.6578 -0.0014  1.4064 12.4394 \n## \n## Coefficients:\n##                                  Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                       5.59338    8.65665   0.646   0.5190    \n## flipper_length_mm                 0.22081    0.04418   4.998 1.35e-06 ***\n## speciesGentoo                   -26.08126   11.67592  -2.234   0.0267 *  \n## flipper_length_mm:speciesGentoo   0.09247    0.05702   1.622   0.1066    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.579 on 183 degrees of freedom\n## Multiple R-squared:  0.3774, Adjusted R-squared:  0.3672 \n## F-statistic: 36.97 on 3 and 183 DF,  p-value: < 2.2e-16\n# do a backwards stepwise elimination\nstats::step(lm_penguins)## Start:  AIC=358.28\n## bill_length_mm ~ flipper_length_mm * species\n## \n##                             Df Sum of Sq    RSS    AIC\n## <none>                                   1217.1 358.28\n## - flipper_length_mm:species  1    17.491 1234.6 358.95## \n## Call:\n## lm(formula = bill_length_mm ~ flipper_length_mm * species, data = penguins)\n## \n## Coefficients:\n##                     (Intercept)                flipper_length_mm  \n##                         5.59338                          0.22081  \n##                   speciesGentoo  flipper_length_mm:speciesGentoo  \n##                       -26.08126                          0.09247\npenguins_resample <- penguins %>% \n  specify(bill_length_mm ~ flipper_length_mm + species) %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  fit()\nget_p_value(penguins_resample, obs_stat = observed_fit, direction = \"two-sided\")## # A tibble: 3 × 2\n##   term              p_value\n##   <chr>               <dbl>\n## 1 flipper_length_mm       0\n## 2 intercept               0\n## 3 speciesGentoo           0\npenguins_resample %>% \n  visualise() +\n  shade_p_value(obs_stat = observed_fit, direction = \"two-sided\")\n# generate the 95% confidence intervals\nget_confidence_interval(\n  penguins_resample, \n  point_estimate = observed_fit, \n  level = .95\n)## # A tibble: 3 × 3\n##   term              lower_ci upper_ci\n##   <chr>                <dbl>    <dbl>\n## 1 flipper_length_mm  -0.0703   0.0753\n## 2 intercept          33.1     61.7   \n## 3 speciesGentoo      -1.91     1.78\n# display the coefficients of the observed linear model\nobserved_fit## # A tibble: 3 × 2\n##   term              estimate\n##   <chr>                <dbl>\n## 1 intercept           -5.28 \n## 2 flipper_length_mm    0.276\n## 3 speciesGentoo       -7.18\n# fit the model\nlm_penguins <- lm(bill_length_mm ~ flipper_length_mm * species,\n                  data = penguins)\n\n# check assumptions (which all look fine)\nlibrary(ggResidpanel)\nlm_penguins %>% \n  resid_panel(c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)\nanova(lm_penguins)## Analysis of Variance Table\n## \n## Response: bill_length_mm\n##                            Df  Sum Sq Mean Sq  F value    Pr(>F)    \n## flipper_length_mm           1   49.33   49.33   7.4174  0.007085 ** \n## species                     1  670.92  670.92 100.8749 < 2.2e-16 ***\n## flipper_length_mm:species   1   17.49   17.49   2.6298  0.106594    \n## Residuals                 183 1217.14    6.65                       \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"single-predictor-permutation-tests.html","id":"key-points-3","chapter":"7 Single predictor permutation tests","heading":"7.9 Key points","text":"Permutation techniques applicable regardless underlying distributionThey allow test non-standard metricsThey require sufficient dataWe can use workflow infer package, part tidymodels perform permutations dataWe specify() model, use hypothesise() define null hypothesis, generate() reshuffled data calculate() statistic interestWe can reiterate workflow obtain distribution p-values.panelset{--panel-tab-font-family: inherit;}","code":""},{},{"path":"principal-component-analysis-pca.html","id":"principal-component-analysis-pca","chapter":"8 Principal component analysis (PCA)","heading":"8 Principal component analysis (PCA)","text":"","code":""},{"path":"principal-component-analysis-pca.html","id":"objectives-6","chapter":"8 Principal component analysis (PCA)","heading":"8.1 Objectives","text":"Understand PCAs can usefulBe able perform PCALearn plot interpret screeplotPlot interpret loadings PCA","code":""},{"path":"principal-component-analysis-pca.html","id":"purpose-and-aim-1","chapter":"8 Principal component analysis (PCA)","heading":"8.2 Purpose and aim","text":"statistical technique reducing dimensionality data set. technique aims find new set variables describing data. new variables made weighted sum old variables. weighting chosen new variables can ranked terms importance first new variable chosen account much variation data possible. second new variable chosen account much remaining variation data possible, many new variables old variables.","code":""},{"path":"principal-component-analysis-pca.html","id":"libraries-and-functions-4","chapter":"8 Principal component analysis (PCA)","heading":"8.3 Libraries and functions","text":"tidyverse","code":""},{"path":"principal-component-analysis-pca.html","id":"data","chapter":"8 Principal component analysis (PCA)","heading":"8.4 Data","text":"First need data! liven things bit, ’ll using data palmerpenguins package. package whole bunch data penguins. ’s love?Penguins\npenguins data set comes palmerpenguins package (information, see GitHub page).","code":""},{"path":"principal-component-analysis-pca.html","id":"visualise-the-data-4","chapter":"8 Principal component analysis (PCA)","heading":"8.5 Visualise the data","text":"First , let’s look data. always good idea get sense data look like.tidyverse\nFirst, load inspect data:can see different kinds variables, factors numerical. Also, appear missing data data set, probably deal .Lastly, careful year column: recognised numerical column (contains numbers), view factor, since years categorical meaning.get better sense data plot numerical variables , see possible correlation . However, quite , might easier just create correlation matrix.tidyverse\nFirst, load corrr package, allows us plot correlation matrix using tidyverse syntax:get message (error) correlation method used pearson, default. also get message missing values treated, complete pairwise comparisons made.Lastly, plotting matrix also get message ggplot() knowing automatically pick scale - defaulting continuous. ’s fine us, since correlation coefficients continuous scale.can see , example, strong positive correlation flipper_length_mm body_mass_g. variable combinations seem reasonably well-correlated, flipper_length_mm bill_length_mm (positive) flipper_length_mm bill_depth_mm (negative).many different variables appear correlated , just lots variables data don’t know look, can useful reduce number variables. can dimension reduction methods, Principal Component Analysis (PCA) one.Basically, PCA replaces original variables new ones: principal components. principal components consist parts original variables.compare smoothy consisting , let’s say, 80% orange, 10% strawberry 10% banana (kale).Similarly, new principal component consist 80% flipper_length_mm, 10% body_mass_g 10% bill_depth_mm (still kale).","code":"\n# attach the data\ndata(package = 'palmerpenguins')\n\n# inspect the data\npenguins## # A tibble: 344 × 8\n##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n##    <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n##  1 Adelie  Torgersen           39.1          18.7               181        3750\n##  2 Adelie  Torgersen           39.5          17.4               186        3800\n##  3 Adelie  Torgersen           40.3          18                 195        3250\n##  4 Adelie  Torgersen           NA            NA                  NA          NA\n##  5 Adelie  Torgersen           36.7          19.3               193        3450\n##  6 Adelie  Torgersen           39.3          20.6               190        3650\n##  7 Adelie  Torgersen           38.9          17.8               181        3625\n##  8 Adelie  Torgersen           39.2          19.6               195        4675\n##  9 Adelie  Torgersen           34.1          18.1               193        3475\n## 10 Adelie  Torgersen           42            20.2               190        4250\n## # … with 334 more rows, and 2 more variables: sex <fct>, year <int>\nlibrary(corrr)\n\npenguins_corr <- penguins %>%\n  select(where(is.numeric)) %>%  # select the numerical columns\n  correlate() %>%                # calculate the correlations\n  shave()## \n## Correlation method: 'pearson'\n## Missing treated using: 'pairwise.complete.obs'\n# plot the correlation matrix\npenguins_corr %>%\n  rplot()## Don't know how to automatically pick scale for object of type noquote. Defaulting to continuous."},{"path":"principal-component-analysis-pca.html","id":"performing-the-pca","chapter":"8 Principal component analysis (PCA)","heading":"8.6 Performing the PCA","text":"tidyverse\nperform PCA, ’ll use recipe() pre-processing steps:remove NA valuescentre predictorsscale predictors","code":"\npenguin_recipe <-\n  # take all variables\n  recipe(~ ., data = penguins) %>% \n  # specify the ID columns (non-numerical)\n  update_role(species, island, sex, year, new_role = \"id\") %>% \n  # remove missing values\n  step_naomit(all_predictors()) %>% \n  # scale the data\n  step_normalize(all_predictors()) %>%\n  # perform the PCA\n  step_pca(all_predictors(), id = \"pca\") %>% \n  # prepares the recipe by estimating the required parameters\n  prep()\n\npenguin_pca <- \n  penguin_recipe %>% \n  tidy(id = \"pca\") \n\npenguin_pca## # A tibble: 16 × 4\n##    terms                value component id   \n##    <chr>                <dbl> <chr>     <chr>\n##  1 bill_length_mm     0.455   PC1       pca  \n##  2 bill_depth_mm     -0.400   PC1       pca  \n##  3 flipper_length_mm  0.576   PC1       pca  \n##  4 body_mass_g        0.548   PC1       pca  \n##  5 bill_length_mm    -0.597   PC2       pca  \n##  6 bill_depth_mm     -0.798   PC2       pca  \n##  7 flipper_length_mm -0.00228 PC2       pca  \n##  8 body_mass_g       -0.0844  PC2       pca  \n##  9 bill_length_mm    -0.644   PC3       pca  \n## 10 bill_depth_mm      0.418   PC3       pca  \n## 11 flipper_length_mm  0.232   PC3       pca  \n## 12 body_mass_g        0.597   PC3       pca  \n## 13 bill_length_mm     0.146   PC4       pca  \n## 14 bill_depth_mm     -0.168   PC4       pca  \n## 15 flipper_length_mm -0.784   PC4       pca  \n## 16 body_mass_g        0.580   PC4       pca"},{"path":"principal-component-analysis-pca.html","id":"visualising-pcs","chapter":"8 Principal component analysis (PCA)","heading":"8.7 Visualising PCs","text":"Now ’ve performed PCA, can bit closer look. useful way looking much PCs (principal components) contributing amount variance explained create screeplot. Basically, plots percentage explained variance PC.tidyverse\ncan extract relevant data directly penguin_recipe object:definition, first principal component (PC1) always explain largest amount variation. case, PC1 explains almost 70% variance!’s pretty good going, since means instead look four variables, look just one still capture 70% variance data. number variables data set manageable, probably wouldn’t . However, data set hundreds variables, seeing can described well using PCs useful thing .","code":"\npenguin_recipe %>% \n  tidy(id = \"pca\", type = \"variance\") %>% \n  filter(terms == \"percent variance\") %>% \n  ggplot(aes(x = component, y = value)) + \n  geom_col() + \n  xlim(c(0, 5)) +\n  ylab(\"% of total variance\")"},{"path":"principal-component-analysis-pca.html","id":"loadings","chapter":"8 Principal component analysis (PCA)","heading":"8.8 Loadings","text":"Let’s think back smoothy metaphor. Remember smoothy made various fruits - just like PCs made parts original variables.Let’s, sake illustrating , assume following PC1:PC something called eigenvector, simplest terms line certain direction length.want calculate length eigenvector PC1, can employ Pythagoras (well, directly, just legacy). gives:\\(eigenvector \\, PC1 = \\sqrt{4^2 + 1^2} = 4.12\\)loading scores PC1 “parts” scaled length, .e.:can values plot loadings original variables. example, plotted PC1 PC2, wanted see much original variables contribute principal component, following:tidyverse\nloadings encoded value column pca object (penguin_pca). plot , need data “wide” format:can see four terms (original variables) four PCs. makes sense, maximum number principal components exceed number original variables.need bit data gymnastics, defining arrow style (vectors represented using arrows), plotting PCs, plotting loadings.Arrow:plot PC1 vs PC2, need extract relevant data. PCA-related data stored penguin_recipe object. Since people developed tidymodels quite fond verbs (’m really adjective kind--guy …) invented bake() function.logic : follow recipe() bake() . Yes, know.Anyways, use get data penguin_recipe, telling function shouldn’t expect new data (function also used model testing, data split training test data set).spits original table, PC values instead original variables. can use information plot PCs, focussing PC1 vs PC2:Lastly (finally), take plot add loading data top :Slightly annoyingly, can cause overlap labels. Also, many different variables , ’ll become rather tricky interpret web vectors.things look pretty OK still. One thing immediately obvious data Gentoo penguins PCs quite distinct Adelie Chinstrap penguins.PC-perspective, flipper_length_mm body_mass_g variables make PC1, since vectors almost horizontal.contrast, bill_length_mm bill_depth_mm contribute lot PC2. also contribute positively (bill_length_mm) negatively (bill_depth_mm) PC1.mentioned, vectors can become bit messy terms visualisation. can useful represent loadings differently. Note , point, ’m aware method allows reasonably straightforward anything R’s tidyverse.tidyverse\nfollowing work, need load tidytext libary. can follows:gives us loadings variable, facetted principal component. reason ’re plotting absolute values, can compare positive negative contributions. PC absolute loadings sorted descending order. distinguish positive negative loadings use colours.important keep amount variance explained PC mind. example, PC3 explains around 9% variance. although bill length body mass contribute substantially PC3, contribution PC3 remains small.","code":"\n# get pca loadings into wider format\npca_wider <- penguin_pca %>% \n  pivot_wider(names_from = component, id_cols = terms)\n\npca_wider## # A tibble: 4 × 5\n##   terms                PC1      PC2    PC3    PC4\n##   <chr>              <dbl>    <dbl>  <dbl>  <dbl>\n## 1 bill_length_mm     0.455 -0.597   -0.644  0.146\n## 2 bill_depth_mm     -0.400 -0.798    0.418 -0.168\n## 3 flipper_length_mm  0.576 -0.00228  0.232 -0.784\n## 4 body_mass_g        0.548 -0.0844   0.597  0.580\n# define arrow style\narrow_style <- arrow(length = unit(2, \"mm\"),\n                     type = \"closed\")\nbake(penguin_recipe, new_data = NULL)## # A tibble: 342 × 8\n##    species island    sex     year    PC1      PC2     PC3     PC4\n##    <fct>   <fct>     <fct>  <int>  <dbl>    <dbl>   <dbl>   <dbl>\n##  1 Adelie  Torgersen male    2007 -1.84  -0.0476   0.232   0.523 \n##  2 Adelie  Torgersen female  2007 -1.30   0.428    0.0295  0.402 \n##  3 Adelie  Torgersen female  2007 -1.37   0.154   -0.198  -0.527 \n##  4 Adelie  Torgersen female  2007 -1.88   0.00205  0.618  -0.478 \n##  5 Adelie  Torgersen male    2007 -1.91  -0.828    0.686  -0.207 \n##  6 Adelie  Torgersen female  2007 -1.76   0.351   -0.0276  0.504 \n##  7 Adelie  Torgersen male    2007 -0.809 -0.522    1.33    0.338 \n##  8 Adelie  Torgersen <NA>    2007 -1.83   0.769    0.689  -0.427 \n##  9 Adelie  Torgersen <NA>    2007 -1.19  -1.02     0.729   0.333 \n## 10 Adelie  Torgersen <NA>    2007 -1.73   0.787   -0.205   0.0205\n## # … with 332 more rows\npca_plot <-\n  bake(penguin_recipe, new_data = NULL) %>%\n  ggplot(aes(PC1, PC2)) +\n  geom_point(aes(colour = species), # colour the data\n             alpha = 0.8,           # add transparency\n             size = 2)              # make the data points bigger\n\npca_plot\npca_plot +\n  # define the vector\n  geom_segment(data = pca_wider,\n               aes(xend = PC1, yend = PC2), \n               x = 0, \n               y = 0, \n               arrow = arrow_style) + \n  # add the text labels\n  geom_text(data = pca_wider,\n            aes(x = PC1, y = PC2, label = terms), \n            hjust = 0, \n            vjust = 1,\n            size = 5) \nlibrary(tidytext)\npenguin_pca %>%\n  mutate(terms = reorder_within(terms, \n                                abs(value), \n                                component)) %>%\n  ggplot(aes(abs(value), terms, fill = value > 0)) +\n  geom_col() +\n  facet_wrap(~ component, scales = \"free_y\") +\n  tidytext::scale_y_reordered() +\n  labs(\n    x = \"Absolute value of contribution\",\n    y = NULL, fill = \"Positive?\"\n  ) "},{"path":"principal-component-analysis-pca.html","id":"exercise-heptathlon","chapter":"8 Principal component analysis (PCA)","heading":"8.9 Exercise: Heptathlon","text":"Exercise 8.1  First , heptathlon actual word. Seven sports events one go! old data set keeps track scores/times 25 athletes heptathlon event. can’t remember data collected, main reason ’ve kept show fleeting concept ‘country’ . good proportion countries longer exist…Let’s get philosophical see can data set. like following:load datacreate correlation matrix visualise highly correlated pairperform PCAcreate screeplot see many PCs bestcalculate loadings PC1 PC2 visualise themtidyverseload dataNote many country codes changed (URS, GDR, FRG!). Also, humbug, HOL ‘Holland’ country, Netherlands !. search see world constantly changing…create correlation matrix visualise highly correlated pairLooking correlation matrix, highly correlated pair longjump hurdles (-0.91). () programmatically, ’s small matrix life short.seems better long jump, faster (thus better) hurdles. guess makes sense interesting data leg length see correlation …perform PCAcreate screeplot see many PCs bestIt’s clear PC1 explains heck lot variance data (around 65%). PC2 explains bit , just 20%. two PCs combined explain 85% variance data, pretty good.Things get bit less clear go “” PCs: PC3 PC4 explain roughly amount variance, ’d include PC3 also include PC4. However, since explain around 8% variance contribute much, leave PC1 PC2.calculate loadings PC1 PC2 visualise themWith 7 original variables, plotting PC1 PC2 loadings bit unclear. case ’ll just create bar chart PC absolute contributions original variable.Just illustrate much informative drawing vectors:Told ya.Well, can conclude ? First , ’s worth noting 25 observations 7 variables, limits analysis bit.can see PC1 (particularly combined PC2) able explain quite big chunk variance data. However, keep mind observation individual athlete. ideally want plot names athletes PC1 vs PC2 plot see individual performances 7 events compare.","code":"\nhept <- read_csv(\"data/heptathlon.csv\")\n\nhept## # A tibble: 25 × 8\n##    athlete             hurdles highjump  shot run200m longjump javelin run800m\n##    <chr>                 <dbl>    <dbl> <dbl>   <dbl>    <dbl>   <dbl>   <dbl>\n##  1 Joyner-Kersee (USA)    12.7     1.86  15.8    22.6     7.27    45.7    129.\n##  2 John (GDR)             12.8     1.8   16.2    23.6     6.71    42.6    126.\n##  3 Behmer (GDR)           13.2     1.83  14.2    23.1     6.68    44.5    124.\n##  4 Sablovskaite (URS)     13.6     1.8   15.2    23.9     6.25    42.8    132.\n##  5 Choubenkova (URS)      13.5     1.74  14.8    23.9     6.32    47.5    128.\n##  6 Schulz (GDR)           13.8     1.83  13.5    24.6     6.33    42.8    126.\n##  7 Fleming (AUS)          13.4     1.8   12.9    23.6     6.37    40.3    133.\n##  8 Greiner (USA)          13.6     1.8   14.1    24.5     6.47    38      134.\n##  9 Lajbnerova (CZE)       13.6     1.83  14.3    24.9     6.11    42.2    136.\n## 10 Bouraga (URS)          13.2     1.77  12.6    23.6     6.28    39.1    135.\n## # … with 15 more rows\nhept_corr <- hept %>%\n  select(where(is.numeric)) %>%  # select the numerical columns\n  correlate() %>%                # calculate the correlations\n  rearrange()                    # arrange highly correlated variables together## \n## Correlation method: 'pearson'\n## Missing treated using: 'pairwise.complete.obs'\nhept_corr## # A tibble: 7 × 8\n##   term      hurdles run200m run800m  javelin   shot highjump longjump\n##   <chr>       <dbl>   <dbl>   <dbl>    <dbl>  <dbl>    <dbl>    <dbl>\n## 1 hurdles  NA         0.774  0.779  -0.00776 -0.651 -0.811    -0.912 \n## 2 run200m   0.774    NA      0.617  -0.333   -0.683 -0.488    -0.817 \n## 3 run800m   0.779     0.617 NA       0.0200  -0.420 -0.591    -0.700 \n## 4 javelin  -0.00776  -0.333  0.0200 NA        0.269  0.00215   0.0671\n## 5 shot     -0.651    -0.683 -0.420   0.269   NA      0.441     0.743 \n## 6 highjump -0.811    -0.488 -0.591   0.00215  0.441 NA         0.782 \n## 7 longjump -0.912    -0.817 -0.700   0.0671   0.743  0.782    NA\nggplot(data = hept,\n       aes(x = longjump,\n           y = hurdles)) +\n  geom_point() +\n  labs(title = \"longjump vs hurdles\")\nhept_recipe <-\n  # take all variables\n  recipe(~ ., data = hept) %>% \n  # specify the ID columns (non-numerical)\n  update_role(athlete, new_role = \"id\") %>% \n  # remove missing values\n  step_naomit(all_predictors()) %>% \n  # scale the data\n  step_normalize(all_predictors()) %>%\n  # perform the PCA\n  step_pca(all_predictors(), id = \"pca\") %>% \n  # prepares the recipe by estimating the required parameters\n  prep()\n\nhept_pca <- \n  hept_recipe %>% \n  tidy(id = \"pca\") \n\nhept_pca## # A tibble: 49 × 4\n##    terms      value component id   \n##    <chr>      <dbl> <chr>     <chr>\n##  1 hurdles   0.453  PC1       pca  \n##  2 highjump -0.377  PC1       pca  \n##  3 shot     -0.363  PC1       pca  \n##  4 run200m   0.408  PC1       pca  \n##  5 longjump -0.456  PC1       pca  \n##  6 javelin  -0.0754 PC1       pca  \n##  7 run800m   0.375  PC1       pca  \n##  8 hurdles  -0.158  PC2       pca  \n##  9 highjump  0.248  PC2       pca  \n## 10 shot     -0.289  PC2       pca  \n## # … with 39 more rows\nhept_recipe %>% \n  tidy(id = \"pca\", type = \"variance\") %>% \n  filter(terms == \"percent variance\") %>% \n  ggplot(aes(x = component, y = value)) + \n  geom_col() + \n  ylab(\"% of total variance\")\nhept_pca %>%\n  filter(component %in% c(\"PC1\", \"PC2\")) %>% \n  mutate(terms = reorder_within(terms, \n                                abs(value), \n                                component)) %>%\n  ggplot(aes(abs(value), terms, fill = value > 0)) +\n  geom_col() +\n  facet_wrap(~ component, scales = \"free_y\") +\n  tidytext::scale_y_reordered() +\n  labs(\n    x = \"Absolute value of contribution\",\n    y = NULL, fill = \"Positive?\"\n  ) \n# get pca loadings into wider format\npca_wider <- hept_pca %>% \n  pivot_wider(names_from = component, id_cols = terms)\n\npca_plot <-\n  bake(hept_recipe, new_data = NULL) %>%\n  ggplot(aes(PC1, PC2)) +\n  geom_point(alpha = 0.8, # add transparency\n             size = 2)    # make the data points bigger\n\n# define arrow style\narrow_style <- arrow(length = unit(2, \"mm\"),\n                     type = \"closed\")\n\npca_plot +\n  # define the vector\n  geom_segment(data = pca_wider,\n               aes(xend = PC1, yend = PC2), \n               x = 0, \n               y = 0, \n               arrow = arrow_style,\n               colour = \"red\") + \n  # add the text labels\n  geom_text(data = pca_wider,\n            aes(x = PC1, y = PC2, label = terms), \n            hjust = 0, \n            vjust = 1,\n            size = 5) "},{"path":"principal-component-analysis-pca.html","id":"load-the-data","chapter":"8 Principal component analysis (PCA)","heading":"8.9.1 Load the data","text":"load dataNote many country codes changed (URS, GDR, FRG!). Also, humbug, HOL ‘Holland’ country, Netherlands !. search see world constantly changing…","code":"\nhept <- read_csv(\"data/heptathlon.csv\")\n\nhept## # A tibble: 25 × 8\n##    athlete             hurdles highjump  shot run200m longjump javelin run800m\n##    <chr>                 <dbl>    <dbl> <dbl>   <dbl>    <dbl>   <dbl>   <dbl>\n##  1 Joyner-Kersee (USA)    12.7     1.86  15.8    22.6     7.27    45.7    129.\n##  2 John (GDR)             12.8     1.8   16.2    23.6     6.71    42.6    126.\n##  3 Behmer (GDR)           13.2     1.83  14.2    23.1     6.68    44.5    124.\n##  4 Sablovskaite (URS)     13.6     1.8   15.2    23.9     6.25    42.8    132.\n##  5 Choubenkova (URS)      13.5     1.74  14.8    23.9     6.32    47.5    128.\n##  6 Schulz (GDR)           13.8     1.83  13.5    24.6     6.33    42.8    126.\n##  7 Fleming (AUS)          13.4     1.8   12.9    23.6     6.37    40.3    133.\n##  8 Greiner (USA)          13.6     1.8   14.1    24.5     6.47    38      134.\n##  9 Lajbnerova (CZE)       13.6     1.83  14.3    24.9     6.11    42.2    136.\n## 10 Bouraga (URS)          13.2     1.77  12.6    23.6     6.28    39.1    135.\n## # … with 15 more rows"},{"path":"principal-component-analysis-pca.html","id":"correlations","chapter":"8 Principal component analysis (PCA)","heading":"8.9.2 Correlations","text":"create correlation matrix visualise highly correlated pairLooking correlation matrix, highly correlated pair longjump hurdles (-0.91). () programmatically, ’s small matrix life short.seems better long jump, faster (thus better) hurdles. guess makes sense interesting data leg length see correlation …","code":"\nhept_corr <- hept %>%\n  select(where(is.numeric)) %>%  # select the numerical columns\n  correlate() %>%                # calculate the correlations\n  rearrange()                    # arrange highly correlated variables together## \n## Correlation method: 'pearson'\n## Missing treated using: 'pairwise.complete.obs'\nhept_corr## # A tibble: 7 × 8\n##   term      hurdles run200m run800m  javelin   shot highjump longjump\n##   <chr>       <dbl>   <dbl>   <dbl>    <dbl>  <dbl>    <dbl>    <dbl>\n## 1 hurdles  NA         0.774  0.779  -0.00776 -0.651 -0.811    -0.912 \n## 2 run200m   0.774    NA      0.617  -0.333   -0.683 -0.488    -0.817 \n## 3 run800m   0.779     0.617 NA       0.0200  -0.420 -0.591    -0.700 \n## 4 javelin  -0.00776  -0.333  0.0200 NA        0.269  0.00215   0.0671\n## 5 shot     -0.651    -0.683 -0.420   0.269   NA      0.441     0.743 \n## 6 highjump -0.811    -0.488 -0.591   0.00215  0.441 NA         0.782 \n## 7 longjump -0.912    -0.817 -0.700   0.0671   0.743  0.782    NA\nggplot(data = hept,\n       aes(x = longjump,\n           y = hurdles)) +\n  geom_point() +\n  labs(title = \"longjump vs hurdles\")"},{"path":"principal-component-analysis-pca.html","id":"pca","chapter":"8 Principal component analysis (PCA)","heading":"8.9.3 PCA","text":"perform PCA","code":"\nhept_recipe <-\n  # take all variables\n  recipe(~ ., data = hept) %>% \n  # specify the ID columns (non-numerical)\n  update_role(athlete, new_role = \"id\") %>% \n  # remove missing values\n  step_naomit(all_predictors()) %>% \n  # scale the data\n  step_normalize(all_predictors()) %>%\n  # perform the PCA\n  step_pca(all_predictors(), id = \"pca\") %>% \n  # prepares the recipe by estimating the required parameters\n  prep()\n\nhept_pca <- \n  hept_recipe %>% \n  tidy(id = \"pca\") \n\nhept_pca## # A tibble: 49 × 4\n##    terms      value component id   \n##    <chr>      <dbl> <chr>     <chr>\n##  1 hurdles   0.453  PC1       pca  \n##  2 highjump -0.377  PC1       pca  \n##  3 shot     -0.363  PC1       pca  \n##  4 run200m   0.408  PC1       pca  \n##  5 longjump -0.456  PC1       pca  \n##  6 javelin  -0.0754 PC1       pca  \n##  7 run800m   0.375  PC1       pca  \n##  8 hurdles  -0.158  PC2       pca  \n##  9 highjump  0.248  PC2       pca  \n## 10 shot     -0.289  PC2       pca  \n## # … with 39 more rows"},{"path":"principal-component-analysis-pca.html","id":"screeplot","chapter":"8 Principal component analysis (PCA)","heading":"8.9.4 Screeplot","text":"create screeplot see many PCs bestIt’s clear PC1 explains heck lot variance data (around 65%). PC2 explains bit , just 20%. two PCs combined explain 85% variance data, pretty good.Things get bit less clear go “” PCs: PC3 PC4 explain roughly amount variance, ’d include PC3 also include PC4. However, since explain around 8% variance contribute much, leave PC1 PC2.","code":"\nhept_recipe %>% \n  tidy(id = \"pca\", type = \"variance\") %>% \n  filter(terms == \"percent variance\") %>% \n  ggplot(aes(x = component, y = value)) + \n  geom_col() + \n  ylab(\"% of total variance\")"},{"path":"principal-component-analysis-pca.html","id":"loadings-1","chapter":"8 Principal component analysis (PCA)","heading":"8.9.5 Loadings","text":"calculate loadings PC1 PC2 visualise themWith 7 original variables, plotting PC1 PC2 loadings bit unclear. case ’ll just create bar chart PC absolute contributions original variable.Just illustrate much informative drawing vectors:Told ya.","code":"\nhept_pca %>%\n  filter(component %in% c(\"PC1\", \"PC2\")) %>% \n  mutate(terms = reorder_within(terms, \n                                abs(value), \n                                component)) %>%\n  ggplot(aes(abs(value), terms, fill = value > 0)) +\n  geom_col() +\n  facet_wrap(~ component, scales = \"free_y\") +\n  tidytext::scale_y_reordered() +\n  labs(\n    x = \"Absolute value of contribution\",\n    y = NULL, fill = \"Positive?\"\n  ) \n# get pca loadings into wider format\npca_wider <- hept_pca %>% \n  pivot_wider(names_from = component, id_cols = terms)\n\npca_plot <-\n  bake(hept_recipe, new_data = NULL) %>%\n  ggplot(aes(PC1, PC2)) +\n  geom_point(alpha = 0.8, # add transparency\n             size = 2)    # make the data points bigger\n\n# define arrow style\narrow_style <- arrow(length = unit(2, \"mm\"),\n                     type = \"closed\")\n\npca_plot +\n  # define the vector\n  geom_segment(data = pca_wider,\n               aes(xend = PC1, yend = PC2), \n               x = 0, \n               y = 0, \n               arrow = arrow_style,\n               colour = \"red\") + \n  # add the text labels\n  geom_text(data = pca_wider,\n            aes(x = PC1, y = PC2, label = terms), \n            hjust = 0, \n            vjust = 1,\n            size = 5) "},{"path":"principal-component-analysis-pca.html","id":"conclusion","chapter":"8 Principal component analysis (PCA)","heading":"8.9.6 Conclusion","text":"Well, can conclude ? First , ’s worth noting 25 observations 7 variables, limits analysis bit.can see PC1 (particularly combined PC2) able explain quite big chunk variance data. However, keep mind observation individual athlete. ideally want plot names athletes PC1 vs PC2 plot see individual performances 7 events compare.","code":""},{"path":"principal-component-analysis-pca.html","id":"key-points-4","chapter":"8 Principal component analysis (PCA)","heading":"8.10 Key points","text":"PCA allows reduce large number variables fewer principal componentsEach PC made combination original variables captures much variance within data possibleThe loadings tell much original variable contributes PCA screeplot graphical representation amount variance explained PC.panelset{--panel-tab-font-family: inherit;}","code":""},{},{"path":"kmeans.html","id":"kmeans","chapter":"9 K-means clustering","heading":"9 K-means clustering","text":"","code":""},{"path":"kmeans.html","id":"objectives-7","chapter":"9 K-means clustering","heading":"9.1 Objectives","text":"Understand k-means clustering worksBe able perform k-means clusteringBe able optimise cluster number","code":""},{"path":"kmeans.html","id":"libraries-and-functions-5","chapter":"9 K-means clustering","heading":"9.2 Libraries and functions","text":"tidyversebase RPython","code":"from plotnine import *\nimport pandas as pd\nfrom datar.all import *from pipda import options\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import StandardScaler\n\noptions.assume_all_piping = True"},{"path":"kmeans.html","id":"workflow","chapter":"9 K-means clustering","heading":"9.3 Workflow","text":"K-means clustering iterative process. follows following steps:Select number clusters identify (e.g. K = 3)Create centroidsPlace centroids randomly dataAssign data point closest centroidCalculate centroid new clusterRepeat steps 4-5 clusters change","code":""},{"path":"kmeans.html","id":"data-1","chapter":"9 K-means clustering","heading":"9.4 Data","text":"example, ’ll using penguin data set.Penguins\npenguins data set comes palmerpenguins package (information, see GitHub page).Darwin’s finches\nfinches dataset adapted accompanying website 40 years evolution. Darwin’s finches Daphne Major Island Peter R. Grant Rosemary B. Grant.really interesting lecture findings Grants can found (1h10min).","code":"\n# load the data\nfinches <- read_csv(\"data/finch_beaks.csv\")"},{"path":"kmeans.html","id":"visualise-the-data-5","chapter":"9 K-means clustering","heading":"9.5 Visualise the data","text":"First , let’s look data. always good idea get sense data.tidyverse\nFirst, load inspect data:Next, plot data:base R\nFirst, load inspect data:Next, plot data:Python\npalmerpenguins package available Python, ’ve provided data separately. load data Python following:Next, plot data:different types penguins, different islands. Bill flipper measurements taken, penguins’ weight plus sex recorded.example, also look bill depth versus bill length.can already see data appear cluster quite closely species. great example illustrate K-means clustering (’d almost think chose example purpose!)","code":"\n# attach the data\ndata(package = 'palmerpenguins')\n\n# inspect the data\npenguins## # A tibble: 344 × 8\n##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n##    <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n##  1 Adelie  Torgersen           39.1          18.7               181        3750\n##  2 Adelie  Torgersen           39.5          17.4               186        3800\n##  3 Adelie  Torgersen           40.3          18                 195        3250\n##  4 Adelie  Torgersen           NA            NA                  NA          NA\n##  5 Adelie  Torgersen           36.7          19.3               193        3450\n##  6 Adelie  Torgersen           39.3          20.6               190        3650\n##  7 Adelie  Torgersen           38.9          17.8               181        3625\n##  8 Adelie  Torgersen           39.2          19.6               195        4675\n##  9 Adelie  Torgersen           34.1          18.1               193        3475\n## 10 Adelie  Torgersen           42            20.2               190        4250\n## # … with 334 more rows, and 2 more variables: sex <fct>, year <int>\nggplot(penguins, aes(x = bill_depth_mm,\n                     y = bill_length_mm,\n                     colour = species)) +\n  geom_point()\n# attach the data\ndata(package = 'palmerpenguins')\n\n# inspect the data\nhead(penguins)## # A tibble: 6 × 8\n##   species island bill_length_mm bill_depth_mm flipper_length_… body_mass_g sex  \n##   <fct>   <fct>           <dbl>         <dbl>            <int>       <int> <fct>\n## 1 Adelie  Torge…           39.1          18.7              181        3750 male \n## 2 Adelie  Torge…           39.5          17.4              186        3800 fema…\n## 3 Adelie  Torge…           40.3          18                195        3250 fema…\n## 4 Adelie  Torge…           NA            NA                 NA          NA <NA> \n## 5 Adelie  Torge…           36.7          19.3              193        3450 fema…\n## 6 Adelie  Torge…           39.3          20.6              190        3650 male \n## # … with 1 more variable: year <int>\nplot(penguins$bill_depth_mm,      # scatter plot\n     penguins$bill_length_mm,\n     pch = 20,\n     col = penguins$species)      # colour by species\n\nlegend(\"bottomright\",             # legend\n       legend = levels(penguins$species),\n       pch = 20,\n       col = factor(levels(penguins$species)))# load the data\npenguins = pd.read_csv('data/penguins.csv')\n\n# inspect the data\npenguins.head()##    species     island  bill_length_mm  ...  body_mass_g      sex    year\n##   <object>   <object>       <float64>  ...    <float64> <object> <int64>\n## 0   Adelie  Torgersen            39.1  ...       3750.0     male    2007\n## 1   Adelie  Torgersen            39.5  ...       3800.0   female    2007\n## 2   Adelie  Torgersen            40.3  ...       3250.0   female    2007\n## 3   Adelie  Torgersen             NaN  ...          NaN      NaN    2007\n## 4   Adelie  Torgersen            36.7            3450.0   female    2007\n## \n## [5 rows x 8 columns](\n  ggplot(penguins,\n    aes(x = 'bill_depth_mm',\n        y = 'bill_length_mm',\n        colour = 'species'))\n  + geom_point()\n)"},{"path":"kmeans.html","id":"exercise---flipper-and-bill-length","chapter":"9 K-means clustering","heading":"9.6 Exercise - Flipper and bill length","text":"Exercise 9.1  exercise ’d like create scatter plot flipper length bill length. ’ll using colour separate female/male data. Lastly, ’re creating individual panels island.code given like replace <FIXME> parts required code.think many clusters try divide data .tidyversebase R\nThings bit convoluted using base R, compared tidyverse. ’s faceting equivalent can implement directly.split data island create loop plot island. ’m loathe go , ’ll just use Biscoe island example ’m sure ’re able adapt things accordingly Dream Torgersen islands!Pythontidyversebase RPython","code":"penguins %>% \n  drop_na() %>%                     \n  ggplot(aes(x = <FIXME>,\n             y = bill_length_mm,\n             colour = <FIXME>)) +\n  geom_<FIXME>() +\n  facet_wrap(facets = vars(<FIXME>))biscoe <- \n  penguins[penguins$island == '<FIXME>', ]\n\nplot(biscoe$<FIXME>,\n     biscoe$bill_length_mm,\n     pch = 20,\n     col = biscoe$<FIXME>)\n\nlegend(\"bottomright\",\n       legend = levels(biscoe$sex),\n       pch = 20,\n       col = factor(levels(biscoe$sex)))\n\ntitle(main = \"Biscoe\")(\n  penguins >> \\\n  drop_na() >> \\\n  ggplot(aes(x = '<FIXME>',\n             y = 'bill_length_mm',\n             colour = '<FIXME>'))\n         + geom_<FIXME>()\n         + facet_wrap('<FIXME>')\n)\npenguins %>% \n  drop_na() %>%                     \n  ggplot(aes(x = flipper_length_mm,\n             y = bill_length_mm,\n             colour = sex)) +\n  geom_point() +\n  facet_wrap(facets = vars(island))\nbiscoe <- \n  penguins[penguins$island == 'Biscoe', ]\n\nplot(biscoe$flipper_length_mm,\n     biscoe$bill_length_mm,\n     pch = 20,\n     col = biscoe$sex)\n\nlegend(\"bottomright\",\n       legend = levels(biscoe$sex),\n       pch = 20,\n       col = factor(levels(biscoe$sex)))\n\ntitle(main = 'Biscoe')(\n  penguins >> \\\n  drop_na() >> \\\n  ggplot(aes(x = 'flipper_length_mm',\n             y = 'bill_length_mm',\n             colour = 'sex'))\n         + geom_point()\n         + facet_wrap('island')\n)"},{"path":"kmeans.html","id":"clustering","chapter":"9 K-means clustering","heading":"9.7 Clustering","text":"Next, ’ll actual clustering.tidyverse\nclustering, ’ll using kmeans() function. function requires numeric data input. also scaling data. Although required case, variables unit (millimetres) good practice. scenarios different units compared, affect clustering.Note output list vectors, differing lengths. ’s contain different types information:cluster contains information pointcenters, withinss, size contain information clustertotss, tot.withinss, betweenss, iter contain information full clusteringbase R\nclustering, ’ll using kmeans() function. function requires numeric data input. also scaling data. Although required case, variables unit (millimetres) good practice. scenarios different units compared, affect clustering.Note output list vectors, differing lengths. ’s contain different types information:cluster contains information pointcenters, withinss, size contain information clustertotss, tot.withinss, betweenss, iter contain information full clusteringPython\nclustering, ’ll using KMeans() function. function requires numeric data input. also scaling data. Although required case, variables unit (millimetres) good practice. scenarios different units compared, affect clustering.","code":"\npoints <-\n  penguins %>% \n  select(bill_depth_mm,          # select data\n         bill_length_mm) %>% \n  drop_na() %>%                  # remove missing values\n  scale() %>%                    # scale the data\n  as_tibble() %>% \n  rename(bill_depth_scaled = bill_depth_mm,\n         bill_length_scaled = bill_length_mm)\n\n\nkclust <-\n  kmeans(points,                 # perform k-means clustering\n         centers = 3)            # using 3 centers\n\nsummary(kclust)                  # summarise output##              Length Class  Mode   \n## cluster      342    -none- numeric\n## centers        6    -none- numeric\n## totss          1    -none- numeric\n## withinss       3    -none- numeric\n## tot.withinss   1    -none- numeric\n## betweenss      1    -none- numeric\n## size           3    -none- numeric\n## iter           1    -none- numeric\n## ifault         1    -none- numeric\npoints_r <-\n  data.frame(\n    penguins$bill_depth_mm,      # get the numeric data\n    penguins$bill_length_mm) |>  # use base R pipe!\n  na.omit() |>                   # remove missing data\n  scale()                        # scale the data\n\n# and rename the columns to avoid confusion\nnames(points_r)[1] <- 'bill_depth_scaled'\nnames(points_r)[2] <- 'bill_length_scaled'\n\nkclusts_r <-\n  kmeans(points_r,               # perform k-means clustering\n         centers = 3)            # using 3 centers\n\nsummary(kclusts_r)                # summarise output##              Length Class  Mode   \n## cluster      342    -none- numeric\n## centers        6    -none- numeric\n## totss          1    -none- numeric\n## withinss       3    -none- numeric\n## tot.withinss   1    -none- numeric\n## betweenss      1    -none- numeric\n## size           3    -none- numeric\n## iter           1    -none- numeric\n## ifault         1    -none- numericscaler = StandardScaler()\n\npoints_py = \\\npenguins >> \\\n  drop_na() >> \\\n  select('bill_depth_mm', 'bill_length_mm')\n\npoints_py = scaler.fit_transform(points_py)\n\nkmeans = KMeans(\ninit = 'random',\nn_clusters = 3,\nn_init = 10,\nmax_iter = 300,\nrandom_state = 42\n)\n\nkmeans.fit(points_py)KMeans(init='random', n_clusters=3, random_state=42)KMeans(init='random', n_clusters=3, random_state=42)"},{"path":"kmeans.html","id":"visualise-clusters","chapter":"9 K-means clustering","heading":"9.8 Visualise clusters","text":"can visualise clusters calculated .tidyverse\nperformed clustering, centers calculated. values give (x, y) coordinates centroids.initial centroids get randomly placed data. , combined iterative nature process, means values see going slightly different values . ’s normal!Next, want visualise data points belong cluster. can follows:base R\nperformed clustering, centers calculated. values give (x, y) coordinates centroids.initial centroids get randomly placed data. , combined iterative nature process, means values see going slightly different values . ’s normal!Next, want visualise data points belong cluster. can follows:Python\nperformed clustering, centers calculated. values give (x, y) coordinates centroids.initial centroids get randomly placed data. , combined iterative nature process, means values see going slightly different values . ’s normal!Next, want visualise data points belong cluster. can follows:","code":"\ntidy_clust <- tidy(kclust) # get centroid coordinates\n\ntidy_clust## # A tibble: 3 × 5\n##   bill_depth_scaled bill_length_scaled  size withinss cluster\n##               <dbl>              <dbl> <int>    <dbl> <fct>  \n## 1            -1.09               0.590   125     59.4 1      \n## 2             0.560             -0.943   153     88.0 2      \n## 3             0.799              1.10     64     39.0 3\nkclust %>%                              # take clustering data\n  augment(points) %>%                   # combine with original data\n  ggplot(aes(x = bill_depth_scaled,     # plot the scaled data\n             y = bill_length_scaled)) +\n  geom_point(aes(colour = .cluster)) +  # colour by classification\n  geom_point(data = tidy_clust,\n             size = 7, shape = 'x')     # add the cluster centers\nkclusts_r$centers  # get centroid coordinates##   penguins.bill_depth_mm penguins.bill_length_mm\n## 1              0.7985421               1.1018368\n## 2              0.5595723              -0.9431819\n## 3             -1.0937700               0.5903143\nplot(points_r,                # plot scaled data\n     col = kclusts_r$cluster,  # colour by cluster\n     pch = 20)\n\npoints(kclusts_r$centers,      # add cluster centers\n       pch = 4,\n       lwd = 3)# calculate the cluster centers\nkclusts_py = kmeans.cluster_centers_\nkclusts_py = pd.DataFrame(kclusts_py, columns = ['0', '1'])\n\n# convert to tibble and rename columns\n# use base0_ = True because indices are 0-based\nkclusts_py = \\\ntibble(kclusts_py) >> \\\nrename(bill_depth_scaled = 0,\n       bill_length_scaled = 1)\n\n# and show the coordinates\nkclusts_py##    bill_depth_scaled  bill_length_scaled\n##            <float64>           <float64>\n## 0          -1.098055            0.586444\n## 1           0.795036            1.088684\n## 2           0.553935           -0.950240# convert NumPy arrays to data frame\npoints_py = pd.DataFrame(points_py, columns = ['0', '1'])\n\npoints_py = \\\ntibble(points_py) >> \\\nrename(bill_depth_scaled = 0,\n       bill_length_scaled = 1)\n\n# merge with original data\n# add predicted clusters\npenguins_clusters = \\\npenguins >> \\\n  drop_na() >> \\\n  bind_cols(points_py) >> \\\n  mutate(cluster = factor(kmeans.fit_predict(points_py)))(\nggplot(penguins_clusters,\n       aes(x = 'bill_depth_mm',\n           y = 'bill_length_mm',\n           colour = 'cluster'))\n         + geom_point()\n)"},{"path":"kmeans.html","id":"optimising-cluster-number","chapter":"9 K-means clustering","heading":"9.9 Optimising cluster number","text":"example set number clusters 3. made sense, data already visually separated roughly three groups - one species.However, might cluster number choose lot less obvious. case helpful explore clustering data range clusters.short, determine values k want explore loop values, repeating workflow looked previously.tidyverse\nReiterating range k values reasonably straightforward using tidyverse. Although write function loop k values, tidyverse series map() functions can . information .short, map() function spits list contains output. data, can create table contains lists information need.calculate following:kclust column contains list kmeans() output, value kthe tidied column contains information per-cluster basisthe glanced column contains single-row summary k - ’ll use tot.withinss values little bit later onthe augmented column contains original data, augmented classification calculated kmeans() functionLists can sometimes bit tricky get head around, ’s worthwhile exploring output. RStudio particularly useful , since can just left-click object Environment panel look.way see lists context containers. one huge table kclusts contains information need. ‘cell’ table container relevant data. kclust column list kmeans objects (output kmeans() k values), whereas columns lists tibbles (tidy(), glance() augment() functions output tibble information value k).us use data lists, makes sense extract column--column basis. ’re ignoring kclust column, don’t need actual kmeans() output .extract data lists use unnest() function.Next, can visualise data. ’ll start plotting scaled data colouring data points based final cluster assigned kmeans() function.(augmented) data assignments. look structure table.facet data k, get single panel value k.also add calculated cluster centres, stored clusters.Looking plot shows already knew (things easy time!): three clusters pretty good choice data. Remember ’re looking clusters distinct, .e. separated one another. example, using k = 4 gives four nice groups, two directly adjacent, suggesting equally well single cluster.","code":"\nkclusts <- \n  tibble(k = 1:6) %>%                         # check for k = 1 to 6\n  mutate(\n    kclust = map(k, ~kmeans(points, .x)),     # perform clustering for each k\n    tidied = map(kclust, tidy),               # summary at per-cluster level\n    glanced = map(kclust, glance),            # get single-row summary\n    augmented = map(kclust, augment, points)  # add classification to data set\n  )\n\nkclusts## # A tibble: 6 × 5\n##       k kclust   tidied           glanced          augmented         \n##   <int> <list>   <list>           <list>           <list>            \n## 1     1 <kmeans> <tibble [1 × 5]> <tibble [1 × 4]> <tibble [342 × 3]>\n## 2     2 <kmeans> <tibble [2 × 5]> <tibble [1 × 4]> <tibble [342 × 3]>\n## 3     3 <kmeans> <tibble [3 × 5]> <tibble [1 × 4]> <tibble [342 × 3]>\n## 4     4 <kmeans> <tibble [4 × 5]> <tibble [1 × 4]> <tibble [342 × 3]>\n## 5     5 <kmeans> <tibble [5 × 5]> <tibble [1 × 4]> <tibble [342 × 3]>\n## 6     6 <kmeans> <tibble [6 × 5]> <tibble [1 × 4]> <tibble [342 × 3]>\nclusters <- \n  kclusts %>%\n  unnest(cols = c(tidied))\n\nassignments <- \n  kclusts %>% \n  unnest(cols = c(augmented))\n\nclusterings <- \n  kclusts %>%\n  unnest(cols = c(glanced))\nggplot(assignments,\n       aes(x = bill_depth_scaled,     # plot data\n           y = bill_length_scaled)) +  \n  geom_point(aes(color = .cluster),   # colour by cluster\n             alpha = 0.8) +           # add transparency\n  facet_wrap(~ k) +                   # facet for each k\n  geom_point(data = clusters,         # add centers\n             size = 7,\n             shape = \"x\")"},{"path":"kmeans.html","id":"elbow-plot","chapter":"9 K-means clustering","heading":"9.9.1 Elbow plot","text":"Visualising data like can helpful time can also bit subjective (hoorah!). find another subjective way interpreting clusters (remember, statistics isn’t YES/magic mushroom comfortable wandering around murky grey areas statistics now), can plot total within-cluster variation value k.Intuitively, keep adding clusters total amount variation can explained clusters increase. extreme case data point cluster can explain variation data.course sensible approach - hence us balancing number clusters much variation can capture.practical approach creating “elbow” plot cumulative amount variation explained plotted number clusters.tidyverse\noutput kmeans() function includes tot.withinss - total within-cluster sum squares.can see total within-cluster sum squares decreases number clusters increases. can also see k = 3 onwards slope line becomes much shallower. “elbow” bending point useful gauge find optimum number clusters.exploration can see three clusters optimal scenario.","code":"\nggplot(clusterings,\n       aes(x = k,                # for each k plot...\n           y = tot.withinss)) +  # total within variance\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(\n    breaks = seq(1, 6, 1))       # set the x-axis breaks"},{"path":"kmeans.html","id":"exercise-1","chapter":"9 K-means clustering","heading":"9.10 Exercise","text":"Exercise 9.2  Practice running clustering workflow using finches dataset. Try following:Read dataExplore visualise dataPerform clustering k = 2Find using k = 2 reasonable choiceTry draw conclusionstidyverseLet’s look data.Next, perform clustering.looks like two clusters reasonable choice. let’s explore bit .Extract relevant data.Visualise result.Create elbow plot closer look.initial clustering done using two clusters, basically capturing two different finch species.Redoing analysis different numbers clusters seems reasonably support decision. elbow plot suggests k = 3 terrible idea either.example used data collected two different time points: 1975 2012.analysis ’ve kept data together. However, original premises data see indication evolution going species finches. Think approach question!","code":"\nfinches <- read_csv(\"data/finch_beaks.csv\")\nhead(finches)## # A tibble: 6 × 5\n##    band species beak_length_mm beak_depth_mm  year\n##   <dbl> <chr>            <dbl>         <dbl> <dbl>\n## 1     2 fortis             9.4           8    1975\n## 2     9 fortis             9.2           8.3  1975\n## 3    12 fortis             9.5           7.5  1975\n## 4    15 fortis             9.5           8    1975\n## 5   305 fortis            11.5           9.9  1975\n## 6   307 fortis            11.1           8.6  1975\nggplot(finches, aes(x = beak_depth_mm,\n                     y = beak_length_mm,\n                     colour = species)) +\n  geom_point()\npoints <-\n  finches %>% \n  select(beak_depth_mm,         # select data\n         beak_length_mm) %>% \n  drop_na()                     # remove missing values\n\nkclust <-\n  kmeans(points,                 # perform k-means clustering\n         centers = 2)            # using 2 centers\n\nsummary(kclust)                  # summarise output##              Length Class  Mode   \n## cluster      651    -none- numeric\n## centers        4    -none- numeric\n## totss          1    -none- numeric\n## withinss       2    -none- numeric\n## tot.withinss   1    -none- numeric\n## betweenss      1    -none- numeric\n## size           2    -none- numeric\n## iter           1    -none- numeric\n## ifault         1    -none- numeric\ntidy_clust <- tidy(kclust) # get centroid coordinates\n\ntidy_clust## # A tibble: 2 × 5\n##   beak_depth_mm beak_length_mm  size withinss cluster\n##           <dbl>          <dbl> <int>    <dbl> <fct>  \n## 1          8.98           10.5   431     442. 1      \n## 2          9.16           13.7   220     237. 2\nkclust %>%                              # take clustering data\n  augment(points) %>%                   # combine with original data\n  ggplot(aes(x = beak_depth_mm,         # plot the original data\n             y = beak_length_mm)) +\n  geom_point(aes(colour = .cluster)) +  # colour by classification\n  geom_point(data = tidy_clust,\n             size = 7, shape = 'x')     # add the cluster centers\nkclusts <- \n  tibble(k = 1:6) %>%                         # check for k = 1 to 6\n  mutate(\n    kclust = map(k, ~kmeans(points, .x)),     # perform clustering for each k\n    tidied = map(kclust, tidy),               # summary at per-cluster level\n    glanced = map(kclust, glance),            # get single-row summary\n    augmented = map(kclust, augment, points)  # add classification to data set\n  )\nclusters <- \n  kclusts %>%\n  unnest(cols = c(tidied))\n\nassignments <- \n  kclusts %>% \n  unnest(cols = c(augmented))\n\nclusterings <- \n  kclusts %>%\n  unnest(cols = c(glanced))\nggplot(assignments,\n       aes(x = beak_depth_mm,        # plot data\n           y = beak_length_mm)) +  \n  geom_point(aes(color = .cluster),  # colour by cluster\n             alpha = 0.8) +          # add transparency\n  facet_wrap(~ k) +                  # facet for each k\n  geom_point(data = clusters,        # add centers\n             size = 7,\n             shape = 'x')\nggplot(clusterings,\n       aes(x = k,                # for each k plot...\n           y = tot.withinss)) +  # total within variance\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(\n    breaks = seq(1, 6, 1))       # set the x-axis breaks"},{"path":"kmeans.html","id":"load-the-data-1","chapter":"9 K-means clustering","heading":"Load the data","text":"","code":"\nfinches <- read_csv(\"data/finch_beaks.csv\")\nhead(finches)## # A tibble: 6 × 5\n##    band species beak_length_mm beak_depth_mm  year\n##   <dbl> <chr>            <dbl>         <dbl> <dbl>\n## 1     2 fortis             9.4           8    1975\n## 2     9 fortis             9.2           8.3  1975\n## 3    12 fortis             9.5           7.5  1975\n## 4    15 fortis             9.5           8    1975\n## 5   305 fortis            11.5           9.9  1975\n## 6   307 fortis            11.1           8.6  1975"},{"path":"kmeans.html","id":"visualise-the-data-6","chapter":"9 K-means clustering","heading":"Visualise the data","text":"Let’s look data.","code":"\nggplot(finches, aes(x = beak_depth_mm,\n                     y = beak_length_mm,\n                     colour = species)) +\n  geom_point()"},{"path":"kmeans.html","id":"clustering-1","chapter":"9 K-means clustering","heading":"Clustering","text":"Next, perform clustering.","code":"\npoints <-\n  finches %>% \n  select(beak_depth_mm,         # select data\n         beak_length_mm) %>% \n  drop_na()                     # remove missing values\n\nkclust <-\n  kmeans(points,                 # perform k-means clustering\n         centers = 2)            # using 2 centers\n\nsummary(kclust)                  # summarise output##              Length Class  Mode   \n## cluster      651    -none- numeric\n## centers        4    -none- numeric\n## totss          1    -none- numeric\n## withinss       2    -none- numeric\n## tot.withinss   1    -none- numeric\n## betweenss      1    -none- numeric\n## size           2    -none- numeric\n## iter           1    -none- numeric\n## ifault         1    -none- numeric\ntidy_clust <- tidy(kclust) # get centroid coordinates\n\ntidy_clust## # A tibble: 2 × 5\n##   beak_depth_mm beak_length_mm  size withinss cluster\n##           <dbl>          <dbl> <int>    <dbl> <fct>  \n## 1          8.98           10.5   431     442. 1      \n## 2          9.16           13.7   220     237. 2"},{"path":"kmeans.html","id":"visualise-the-clusters","chapter":"9 K-means clustering","heading":"Visualise the clusters","text":"","code":"\nkclust %>%                              # take clustering data\n  augment(points) %>%                   # combine with original data\n  ggplot(aes(x = beak_depth_mm,         # plot the original data\n             y = beak_length_mm)) +\n  geom_point(aes(colour = .cluster)) +  # colour by classification\n  geom_point(data = tidy_clust,\n             size = 7, shape = 'x')     # add the cluster centers"},{"path":"kmeans.html","id":"optimise-clusters","chapter":"9 K-means clustering","heading":"Optimise clusters","text":"looks like two clusters reasonable choice. let’s explore bit .Extract relevant data.Visualise result.Create elbow plot closer look.","code":"\nkclusts <- \n  tibble(k = 1:6) %>%                         # check for k = 1 to 6\n  mutate(\n    kclust = map(k, ~kmeans(points, .x)),     # perform clustering for each k\n    tidied = map(kclust, tidy),               # summary at per-cluster level\n    glanced = map(kclust, glance),            # get single-row summary\n    augmented = map(kclust, augment, points)  # add classification to data set\n  )\nclusters <- \n  kclusts %>%\n  unnest(cols = c(tidied))\n\nassignments <- \n  kclusts %>% \n  unnest(cols = c(augmented))\n\nclusterings <- \n  kclusts %>%\n  unnest(cols = c(glanced))\nggplot(assignments,\n       aes(x = beak_depth_mm,        # plot data\n           y = beak_length_mm)) +  \n  geom_point(aes(color = .cluster),  # colour by cluster\n             alpha = 0.8) +          # add transparency\n  facet_wrap(~ k) +                  # facet for each k\n  geom_point(data = clusters,        # add centers\n             size = 7,\n             shape = 'x')\nggplot(clusterings,\n       aes(x = k,                # for each k plot...\n           y = tot.withinss)) +  # total within variance\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(\n    breaks = seq(1, 6, 1))       # set the x-axis breaks"},{"path":"kmeans.html","id":"conclusions-1","chapter":"9 K-means clustering","heading":"Conclusions","text":"initial clustering done using two clusters, basically capturing two different finch species.Redoing analysis different numbers clusters seems reasonably support decision. elbow plot suggests k = 3 terrible idea either.","code":""},{"path":"kmeans.html","id":"food-for-thought-1","chapter":"9 K-means clustering","heading":"Food for thought","text":"example used data collected two different time points: 1975 2012.analysis ’ve kept data together. However, original premises data see indication evolution going species finches. Think approach question!","code":""},{"path":"kmeans.html","id":"key-points-5","chapter":"9 K-means clustering","heading":"9.11 Key points","text":"k-means clustering partitions data clustersthe k defines number clusterscluster centers centroids get assigned randomlyeach data point gets assigned closest centroidthe centroid new clusters gets calculated process assignment recalculation repeats cluster longer changethe optimal number clusters can determined ‘elbow’ plot.panelset{--panel-tab-font-family: inherit;}","code":""},{},{"path":"hierarchical-clustering.html","id":"hierarchical-clustering","chapter":"10 Hierarchical clustering","heading":"10 Hierarchical clustering","text":"","code":""},{"path":"hierarchical-clustering.html","id":"objectives-8","chapter":"10 Hierarchical clustering","heading":"10.1 Objectives","text":"Understand hierarchical clustering can used forBe able calculate distance matricesKnow different methods calculate distance matricesPerform hierarchical clusteringDraw dendrogramsCut dendrograms clusters use clustering information visualise data","code":""},{"path":"hierarchical-clustering.html","id":"purpose-and-aim-2","chapter":"10 Hierarchical clustering","heading":"10.2 Purpose and aim","text":"Hierarchical clustering form cluster analysis, aim create hierarchy clusters. results commonly displayed dendrogram, displays clusters found analysis.","code":""},{"path":"hierarchical-clustering.html","id":"libraries-and-functions-6","chapter":"10 Hierarchical clustering","heading":"10.3 Libraries and functions","text":"tidyverse","code":""},{"path":"hierarchical-clustering.html","id":"data-2","chapter":"10 Hierarchical clustering","heading":"10.4 Data","text":"example session ’ll using yeast RNAseq data set.Yeast RNAseqThese data experiment included fission R/Bioconductor package. briefly, transcriptome data :Two yeast strains: wild type (wt) atf21del mutant (mut)6 time points osmotic stress time (0, 15, 30, 60, 120 180 mins)Three replicates strain time pointLet’s say experiment , bioinformatician analysed provided four files data:sample_info.csv - information sample.counts_raw.csv - raw unprocessed read counts genes, gives measure genes’ expression. (simply scaled size library account fact different samples less total number reads).counts_transformed.csv - normalised read counts genes, log scale transformed correct dependency mean variance. typical count data.test_result.csv - results statistical test assessed probability observed expression differences first time points WT cells, assuming null hypothesis difference.","code":""},{"path":"hierarchical-clustering.html","id":"get-to-know-your-data","chapter":"10 Hierarchical clustering","heading":"10.5 Get to know your data","text":"Let’s load data need session (don’t need raw data):","code":"\ntrans_cts <- read_csv(\"data/transcriptome/counts_transformed.csv\")\nsample_info <- read_csv(\"data/transcriptome/sample_info.csv\")\ntest_result <- read_csv(\"data/transcriptome/test_result.csv\")"},{"path":"hierarchical-clustering.html","id":"transformed-counts","chapter":"10 Hierarchical clustering","heading":"10.5.1 Transformed counts","text":"Let’s look transformed count data:list genes, 37 columns. columns encode information strain (wt/mut), time point (0, 15, etc) repeat (r1, r2, r3). something need aware , ’s often helpful kind information encoded column name.quick check also tells us 6,011 genes data set, gene occurring :","code":"\ntrans_cts## # A tibble: 6,011 × 37\n##    gene     wt_0_r1 wt_0_r2 wt_0_r3 wt_15_r1 wt_15_r2 wt_15_r3 wt_30_r1 wt_30_r2\n##    <chr>      <dbl>   <dbl>   <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n##  1 SPAC212…    4.95    4.97    5.66     5.45     5.44     6.50     5.08     5.25\n##  2 SPAC212…    5.44    6.21    6.17     5.94     6.33     6.41     6.71     7.15\n##  3 SPAC212…    5.75    5.06    5.54     5.68     5.18     5.10     5.82     6.31\n##  4 SPNCRNA…    5.73    4.87    4.94     5.57     5.32     4.20     5.17     4.77\n##  5 SPAC977…    7.05    6.84    6.79     6.87     6.09     6.19     6.91     6.66\n##  6 SPAC977…    5.34    5.34    5.31     5.32     5.99     5.30     7.61     7.48\n##  7 SPAC977…    6.50    6.23    6.70     7.03     6.92     7.53     6.44     6.68\n##  8 SPAC977…    7.24    7.46    7.48     7.09     7.46     7.65     6.88     7.13\n##  9 SPNCRNA…    5.96    5.69    5.94     5.92     5.87     4.84     7.38     7.30\n## 10 SPAC1F8…    6.64    6.65    6.78     4.62     5.61     6.15     5.66     6.50\n## # … with 6,001 more rows, and 28 more variables: wt_30_r3 <dbl>,\n## #   wt_60_r1 <dbl>, wt_60_r2 <dbl>, wt_60_r3 <dbl>, wt_120_r1 <dbl>,\n## #   wt_120_r2 <dbl>, wt_120_r3 <dbl>, wt_180_r1 <dbl>, wt_180_r2 <dbl>,\n## #   wt_180_r3 <dbl>, mut_0_r1 <dbl>, mut_0_r2 <dbl>, mut_0_r3 <dbl>,\n## #   mut_15_r1 <dbl>, mut_15_r2 <dbl>, mut_15_r3 <dbl>, mut_30_r1 <dbl>,\n## #   mut_30_r2 <dbl>, mut_30_r3 <dbl>, mut_60_r1 <dbl>, mut_60_r2 <dbl>,\n## #   mut_60_r3 <dbl>, mut_120_r1 <dbl>, mut_120_r2 <dbl>, mut_120_r3 <dbl>, …\ntrans_cts %>% \n  count(gene) %>%  # count the number of genes\n  arrange(desc(n)) # arrange in descending order## # A tibble: 6,011 × 2\n##    gene             n\n##    <chr>        <int>\n##  1 SPAC1002.01      1\n##  2 SPAC1002.02      1\n##  3 SPAC1002.03c     1\n##  4 SPAC1002.04c     1\n##  5 SPAC1002.05c     1\n##  6 SPAC1002.07c     1\n##  7 SPAC1002.08c     1\n##  8 SPAC1002.09c     1\n##  9 SPAC1002.10c     1\n## 10 SPAC1002.11      1\n## # … with 6,001 more rows"},{"path":"hierarchical-clustering.html","id":"sample-info","chapter":"10 Hierarchical clustering","heading":"10.5.2 Sample info","text":"Let’s look see sample info:data set contains information various samples, data also split column. ’ll come handy later .","code":"\nsample_info## # A tibble: 36 × 4\n##    sample   strain minute replicate\n##    <chr>    <chr>   <dbl> <chr>    \n##  1 wt_0_r1  wt          0 r1       \n##  2 wt_0_r2  wt          0 r2       \n##  3 wt_0_r3  wt          0 r3       \n##  4 wt_15_r1 wt         15 r1       \n##  5 wt_15_r2 wt         15 r2       \n##  6 wt_15_r3 wt         15 r3       \n##  7 wt_30_r1 wt         30 r1       \n##  8 wt_30_r2 wt         30 r2       \n##  9 wt_30_r3 wt         30 r3       \n## 10 wt_60_r1 wt         60 r1       \n## # … with 26 more rows"},{"path":"hierarchical-clustering.html","id":"test-results","chapter":"10 Hierarchical clustering","heading":"10.5.3 Test results","text":"test results give us results statistical test first time point WT cells, comparing time points. null hypothesis difference. column ’re mostly interested padj, gives us adjusted p-values.","code":"\ntest_result## # A tibble: 30,055 × 8\n##    gene        baseMean log2FoldChange lfcSE   stat pvalue  padj comparison\n##    <chr>          <dbl>          <dbl> <dbl>  <dbl>  <dbl> <dbl>      <dbl>\n##  1 SPAC212.11      8.55         1.54   0.497  1.09  0.276      1         15\n##  2 SPAC212.09c    50.8          0.399  0.273  0     1          1         15\n##  3 SPAC212.04c    38.3         -0.0230 0.269  0     1          1         15\n##  4 SPNCRNA.601     9.47        -0.0841 0.483  0     1          1         15\n##  5 SPAC977.11     70.4         -0.819  0.201  0     1          1         15\n##  6 SPAC977.13c    36.7          1.19   0.344  0.552 0.581      1         15\n##  7 SPAC977.15     49.1          0.600  0.208  0     1          1         15\n##  8 SPAC977.16c    83.2          0.148  0.239  0     1          1         15\n##  9 SPNCRNA.607    60.4          0.0638 0.268  0     1          1         15\n## 10 SPAC1F8.06     74.2         -1.58   0.298 -1.94  0.0520     1         15\n## # … with 30,045 more rows\ntest_result %>% \n  select(gene, padj)## # A tibble: 30,055 × 2\n##    gene         padj\n##    <chr>       <dbl>\n##  1 SPAC212.11      1\n##  2 SPAC212.09c     1\n##  3 SPAC212.04c     1\n##  4 SPNCRNA.601     1\n##  5 SPAC977.11      1\n##  6 SPAC977.13c     1\n##  7 SPAC977.15      1\n##  8 SPAC977.16c     1\n##  9 SPNCRNA.607     1\n## 10 SPAC1F8.06      1\n## # … with 30,045 more rows"},{"path":"hierarchical-clustering.html","id":"clustering-2","chapter":"10 Hierarchical clustering","heading":"10.6 Clustering","text":"lot data (6,000 data points!). might interested data group/cluster together. using k-means clustering ’re going use hierarchical clustering.’re looking specifically whether groups genes similar one another. approach creating hierarchy: genes similar cluster together, followed next groups genes similar , forth.make things bit manageable example, ’ll look subset 6,011 genes. ’ll select 50 highly differentially expressed genes work store gene names data frame:tidyverseNow ’ve got list genes ’re interested , can use cluster data.way works first gene compared genes. two genes form cluster. second gene compared cluster remaining genes. forms cluster similar gene cluster.process continues comparisons left.way quantified calculating matrix dissimilarities. happens using distance measures - something already learned k-means clustering. Two useful distance measures Euclidian Manhattan distance.different ways methods calculating distances, commonly types used:tidyverse\nfunction use calculate clusters hclust(). can , need calculate dissimilarities clusters. using dist() function. default method used \"euclidian\", options. Run ?dist look.default method used hclust() \"complete\", just different ’ll using \"average\" linkage . ’s always useful see method helps look data best.Scaling technically necessary , differential expression analysis already done us. However, ’ve included step anyway make aware . Trying calculate distances values different scales result non-sensical results!can look hclust() produced us:answer list contains whole bunch data. can see distance clustering methods specified (hoorah!). Also, appear 44 objects.help us much, let’s go ahead plot . make bit manageable ’re using library ggdendro, allows us plot dendrograms using ggplot-style syntax.haven’t installed/loaded , now good time. can follows:Next, can plot dendrogram using ggdendrogram() function. give gene_clust object, tell rotate dendrogram (try setting TRUE see happens!), give title.dendrogram can see quite bit structure data. question , start delve bit deeper ? One way cutting dendrogram different groups.Visually, see slicing across various clusters. represented horizontal line, slice dendrogram four groups:tidyverseWe can kind slicing programmatically well. happens comparable k-means clustering, divide data groups (clusters) gene gets assigned specific cluster.tidyverse\ncreate clusters cutting dendrogram using cutree() function. little bit data wrangling (creating tibble resulting vector, renaming column names) get following output:can see gene list now assigned certain cluster number. can use information look data bit detail.example, see gene expression trends visible across different clusters. useful visually follow gene expression candidate genes time, cluster strain.requires bit logical thinking, let’s go step--step.three biological repeats per time point per strain, need average thosewe need make sure data scaledwe need create scaled averages gene, strain time pointTo , take transformed counts (trans_cts) data first rejig long format can grouping . merge sample_info data, get relevant information regarding strain, time point repeat. filter candidate genes, scale counts, group data calculate average counts.Sounds doable, right? Hoorah pipes, can go step--step:’s done, can merge information gene_cluster, contains cluster classification gene:can see now data need: gene information type strain, time point, scaled mean counts cluster gene assigned . also bonus column containing number repeats make mean values.Exercise 10.1  Bonus exercise\nmean values made three biological repeats?many ways can skin proverbial cat, one :yes, mean counts values made three biological repeats. good know, realise averages comparable.Now data, can finally plot gene expression trends, separating genes interest cluster.facetting:can see overall trend comparable clusters. Something different seems going cluster 4, actually based seems like single observation. reason (well, ) choice look top 50 differentially expressed genes.get generalised view can also add median line facet, showing median expression cluster:","code":"\n# set of candidate genes for clustering\n# we select the 50 genes with the lowest padj value\ncandidate_genes <- test_result %>% \n  slice_min(padj, n = 50) %>%  \n  select(gene) %>% \n  distinct()\ngene_hclust <- trans_cts %>%\n  # filter our data for the candidate genes\n  semi_join(candidate_genes, by = \"gene\") %>%\n  # convert the gene column to row names\n  # because dist() takes a matrix\n  column_to_rownames(var = \"gene\") %>% \n  # scale the data\n  scale() %>% \n  # calculate the Euclidian distance\n  dist(method = \"euclidian\") %>% \n  # perform the clustering\n  hclust(method = \"average\")\ngene_hclust## \n## Call:\n## hclust(d = ., method = \"average\")\n## \n## Cluster method   : average \n## Distance         : euclidean \n## Number of objects: 44\n# install if needed\ninstall.packages(\"ggdendro\")\n\n# and load the library\nlibrary(ggdendro)\nggdendrogram(gene_hclust, rotate = FALSE) +\n  labs(title = \"Top 50 DEG dendrogram\")\nggdendrogram(gene_hclust, rotate = FALSE) +\n  geom_hline(yintercept = 8.2, colour = \"red\") +\n  labs(title = \"Top 50 DEG dendrogram\",\n       subtitle = \"cutting into 4 cluster\")\ngene_cluster <- cutree(gene_hclust, k = 4) %>% \n  # turn the named vector into a tibble\n  enframe() %>% \n  # rename some of the columns\n  rename(gene = name, cluster = value)\n\nhead(gene_cluster)## # A tibble: 6 × 2\n##   gene          cluster\n##   <chr>           <int>\n## 1 SPAC22A12.17c       1\n## 2 SPACUNK4.17         1\n## 3 SPAC4H3.03c         2\n## 4 SPAC2F3.05c         1\n## 5 SPAC637.03          2\n## 6 SPAC26F1.07         3\n# summarise counts \ntrans_cts_mean <- trans_cts %>% \n  # convert to long format\n  pivot_longer(cols = wt_0_r1:mut_180_r3, names_to = \"sample\", values_to = \"cts\")  %>% \n  # join with sample info table\n  full_join(sample_info, by = \"sample\") %>% \n  # filter to retain only genes of interest\n  semi_join(candidate_genes, by = \"gene\") %>%\n  # for each gene\n  group_by(gene) %>% \n  # scale the cts column\n  mutate(cts_scaled = scale(cts)) %>% \n  # for each gene, strain and minute\n  group_by(gene, strain, minute) %>%\n  # calculate the mean (scaled) cts\n  summarise(mean_cts_scaled = mean(cts_scaled),\n            n_rep = n()) %>% \n  ungroup()\ntrans_cts_cluster <- trans_cts_mean %>% \n  inner_join(gene_cluster, by = \"gene\")\n\nhead(trans_cts_cluster)## # A tibble: 6 × 6\n##   gene        strain minute mean_cts_scaled n_rep cluster\n##   <chr>       <chr>   <dbl>           <dbl> <int>   <int>\n## 1 SPAC11E3.14 mut         0          -1.06      3       1\n## 2 SPAC11E3.14 mut        15           0.615     3       1\n## 3 SPAC11E3.14 mut        30           1.83      3       1\n## 4 SPAC11E3.14 mut        60          -0.553     3       1\n## 5 SPAC11E3.14 mut       120          -0.353     3       1\n## 6 SPAC11E3.14 mut       180          -0.635     3       1\ntrans_cts_cluster %>% \n  count(n_rep)## # A tibble: 1 × 2\n##   n_rep     n\n##   <int> <int>\n## 1     3   528\ntrans_cts_cluster %>% \n  ggplot(aes(minute, mean_cts_scaled)) +\n  geom_line(aes(group = gene)) +\n  facet_grid(rows = vars(strain), cols = vars(cluster))\ntrans_cts_cluster %>% \n  ggplot(aes(minute, mean_cts_scaled)) +\n  geom_line(aes(group = gene),\n            alpha = 0.3) +\n  geom_line(stat = \"summary\",      # create a summary stat\n            fun = \"median\",        # and use the median\n            colour = \"red\",\n            size = 0.5, \n            aes(group = 1)) +      # idiosyncratic necessity to group the line\n  facet_grid(rows = vars(strain),  # plot strains in rows\n             cols = vars(cluster)) # and clusters in columns"},{"path":"hierarchical-clustering.html","id":"exercise-penguins-1","chapter":"10 Hierarchical clustering","heading":"10.7 Exercise: Penguins","text":"Exercise 10.2  ’re still us point, well done! exercise ’re going practice creating dendrogram using penguins data set.like following:load penguins data set, neededremove missing values add ID column (factor)scale data (needed)calculate distance matrix using Euclidian distanceperform hierarchical clustering complete linkageplot dendrogramrepeat process now using Manhattan distancesee hierarchical structure similar (eye-balling )tidyverseFirst update penguins data set, removing missing values creating ID column. simply creating row number, gives unique ID observation. number real numerical meaning, set factor.clustering, first remove non-numerical data data set. still want retain information data, use id column row names.need scale() data, original variables different scales (e.g. flipper length milimeters, whereas body mass grams).show calculate distance matrix using Euclidian distance, Manhattan method, simply change method = \"manhattan\". everything life easy…, dear viewers, allows us create wonderful dendrogram. many observations, can omit labels using labels = FALSE.Lastly, comparing effect Euclidian Manhattan distance matrices final dendrogram shows slight differences two methods:","code":"\npenguins <- penguins %>% \n  # remove missing values\n  drop_na() %>% \n  # create ID column\n  mutate(id = 1:n(),\n         id = as_factor(id))\npenguins_hclust <- penguins %>% \n  select(-species, -island, -sex, -year) %>% \n  column_to_rownames(var = \"id\") %>% \n  scale() %>% \n  dist(method = \"euclidian\") %>% \n  hclust(method = \"complete\")\nggdendrogram(penguins_hclust, rotate = FALSE, labels = FALSE) +\n  labs(title = \"Penguins dendrogram\")"},{"path":"hierarchical-clustering.html","id":"optional-colouring-clusters","chapter":"10 Hierarchical clustering","heading":"10.8 Optional: Colouring clusters","text":"Adding colour dendrograms can bit tricky. different ways , simplest method ’ve found (far) require installation various, extensive packages bunch functions written Atrebas. See blogpost.Basically, need load script provided go!can also plot circular dendrogram:","code":"\nsource(file = \"scripts/ggdendro_extended.R\")\n# cut the dendrogram, specify the number of clusters\nhcdata <- dendro_data_k(gene_hclust, 4)\n\n\nplot_ggdendro(hcdata,\n              direction   = \"lr\",\n              expand.y    = 0.2,\n              branch.size = 0.5)\nplot_ggdendro(hcdata,\n              fan         = TRUE,\n              label.size  = 3,\n              nudge.label = 0.02,\n              expand.y    = 0.4) +\n  theme_void()"},{"path":"hierarchical-clustering.html","id":"key-points-6","chapter":"10 Hierarchical clustering","heading":"10.9 Key points","text":"Hierarchical clustering can used determine visualise hierarchy dataDistance matrices can calculated , example, Euclidian distance Manhattan distanceCalculating dissimilarity clusters can done different ways, example using complete linkage (largest distance), single linkage (minimum distance) average linkageDrawing dendrograms can visualise hierarchy cutting dendrograms can help investigate potential clusters data","code":""}]
