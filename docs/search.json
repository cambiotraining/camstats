[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"sessions intended enable perform additional data analysis techniques appropriately confidently using R Python.Ongoing formative assessment exercisesOngoing formative assessment exercisesNo formal assessmentNo formal assessmentNo mathematical derivationsNo mathematical derivationsNo pen paper calculationsNo pen paper calculationsThey ‚Äúmindlessly use stats program‚Äù course!","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.1 Core aims","text":"know presented non-standard dataset e.g.Know deal non-normal dataKnow analyse count dataBe able deal random effects","code":""},{"path":"index.html","id":"core-topics","chapter":"1 Overview","heading":"1.2 Core topics","text":"Generalised linear models","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.3 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder right-clicking link Save ‚Ä¶. Next unzip file copy working directory. data accessible via <working-directory-name>/data.","code":""},{},{"path":"glm-intro.html","id":"glm-intro","chapter":"2 Introduction","heading":"2 Introduction","text":"","code":""},{"path":"glm-intro.html","id":"objectives","chapter":"2 Introduction","heading":"2.1 Objectives","text":"Aim: introduce R commands analysing data non-continuous response variables.end practical participants able achieve following:Construct\nlogistic model binary response variables\nlogistic model proportion response variables\nPoisson model count response variables\nNegative Binomial model count response variables\nlogistic model binary response variablesa logistic model proportion response variablesa Poisson model count response variablesa Negative Binomial model count response variablesPlot data fitted curve case continuous categorical predictorsAssess significance fitAssess assumption model","code":""},{"path":"glm-intro.html","id":"background","chapter":"2 Introduction","heading":"2.2 Background","text":"practical divided sections considers sort response variable generalised linear model turn. Within section least one example modelling process followed example.","code":""},{},{"path":"logistic-models-binary-response.html","id":"logistic-models-binary-response","chapter":"3 Logistic Models ‚Äì Binary Response","heading":"3 Logistic Models ‚Äì Binary Response","text":"","code":""},{"path":"logistic-models-binary-response.html","id":"objectives-1","chapter":"3 Logistic Models ‚Äì Binary Response","heading":"3.1 Objectives","text":"QuestionsObjectives","code":""},{"path":"logistic-models-binary-response.html","id":"data","chapter":"3 Logistic Models ‚Äì Binary Response","heading":"3.2 Data","text":"section uses following dataset:data/MS1-Diabetes.csvThis dataset comprising 768 observations three variables (one dependent two predictor variables). records results diabetes test binary variable (1 positive result, 0 negative result), along result glucose test diastolic blood pressure 767 women. variables called test, glucose diastolic.","code":""},{"path":"logistic-models-binary-response.html","id":"load-the-data","chapter":"3 Logistic Models ‚Äì Binary Response","heading":"3.3 Load the data","text":"First load data, visualise . needed, load tidyverse package using:can plot data:looks though variable glucose may effect results diabetes test since positive test results seem slightly higher negative test results.can visualise differently plotting data points classic binary response plot:","code":"\nlibrary(tidyverse)\ndiabetes <- read_csv(\"data/MS1-Diabetes.csv\")\ndiabetes %>% \n  mutate(test = as_factor(test)) %>% \n  ggplot(aes(x = test, y = glucose)) +\n  geom_boxplot()\ndiabetes %>% \n  ggplot(aes(x = glucose, y = test)) +\n  geom_point()"},{"path":"logistic-models-binary-response.html","id":"construct-a-logistic-model","chapter":"3 Logistic Models ‚Äì Binary Response","heading":"3.4 Construct a logistic model","text":"First construct logistic model named glm_diabetes. format function similar used linear model function lm(). important difference must specify family error distribution use. logistic regression must set family binomial.Important: forget include family argument glm() function just performs ordinary linear model fit (lm() function)Right, let‚Äôs construct model:summarise output model, get following information:‚Äôs lot unpack take deep breath (make sure coffee) continuing‚Ä¶first lines just confirm model ‚Äôve fitting (trust , can useful ‚Äôre middle load analysis ‚Äôve lost track hell going !)first lines just confirm model ‚Äôve fitting (trust , can useful ‚Äôre middle load analysis ‚Äôve lost track hell going !)next block called Deviance Residuals. isn‚Äôt particularly useful, just know: linear models residuals calculated data point squared added get SS (sum squares), used fit model. generalised linear models don‚Äôt use SS fit model instead use entirely different method called maximum likelihood. fitting procedure generates different quantity, called Deviance, analogue SS. deviance zero indicates best model hope bigger values indicate model doesn‚Äôt fit quite well. deviance residuals values associated data point, squared summed give deviance model (exact analogy normal residuals). ‚Äôre unlikely ever need know , time hands decided share little nugget üòâ.next block called Deviance Residuals. isn‚Äôt particularly useful, just know: linear models residuals calculated data point squared added get SS (sum squares), used fit model. generalised linear models don‚Äôt use SS fit model instead use entirely different method called maximum likelihood. fitting procedure generates different quantity, called Deviance, analogue SS. deviance zero indicates best model hope bigger values indicate model doesn‚Äôt fit quite well. deviance residuals values associated data point, squared summed give deviance model (exact analogy normal residuals). ‚Äôre unlikely ever need know , time hands decided share little nugget üòâ.Coefficients block next. main numbers extract output two numbers underneath Estimate.Std: (Intercept) -5.611732 glucose 0.039510.coefficients logistic model equation need placed correct equation want able calculate probability positive diabetes test given glucose level.Coefficients block next. main numbers extract output two numbers underneath Estimate.Std: (Intercept) -5.611732 glucose 0.039510.coefficients logistic model equation need placed correct equation want able calculate probability positive diabetes test given glucose level.\\[\\begin{equation}\nP(positive \\ test) = \\frac{1}{1 + {e}^{-(-5.61 +  0.040 \\cdot glucose)}}\n\\end{equation}\\]p values (Pr(>|z|) end coefficient row merely show whether particular coefficient significantly different zero. similar p-values obtained summary output linear model, , continuous predictors p-values can used rough guide whether predictor important (case glucose appears significant). However, p-values aren‚Äôt great multiple predictor variables, categorical predictors multiple levels (since output give us p-value level rather predictor whole).p values (Pr(>|z|) end coefficient row merely show whether particular coefficient significantly different zero. similar p-values obtained summary output linear model, , continuous predictors p-values can used rough guide whether predictor important (case glucose appears significant). However, p-values aren‚Äôt great multiple predictor variables, categorical predictors multiple levels (since output give us p-value level rather predictor whole).next line tells us dispersion parameter assumed 1 binomial model. Dispersion property says whether data less spread around logistic curve expect. dispersion parameter 1 says data spread exactly expect. Greater 1 called -dispersion less 1 called -dispersion. line saying fitted model, assuming dispersion data exactly 1. binary data, like , data - -dispersed something ‚Äôll need check sorts generalised linear models.next line tells us dispersion parameter assumed 1 binomial model. Dispersion property says whether data less spread around logistic curve expect. dispersion parameter 1 says data spread exactly expect. Greater 1 called -dispersion less 1 called -dispersion. line saying fitted model, assuming dispersion data exactly 1. binary data, like , data - -dispersed something ‚Äôll need check sorts generalised linear models.last three lines relate quantities called deviance AIC (Akaike Information Criterion).\nsaid just , deviance values equivalent Sums Squares values linear models (product technique used fit curve data). can used metric goodness fit model, deviance 0 indicating perfect fitting model. deviance null model (.e.¬†model without predictors, basically saying probability getting positive diabetes score constant doesn‚Äôt depend glucose level) given first line deviance actual model given residual deviance line. see can use deviance two things.\ncheck whether model actually good (.e.¬†way look like ‚Äôs close data). akin R2 values linear models.\ncheck model ‚Äôve specified better null model.\n‚Äôs important realise two things can independent ; can model significantly better null model whilst still rubbish overall (null model even rubbish comparison), can model brilliant yet still better null model (case null model already brilliant).\n\nlast three lines relate quantities called deviance AIC (Akaike Information Criterion).said just , deviance values equivalent Sums Squares values linear models (product technique used fit curve data). can used metric goodness fit model, deviance 0 indicating perfect fitting model. deviance null model (.e.¬†model without predictors, basically saying probability getting positive diabetes score constant doesn‚Äôt depend glucose level) given first line deviance actual model given residual deviance line. see can use deviance two things.\ncheck whether model actually good (.e.¬†way look like ‚Äôs close data). akin R2 values linear models.\ncheck model ‚Äôve specified better null model.\n‚Äôs important realise two things can independent ; can model significantly better null model whilst still rubbish overall (null model even rubbish comparison), can model brilliant yet still better null model (case null model already brilliant).\ncheck whether model actually good (.e.¬†way look like ‚Äôs close data). akin R2 values linear models.check model ‚Äôve specified better null model.\n‚Äôs important realise two things can independent ; can model significantly better null model whilst still rubbish overall (null model even rubbish comparison), can model brilliant yet still better null model (case null model already brilliant).found previous practical AIC value meaningless , allow us compare model another model different terms (model smaller AIC value better fitting model).found previous practical AIC value meaningless , allow us compare model another model different terms (model smaller AIC value better fitting model).","code":"\nglm_diabetes <- diabetes %>% \n  glm(test ~ glucose,\n      family = binomial,\n      data = .)\nsummary(glm_diabetes)## \n## Call:\n## glm(formula = test ~ glucose, family = binomial, data = .)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -2.1353  -0.7819  -0.5189   0.8269   2.2832  \n## \n## Coefficients:\n##              Estimate Std. Error z value Pr(>|z|)    \n## (Intercept) -5.611732   0.442289  -12.69   <2e-16 ***\n## glucose      0.039510   0.003398   11.63   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 936.6  on 727  degrees of freedom\n## Residual deviance: 752.2  on 726  degrees of freedom\n## AIC: 756.2\n## \n## Number of Fisher Scoring iterations: 4"},{"path":"logistic-models-binary-response.html","id":"assessing-significance","chapter":"3 Logistic Models ‚Äì Binary Response","heading":"3.5 Assessing significance","text":"First, ‚Äôll look whether model ‚Äúwell specified‚Äù overall. Roughly speaking ‚Äúwell specified‚Äù just means model can predict dataset pretty well.","code":"\nglm_diabetes %>% \n  #augment()\n  glance() %>%\n  select(deviance, df.residual) %>% \n  as.numeric() %>% \n  #pchisq(x = .[1], df = .[2]) %>% \n  chisq_test()## # A tibble: 1 √ó 6\n##       n statistic     p    df method          p.signif\n## * <int>     <dbl> <dbl> <dbl> <chr>           <chr>   \n## 1     2     0.464 0.496     1 Chi-square test ns\n#install.packages(\"tidymodels\")\nlibrary(tidymodels)## Registered S3 method overwritten by 'tune':\n##   method                   from   \n##   required_pkgs.model_spec parsnip## ‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels 0.1.4 ‚îÄ‚îÄ## ‚úì dials        0.0.10     ‚úì rsample      0.1.1 \n## ‚úì infer        1.0.0      ‚úì tune         0.1.6 \n## ‚úì modeldata    0.1.1      ‚úì workflows    0.2.4 \n## ‚úì parsnip      0.1.7      ‚úì workflowsets 0.1.0 \n## ‚úì recipes      0.1.17     ‚úì yardstick    0.0.9## ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidymodels_conflicts() ‚îÄ‚îÄ\n## x infer::chisq_test() masks rstatix::chisq_test()\n## x scales::discard()   masks purrr::discard()\n## x rstatix::filter()   masks dplyr::filter(), stats::filter()\n## x recipes::fixed()    masks stringr::fixed()\n## x dials::get_n()      masks rstatix::get_n()\n## x dplyr::lag()        masks stats::lag()\n## x infer::prop_test()  masks rstatix::prop_test()\n## x yardstick::spec()   masks readr::spec()\n## x recipes::step()     masks stats::step()\n## x infer::t_test()     masks rstatix::t_test()\n## ‚Ä¢ Use suppressPackageStartupMessages() to eliminate package startup messages\nlibrary(glmnet)## Loading required package: Matrix## \n## Attaching package: 'Matrix'## The following objects are masked from 'package:tidyr':\n## \n##     expand, pack, unpack## Loaded glmnet 4.1-3\npchisq(752.2,726)## [1] 0.757072\n1-pchisq(752.2,726)## [1] 0.242928"},{"path":"logistic-models-binary-response.html","id":"exercise","chapter":"3 Logistic Models ‚Äì Binary Response","heading":"3.6 Exercise","text":"Exercise 3.1  can add exercises","code":""},{"path":"logistic-models-binary-response.html","id":"key-points","chapter":"3 Logistic Models ‚Äì Binary Response","heading":"3.7 Key points","text":"Adding key points","code":""},{},{"path":"resampling-intro.html","id":"resampling-intro","chapter":"4 Introduction","heading":"4 Introduction","text":"","code":""},{"path":"resampling-intro.html","id":"objectives-2","chapter":"4 Introduction","heading":"4.1 Objectives","text":"Aim: introduce R/Python commands algorithms conducting simple permutation tests.end practical participants able performMonte Carlo permutation tests \nTwo-samples continuous data\nMultiple samples continuous data\nSimple Linear Regression\nTwo-way anova\nTwo-samples continuous dataMultiple samples continuous dataSimple Linear RegressionTwo-way anovaand understand apply techniques generally.","code":""},{"path":"resampling-intro.html","id":"background-1","chapter":"4 Introduction","heading":"4.2 Background","text":"traditional statistical test make use various named distributions (normally normal distribution, lol, parametric tests like t-test ANOVA) order work properly, require certain assumptions made parent distribution (shape distribution symmetric non-parametric tests like Wilcoxon). assumptions met traditional statistical tests fine, can can‚Äôt assume normality distribution data just weird?Resampling techniques tools work . can allow us test hypotheses data using data (without appeal assumptions shape form parent distribution). ways much simpler approach statistics, rely ability generate thousands tens thousands random numbers quickly, simply weren‚Äôt considered practical back day. Even now, aren‚Äôt widely used require user (, case ‚Äôd forgotten ‚Äôs going time day) click button stats package even know name test. techniques require mix statistical knowledge programming; combination skills isn‚Äôt common! three broad areas resampling methods (although quite closely related):Permutation MethodsBootstrappingCross-validationPermutation methods focus practical allow us carry hypothesis testing.Bootstrapping technique estimating confidence intervals parameter estimates. effectively treat dataset parent distribution, draw samples calculate statistic choice (mean usually) using sub-samples. repeat process many times, eventually able construct distribution sample statistic. can used give us confidence interval statistic.Cross-validation heart modern machine learning approaches existed long technique became sexy/fashionable. divide dataset two sets: training set use fit model testing set use evaluate model. allows model accuracy empirically measured. several variants technique (holdout, k-fold cross validation, leave-one--cross-validation (LOOCV), leave-p--cross-validation (LpOCV) etc.), essentially thing; main difference trade-amount time takes perform versus reliability method.won‚Äôt cover bootstrapping cross-validation practical feel free Google .","code":""},{},{"path":"single-predictor-permutation-tests.html","id":"single-predictor-permutation-tests","chapter":"5 Single predictor permutation tests","heading":"5 Single predictor permutation tests","text":"","code":""},{"path":"single-predictor-permutation-tests.html","id":"objectives-3","chapter":"5 Single predictor permutation tests","heading":"5.1 Objectives","text":"QuestionsObjectives","code":""},{"path":"single-predictor-permutation-tests.html","id":"purpose-and-aim","chapter":"5 Single predictor permutation tests","heading":"5.2 Purpose and aim","text":"wish test difference two groups case assumptions two-sample t-test just aren‚Äôt met, two-sample permutation test procedure appropriate. also appropriate even assumptions t-test met, case, easier just damn t-test.One additional benefits permutation test aren‚Äôt just restricted testing hypotheses means two groups. can test hypotheses absolutely anything want! , see ranges two groups differed significantly etc.","code":""},{"path":"single-predictor-permutation-tests.html","id":"data-and-hypotheses","chapter":"5 Single predictor permutation tests","heading":"5.3 Data and hypotheses","text":"Let‚Äôs consider experimental dataset measured weights two groups 12 female mice (24 mice total). One group mice given perfectly normal diet (control) group mice given high fat diet several months. want test whether difference mean weight two groups. still need specify hypotheses:\\(H_0\\): difference means two groups\n\\(H_1\\): difference means two groups","code":""},{"path":"single-predictor-permutation-tests.html","id":"load-the-data-1","chapter":"5 Single predictor permutation tests","heading":"5.4 Load the data","text":"First load data, visualise . needed, load tidyverse package using:","code":"\nlibrary(tidyverse)"},{"path":"single-predictor-permutation-tests.html","id":"exercise-1","chapter":"5 Single predictor permutation tests","heading":"5.5 Exercise","text":"Exercise 5.1  can add exercises","code":""},{"path":"single-predictor-permutation-tests.html","id":"key-points-1","chapter":"5 Single predictor permutation tests","heading":"5.6 Key points","text":"Adding key points","code":""}]
